#!/usr/bin/env python3
"""
ğŸ”§ æ¬ è½ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã ãŒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒæœªç”Ÿæˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
"""

import os
import sys
import asyncio
import logging
from datetime import datetime
from dotenv import load_dotenv
from modules.batch_embedding import batch_generate_embeddings_for_document
from supabase_adapter import get_supabase_client, select_data

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

async def fix_missing_embeddings():
    """æ¬ è½ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¿®å¾©"""
    try:
        logger.info("ğŸ”§ æ¬ è½ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿®å¾©é–‹å§‹")
        
        # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        auto_embed = os.getenv("AUTO_GENERATE_EMBEDDINGS", "false").lower()
        logger.info(f"ğŸ“‹ AUTO_GENERATE_EMBEDDINGSè¨­å®š: {auto_embed}")
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
        supabase = get_supabase_client()
        logger.info("âœ… Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—å®Œäº†")
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æœªç”Ÿæˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
        logger.info("ğŸ” ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æœªç”Ÿæˆã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ä¸­...")
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—
        chunks_result = select_data(
            "chunks",
            columns="doc_id",
            filters={"embedding": None},
            limit=100
        )
        
        if not chunks_result.data:
            logger.info("âœ… å‡¦ç†ãŒå¿…è¦ãªãƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
            return True
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—
        doc_ids = list(set(chunk['doc_id'] for chunk in chunks_result.data))
        logger.info(f"ğŸ“‹ å‡¦ç†å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(doc_ids)}")
        
        # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        for i, doc_id in enumerate(doc_ids, 1):
            try:
                logger.info(f"ğŸ”„ [{i}/{len(doc_ids)}] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†é–‹å§‹: {doc_id}")
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
                doc_result = select_data(
                    "document_sources",
                    columns="id,name,type",
                    filters={"id": doc_id}
                )
                
                doc_name = "Unknown"
                if doc_result.data:
                    doc_name = doc_result.data[0].get('name', 'Unknown')
                    doc_type = doc_result.data[0].get('type', 'Unknown')
                    logger.info(f"  ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc_name} ({doc_type})")
                
                # è©²å½“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ç¢ºèª
                doc_chunks_result = select_data(
                    "chunks",
                    columns="id,chunk_index",
                    filters={
                        "doc_id": doc_id,
                        "embedding": None
                    }
                )
                
                if not doc_chunks_result.data:
                    logger.info(f"  âœ… {doc_name}: å‡¦ç†æ¸ˆã¿")
                    continue
                
                chunk_count = len(doc_chunks_result.data)
                logger.info(f"  ğŸ“Š æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count}")
                
                # ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ
                logger.info(f"  ğŸ§  ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆé–‹å§‹: {doc_name}")
                success = await batch_generate_embeddings_for_document(doc_id, chunk_count)
                
                if success:
                    logger.info(f"  ğŸ‰ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Œäº†: {doc_name}")
                else:
                    logger.warning(f"  âš ï¸ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼: {doc_name}")
                
                # å‡¦ç†é–“éš”ã‚’è¨­ã‘ã‚‹ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
                if i < len(doc_ids):
                    await asyncio.sleep(1)
                    
            except Exception as doc_error:
                logger.error(f"  âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {doc_id} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {doc_error}")
                continue
        
        # æœ€çµ‚çµæœç¢ºèª
        logger.info("ğŸ” ä¿®å¾©çµæœã‚’ç¢ºèªä¸­...")
        
        final_chunks_result = select_data(
            "chunks",
            columns="doc_id",
            filters={"embedding": None},
            limit=10
        )
        
        remaining_count = len(final_chunks_result.data) if final_chunks_result.data else 0
        logger.info(f"ğŸ“Š ä¿®å¾©å¾Œã®æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {remaining_count}")
        
        if remaining_count == 0:
            logger.info("ğŸ‰ ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿®å¾©å®Œäº†")
            return True
        else:
            logger.warning(f"âš ï¸ {remaining_count}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ãŒæœªå‡¦ç†ã®ã¾ã¾æ®‹ã£ã¦ã„ã¾ã™")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ä¿®å¾©å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸš€ æ¬ è½ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    
    success = await fix_missing_embeddings()
    
    if success:
        logger.info("âœ… ä¿®å¾©å‡¦ç†å®Œäº†")
        sys.exit(0)
    else:
        logger.error("âŒ ä¿®å¾©å‡¦ç†å¤±æ•—")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())