#!/usr/bin/env python3
"""
ğŸ§  ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒãƒ£ãƒ³ã‚¯ã‚’10ä»¶ãšã¤ã¾ã¨ã‚ã¦ãƒãƒƒãƒã§é€ä¿¡ã—ã€ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ä»˜ãã§embeddingã‚’ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
  python batch_embedding_processor.py                    # å…¨ã¦ã®æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
  python batch_embedding_processor.py --limit 100       # æœ€å¤§100ãƒãƒ£ãƒ³ã‚¯ã¾ã§å‡¦ç†
  python batch_embedding_processor.py --doc-id <ID>     # ç‰¹å®šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿å‡¦ç†
  python batch_embedding_processor.py --retry-only      # å¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ã¿å†å‡¦ç†
"""

import os
import sys
import asyncio
import argparse
import logging
from datetime import datetime
from dotenv import load_dotenv
from modules.batch_embedding import batch_generate_embeddings_for_document, batch_generate_embeddings_for_all_pending
from supabase_adapter import get_supabase_client, select_data

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('batch_embedding.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

async def process_specific_document(doc_id: str) -> bool:
    """ç‰¹å®šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†"""
    try:
        logger.info(f"ğŸ¯ ç‰¹å®šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†é–‹å§‹: {doc_id}")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
        doc_result = select_data(
            "document_sources",
            columns="id,name,type",
            filters={"id": doc_id}
        )
        
        if not doc_result.data:
            logger.error(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {doc_id}")
            return False
        
        doc_info = doc_result.data[0]
        doc_name = doc_info.get('name', 'Unknown')
        doc_type = doc_info.get('type', 'Unknown')
        
        logger.info(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc_name} ({doc_type})")
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ç¢ºèª
        chunks_result = select_data(
            "chunks",
            columns="id",
            filters={
                "doc_id": doc_id,
                "embedding": None
            }
        )
        
        if not chunks_result.data:
            logger.info(f"âœ… {doc_name}: å‡¦ç†æ¸ˆã¿")
            return True
        
        chunk_count = len(chunks_result.data)
        logger.info(f"ğŸ“Š æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count}")
        
        # ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ
        success = await batch_generate_embeddings_for_document(doc_id, chunk_count)
        
        if success:
            logger.info(f"ğŸ‰ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†å®Œäº†: {doc_name}")
        else:
            logger.warning(f"âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼: {doc_name}")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def process_all_pending(limit: int = None) -> bool:
    """å…¨ã¦ã®æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†"""
    try:
        logger.info("ğŸŒ å…¨æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–‹å§‹")
        
        if limit:
            logger.info(f"ğŸ“‹ å‡¦ç†åˆ¶é™: {limit}ãƒãƒ£ãƒ³ã‚¯")
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ç¢ºèª
        chunks_result = select_data(
            "chunks",
            columns="id",
            filters={"embedding": None},
            limit=limit or 1000  # ç¢ºèªç”¨ã®åˆ¶é™
        )
        
        if not chunks_result.data:
            logger.info("âœ… å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
            return True
        
        total_pending = len(chunks_result.data)
        logger.info(f"ğŸ“Š æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {total_pending}ä»¶")
        
        # ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ
        success = await batch_generate_embeddings_for_all_pending(limit)
        
        if success:
            logger.info("ğŸ‰ å…¨ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†")
        else:
            logger.warning("âš ï¸ å…¨ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ å…¨ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def retry_failed_chunks() -> bool:
    """å¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ã¿å†å‡¦ç†"""
    try:
        logger.info("ğŸ”„ å¤±æ•—ãƒãƒ£ãƒ³ã‚¯å†å‡¦ç†é–‹å§‹")
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆã“ã‚Œã‚‰ãŒå¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ï¼‰
        chunks_result = select_data(
            "chunks",
            columns="id,doc_id",
            filters={"embedding": None},
            limit=100  # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹åˆ¶é™
        )
        
        if not chunks_result.data:
            logger.info("âœ… å†å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
            return True
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        doc_chunks = {}
        for chunk in chunks_result.data:
            doc_id = chunk['doc_id']
            if doc_id not in doc_chunks:
                doc_chunks[doc_id] = []
            doc_chunks[doc_id].append(chunk['id'])
        
        logger.info(f"ğŸ“Š å†å‡¦ç†å¯¾è±¡: {len(doc_chunks)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ, {len(chunks_result.data)}ãƒãƒ£ãƒ³ã‚¯")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã”ã¨ã«å†å‡¦ç†
        total_success = True
        for doc_id, chunk_ids in doc_chunks.items():
            logger.info(f"ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {doc_id} å†å‡¦ç†: {len(chunk_ids)}ãƒãƒ£ãƒ³ã‚¯")
            
            success = await batch_generate_embeddings_for_document(doc_id, len(chunk_ids))
            if not success:
                total_success = False
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã§å¾…æ©Ÿ
            await asyncio.sleep(2)
        
        if total_success:
            logger.info("ğŸ‰ å¤±æ•—ãƒãƒ£ãƒ³ã‚¯å†å‡¦ç†å®Œäº†")
        else:
            logger.warning("âš ï¸ å¤±æ•—ãƒãƒ£ãƒ³ã‚¯å†å‡¦ç†ã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼")
        
        return total_success
        
    except Exception as e:
        logger.error(f"âŒ å¤±æ•—ãƒãƒ£ãƒ³ã‚¯å†å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def show_status():
    """å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤º"""
    try:
        logger.info("ğŸ“Š å‡¦ç†çŠ¶æ³ç¢ºèªä¸­...")
        
        # ç·ãƒãƒ£ãƒ³ã‚¯æ•°
        total_result = select_data("chunks", columns="id")
        total_chunks = len(total_result.data) if total_result.data else 0
        
        # å‡¦ç†æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•°
        processed_result = select_data(
            "chunks", 
            columns="id", 
            filters={"embedding": "NOT NULL"}
        )
        processed_chunks = len(processed_result.data) if processed_result.data else 0
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°
        pending_result = select_data(
            "chunks", 
            columns="id", 
            filters={"embedding": None}
        )
        pending_chunks = len(pending_result.data) if pending_result.data else 0
        
        # é€²æ—ç‡è¨ˆç®—
        progress_rate = (processed_chunks / total_chunks * 100) if total_chunks > 0 else 0
        
        logger.info("=" * 50)
        logger.info("ğŸ“Š ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†çŠ¶æ³")
        logger.info("=" * 50)
        logger.info(f"ğŸ“‹ ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}")
        logger.info(f"âœ… å‡¦ç†æ¸ˆã¿: {processed_chunks}")
        logger.info(f"â³ æœªå‡¦ç†: {pending_chunks}")
        logger.info(f"ğŸ“ˆ é€²æ—ç‡: {progress_rate:.1f}%")
        logger.info("=" * 50)
        
        return pending_chunks == 0
        
    except Exception as e:
        logger.error(f"âŒ çŠ¶æ³ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python batch_embedding_processor.py                    # å…¨ã¦ã®æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
  python batch_embedding_processor.py --limit 100       # æœ€å¤§100ãƒãƒ£ãƒ³ã‚¯ã¾ã§å‡¦ç†
  python batch_embedding_processor.py --doc-id abc123   # ç‰¹å®šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿å‡¦ç†
  python batch_embedding_processor.py --retry-only      # å¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ã¿å†å‡¦ç†
  python batch_embedding_processor.py --status          # å‡¦ç†çŠ¶æ³ã®ã¿è¡¨ç¤º
        """
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        help="å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ•°"
    )
    
    parser.add_argument(
        "--doc-id",
        type=str,
        help="å‡¦ç†ã™ã‚‹ç‰¹å®šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"
    )
    
    parser.add_argument(
        "--retry-only",
        action="store_true",
        help="å¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ã¿å†å‡¦ç†"
    )
    
    parser.add_argument(
        "--status",
        action="store_true",
        help="å‡¦ç†çŠ¶æ³ã®ã¿è¡¨ç¤º"
    )
    
    return parser.parse_args()

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    args = parse_arguments()
    
    logger.info("ğŸš€ ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    logger.info(f"â° é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        auto_embed = os.getenv("AUTO_GENERATE_EMBEDDINGS", "false").lower()
        if auto_embed != "true":
            logger.warning("âš ï¸ AUTO_GENERATE_EMBEDDINGS=false ã§ã™ã€‚å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ")
            logger.info("ğŸ’¡ ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã‹ã€.envãƒ•ã‚¡ã‚¤ãƒ«ã§AUTO_GENERATE_EMBEDDINGS=trueã«è¨­å®šã—ã¦ãã ã•ã„")
        
        success = False
        
        if args.status:
            # çŠ¶æ³è¡¨ç¤ºã®ã¿
            success = await show_status()
        elif args.doc_id:
            # ç‰¹å®šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†
            success = await process_specific_document(args.doc_id)
        elif args.retry_only:
            # å¤±æ•—ãƒãƒ£ãƒ³ã‚¯å†å‡¦ç†
            success = await retry_failed_chunks()
        else:
            # å…¨ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
            success = await process_all_pending(args.limit)
        
        # æœ€çµ‚çŠ¶æ³è¡¨ç¤º
        if not args.status:
            await show_status()
        
        if success:
            logger.info("âœ… å‡¦ç†å®Œäº†")
            sys.exit(0)
        else:
            logger.error("âŒ å‡¦ç†å¤±æ•—")
            sys.exit(1)
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹å‡¦ç†ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())