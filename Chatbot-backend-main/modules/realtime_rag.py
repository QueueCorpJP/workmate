"""
ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†ãƒ•ãƒ­ãƒ¼
è³ªå•å—ä»˜ã€œRAGå‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å›ç­”ï¼‰ã®å®Ÿè£…

ã‚¹ãƒ†ãƒƒãƒ—:
âœï¸ Step 1. è³ªå•å…¥åŠ› - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«è³ªå•ã‚’å…¥åŠ›
ğŸ§  Step 2. embedding ç”Ÿæˆ - Gemini Vectors APIï¼ˆgemini-embedding-exp-03-07ï¼‰ã‚’ä½¿ã£ã¦ã€è³ªå•æ–‡ã‚’3072æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
ğŸ” Step 3. é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢ï¼ˆTop-Kï¼‰ - Supabaseã® chunks ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã€ãƒ™ã‚¯ãƒˆãƒ«è·é›¢ãŒè¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ pgvector ã‚’ç”¨ã„ã¦å–å¾—
ğŸ’¡ Step 4. LLMã¸é€ä¿¡ - Top-K ãƒãƒ£ãƒ³ã‚¯ã¨å…ƒã®è³ªå•ã‚’ Gemini Flash 2.5 ã«æ¸¡ã—ã¦ã€è¦ç´„ã›ãšã«ã€ŒåŸæ–‡ãƒ™ãƒ¼ã‚¹ã€ã§å›ç­”ã‚’ç”Ÿæˆ
âš¡ï¸ Step 5. å›ç­”è¡¨ç¤º
"""

import os
import logging
import asyncio
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
import google.generativeai as genai
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from datetime import datetime

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

logger = logging.getLogger(__name__)

class RealtimeRAGProcessor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        model_name = os.getenv("EMBEDDING_MODEL", "models/text-embedding-004")
        
        # ãƒ¢ãƒ‡ãƒ«åãŒæ­£ã—ã„å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£
        if not model_name.startswith(("models/", "tunedModels/")):
            if model_name in ["gemini-embedding-exp-03-07", "text-embedding-004"]:
                model_name = f"models/{model_name}"
            else:
                model_name = "models/text-embedding-004"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        self.embedding_model = model_name
        self.chat_model = "gemini-2.5-flash"  # æœ€æ–°ã®Gemini Flash 2.5
        self.db_url = self._get_db_url()
        
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        genai.configure(api_key=self.api_key)
        self.chat_client = genai.GenerativeModel(self.chat_model)
        
        logger.info(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–å®Œäº†: ãƒ¢ãƒ‡ãƒ«={self.embedding_model}")
    
    def _get_db_url(self) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’æ§‹ç¯‰"""
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        
        if not supabase_url or not supabase_key:
            raise ValueError("SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # Supabase URLã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’æŠ½å‡º
        if "supabase.co" in supabase_url:
            project_id = supabase_url.split("://")[1].split(".")[0]
            return f"postgresql://postgres.{project_id}:{os.getenv('DB_PASSWORD', '')}@aws-0-ap-northeast-1.pooler.supabase.com:6543/postgres"
        else:
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã®å ´åˆ
            db_url = os.getenv("DATABASE_URL")
            if not db_url:
                raise ValueError("DATABASE_URL ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return db_url
    
    async def step1_receive_question(self, question: str, company_id: str = None) -> Dict:
        """
        âœï¸ Step 1. è³ªå•å…¥åŠ›
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«è³ªå•ã‚’å…¥åŠ›
        """
        logger.info(f"âœï¸ Step 1: è³ªå•å—ä»˜ - '{question[:50]}...'")
        
        if not question or not question.strip():
            raise ValueError("è³ªå•ãŒç©ºã§ã™")
        
        # è³ªå•ã®å‰å‡¦ç†
        processed_question = question.strip()
        
        return {
            "original_question": question,
            "processed_question": processed_question,
            "company_id": company_id,
            "timestamp": datetime.now().isoformat(),
            "step": 1
        }
    
    async def step2_generate_embedding(self, question: str) -> List[float]:
        """
        ğŸ§  Step 2. embedding ç”Ÿæˆ
        Gemini Vectors APIï¼ˆgemini-embedding-exp-03-07ï¼‰ã‚’ä½¿ã£ã¦ã€è³ªå•æ–‡ã‚’3072æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        """
        logger.info(f"ğŸ§  Step 2: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆä¸­...")
        
        try:
            # Gemini Embedding APIå‘¼ã³å‡ºã—
            response = genai.embed_content(
                model=self.embedding_model,
                content=question
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—
            embedding_vector = None
            
            if isinstance(response, dict) and 'embedding' in response:
                embedding_vector = response['embedding']
            elif hasattr(response, 'embedding') and response.embedding:
                embedding_vector = response.embedding
            else:
                logger.error(f"äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
                raise ValueError("ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            if not embedding_vector or len(embedding_vector) != 3072:
                raise ValueError(f"ç„¡åŠ¹ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¬¡å…ƒ: {len(embedding_vector) if embedding_vector else 0}")
            
            logger.info(f"âœ… Step 2å®Œäº†: 3072æ¬¡å…ƒã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”ŸæˆæˆåŠŸ")
            return embedding_vector
            
        except Exception as e:
            logger.error(f"âŒ Step 2ã‚¨ãƒ©ãƒ¼: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•— - {e}")
            raise
    
    async def step3_similarity_search(self, query_embedding: List[float], company_id: str = None, top_k: int = 10) -> List[Dict]:
        """
        ğŸ” Step 3. é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢ï¼ˆTop-Kï¼‰
        Supabaseã® chunks ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã€ãƒ™ã‚¯ãƒˆãƒ«è·é›¢ãŒè¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ pgvector ã‚’ç”¨ã„ã¦å–å¾—
        """
        logger.info(f"ğŸ” Step 3: é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢é–‹å§‹ (Top-{top_k})")
        
        try:
            with psycopg2.connect(self.db_url, cursor_factory=RealDictCursor) as conn:
                with conn.cursor() as cur:
                    # pgvectorã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ¤œç´¢SQL
                    sql = """
                    SELECT 
                        c.id,
                        c.doc_id,
                        c.chunk_index,
                        c.content,
                        ds.name as document_name,
                        ds.type as document_type,
                        1 - (c.embedding <=> %s) as similarity_score
                    FROM chunks c
                    LEFT JOIN document_sources ds ON ds.id = c.doc_id
                    WHERE c.embedding IS NOT NULL
                    """
                    
                    params = [query_embedding]
                    
                    # ä¼šç¤¾IDãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    if company_id:
                        sql += " AND c.company_id = %s"
                        params.append(company_id)
                    
                    # ãƒ™ã‚¯ãƒˆãƒ«è·é›¢é †ã§ã‚½ãƒ¼ãƒˆï¼ˆTop-Kå–å¾—ï¼‰
                    sql += " ORDER BY c.embedding <=> %s LIMIT %s"
                    params.extend([query_embedding, top_k])
                    
                    logger.info(f"å®Ÿè¡ŒSQL: ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ¤œç´¢ (Top-{top_k})")
                    cur.execute(sql, params)
                    results = cur.fetchall()
                    
                    # çµæœã‚’è¾æ›¸ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
                    similar_chunks = []
                    for row in results:
                        similar_chunks.append({
                            'chunk_id': row['id'],
                            'doc_id': row['doc_id'],
                            'chunk_index': row['chunk_index'],
                            'content': row['content'],
                            'document_name': row['document_name'],
                            'document_type': row['document_type'],
                            'similarity_score': float(row['similarity_score'])
                        })
                    
                    logger.info(f"âœ… Step 3å®Œäº†: {len(similar_chunks)}å€‹ã®é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—")
                    
                    # ãƒ‡ãƒãƒƒã‚°: ä¸Šä½3ä»¶ã®é¡ä¼¼åº¦ã‚’è¡¨ç¤º
                    for i, chunk in enumerate(similar_chunks[:3]):
                        logger.info(f"  {i+1}. {chunk['document_name']} [ãƒãƒ£ãƒ³ã‚¯{chunk['chunk_index']}] é¡ä¼¼åº¦: {chunk['similarity_score']:.3f}")
                    
                    return similar_chunks
        
        except Exception as e:
            logger.error(f"âŒ Step 3ã‚¨ãƒ©ãƒ¼: é¡ä¼¼æ¤œç´¢å¤±æ•— - {e}")
            raise
    
    async def step4_generate_answer(self, question: str, similar_chunks: List[Dict], company_name: str = "ãŠå®¢æ§˜ã®ä¼šç¤¾") -> str:
        """
        ğŸ’¡ Step 4. LLMã¸é€ä¿¡
        Top-K ãƒãƒ£ãƒ³ã‚¯ã¨å…ƒã®è³ªå•ã‚’ Gemini Flash 2.5 ã«æ¸¡ã—ã¦ã€è¦ç´„ã›ãšã«ã€ŒåŸæ–‡ãƒ™ãƒ¼ã‚¹ã€ã§å›ç­”ã‚’ç”Ÿæˆ
        """
        logger.info(f"ğŸ’¡ Step 4: LLMå›ç­”ç”Ÿæˆé–‹å§‹ ({len(similar_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ä½¿ç”¨)")
        
        if not similar_chunks:
            logger.warning("é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ä¸€èˆ¬çš„ãªå›ç­”ã‚’ç”Ÿæˆ")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã”è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ã—ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        
        try:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ï¼ˆåŸæ–‡ãƒ™ãƒ¼ã‚¹ï¼‰
            context_parts = []
            total_length = 0
            max_context_length = 100000  # 10ä¸‡æ–‡å­—åˆ¶é™
            
            for i, chunk in enumerate(similar_chunks):
                chunk_content = f"ã€å‚è€ƒè³‡æ–™{i+1}: {chunk['document_name']} - ãƒãƒ£ãƒ³ã‚¯{chunk['chunk_index']}ã€‘\n{chunk['content']}\n"
                
                if total_length + len(chunk_content) > max_context_length:
                    logger.info(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™ã«ã‚ˆã‚Š{i}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ç”¨")
                    break
                
                context_parts.append(chunk_content)
                total_length += len(chunk_content)
            
            context = "\n".join(context_parts)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆåŸæ–‡ãƒ™ãƒ¼ã‚¹é‡è¦–ï¼‰
            prompt = f"""ã‚ãªãŸã¯{company_name}ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å‚è€ƒè³‡æ–™ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
1. å‚è€ƒè³‡æ–™ã®å†…å®¹ã‚’è¦ç´„ã›ãšã€åŸæ–‡ã®è¡¨ç¾ã‚’ãã®ã¾ã¾æ´»ç”¨ã—ã¦ãã ã•ã„
2. å‚è€ƒè³‡æ–™ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å…·ä½“çš„ãªæ‰‹é †ã€é€£çµ¡å…ˆã€æ¡ä»¶ç­‰ã¯æ­£ç¢ºã«ä¼ãˆã¦ãã ã•ã„
3. å‚è€ƒè³‡æ–™ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãšã€ã€Œè³‡æ–™ã«è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨æ˜è¨˜ã—ã¦ãã ã•ã„
4. å›ç­”ã¯ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„

ã€å‚è€ƒè³‡æ–™ã€‘
{context}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{question}

ã€å›ç­”ã€‘"""

            # Gemini Flash 2.5ã§å›ç­”ç”Ÿæˆ
            response = self.chat_client.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.1,  # ä¸€è²«æ€§é‡è¦–
                    max_output_tokens=2048,
                    top_p=0.8,
                    top_k=40
                )
            )
            
            if response and response.text:
                answer = response.text.strip()
                logger.info(f"âœ… Step 4å®Œäº†: {len(answer)}æ–‡å­—ã®å›ç­”ã‚’ç”Ÿæˆ")
                return answer
            else:
                logger.error("LLMã‹ã‚‰ã®å›ç­”ãŒç©ºã§ã™")
                return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        
        except Exception as e:
            logger.error(f"âŒ Step 4ã‚¨ãƒ©ãƒ¼: LLMå›ç­”ç”Ÿæˆå¤±æ•— - {e}")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    async def step5_display_answer(self, answer: str, metadata: Dict = None) -> Dict:
        """
        âš¡ï¸ Step 5. å›ç­”è¡¨ç¤º
        æœ€çµ‚çš„ãªå›ç­”ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        """
        logger.info(f"âš¡ï¸ Step 5: å›ç­”è¡¨ç¤ºæº–å‚™å®Œäº†")
        
        result = {
            "answer": answer,
            "timestamp": datetime.now().isoformat(),
            "step": 5,
            "status": "completed"
        }
        
        if metadata:
            result.update(metadata)
        
        logger.info(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†å®Œäº†: {len(answer)}æ–‡å­—ã®å›ç­”")
        return result
    
    async def process_realtime_rag(self, question: str, company_id: str = None, company_name: str = "ãŠå®¢æ§˜ã®ä¼šç¤¾", top_k: int = 10) -> Dict:
        """
        ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®å®Ÿè¡Œ
        Step 1ã€œ5ã‚’é †æ¬¡å®Ÿè¡Œã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å›ç­”ã‚’ç”Ÿæˆ
        """
        logger.info(f"ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†é–‹å§‹: '{question[:50]}...'")
        
        try:
            # Step 1: è³ªå•å…¥åŠ›
            step1_result = await self.step1_receive_question(question, company_id)
            processed_question = step1_result["processed_question"]
            
            # Step 2: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
            query_embedding = await self.step2_generate_embedding(processed_question)
            
            # Step 3: é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
            similar_chunks = await self.step3_similarity_search(query_embedding, company_id, top_k)
            
            # Step 4: LLMå›ç­”ç”Ÿæˆ
            answer = await self.step4_generate_answer(processed_question, similar_chunks, company_name)
            
            # Step 5: å›ç­”è¡¨ç¤º
            metadata = {
                "original_question": question,
                "processed_question": processed_question,
                "chunks_used": len(similar_chunks),
                "top_similarity": similar_chunks[0]["similarity_score"] if similar_chunks else 0.0,
                "company_id": company_id,
                "company_name": company_name
            }
            
            result = await self.step5_display_answer(answer, metadata)
            
            logger.info(f"ğŸ‰ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†æˆåŠŸå®Œäº†")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            error_result = {
                "answer": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "status": "error"
            }
            return error_result

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_realtime_rag_processor = None

def get_realtime_rag_processor() -> Optional[RealtimeRAGProcessor]:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGãƒ—ãƒ­ã‚»ãƒƒã‚µã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰"""
    global _realtime_rag_processor
    
    if _realtime_rag_processor is None:
        try:
            _realtime_rag_processor = RealtimeRAGProcessor()
            logger.info("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    return _realtime_rag_processor

async def process_question_realtime(question: str, company_id: str = None, company_name: str = "ãŠå®¢æ§˜ã®ä¼šç¤¾", top_k: int = 10) -> Dict:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGå‡¦ç†ã®å¤–éƒ¨å‘¼ã³å‡ºã—ç”¨é–¢æ•°
    
    Args:
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        company_id: ä¼šç¤¾IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        company_name: ä¼šç¤¾åï¼ˆå›ç­”ç”Ÿæˆç”¨ï¼‰
        top_k: å–å¾—ã™ã‚‹é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ•°
    
    Returns:
        Dict: å‡¦ç†çµæœï¼ˆå›ç­”ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç­‰ï¼‰
    """
    processor = get_realtime_rag_processor()
    if not processor:
        return {
            "answer": "ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
            "error": "RealtimeRAGProcessor initialization failed",
            "timestamp": datetime.now().isoformat(),
            "status": "error"
        }
    
    return await processor.process_realtime_rag(question, company_id, company_name, top_k)

def realtime_rag_available() -> bool:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ RAGãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
    try:
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        
        return bool(api_key and supabase_url and supabase_key)
    except Exception:
        return False