"""
ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
ãƒãƒ£ãƒƒãƒˆã®ä¸»è¦ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã—ã¾ã™
"""
import asyncio
from typing import Dict, Any, Optional, List
import uuid
from datetime import datetime
from supabase_adapter import select_data, insert_data
from .chat_config import (
    safe_print, HTTPException, model, get_db_cursor,
    USAGE_LIMIT_ENABLED, USAGE_LIMIT_PER_HOUR, CONTEXT_CACHING_ENABLED
)
from .chat_conversation import (
    detect_conversation_intent, generate_casual_response, 
    should_use_rag_search, extract_search_query
)
from .chat_rag import adaptive_rag_search, contextual_rag_search, format_search_results
from .comprehensive_search_system import comprehensive_search, initialize_comprehensive_search
from .chat_rag_enhanced import enhanced_rag_search, enhanced_format_search_results
from .chat_utils import safe_safe_print

# ä½¿ç”¨é‡è¿½è·¡ç”¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
usage_tracker = {}

def check_usage_limit(user_id: str) -> bool:
    """
    ä½¿ç”¨é‡åˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        
    Returns:
        åˆ¶é™å†…ã®å ´åˆTrue
    """
    if not USAGE_LIMIT_ENABLED:
        return True
    
    import time
    current_time = time.time()
    hour_ago = current_time - 3600  # 1æ™‚é–“å‰
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½¿ç”¨å±¥æ­´ã‚’å–å¾—
    if user_id not in usage_tracker:
        usage_tracker[user_id] = []
    
    user_usage = usage_tracker[user_id]
    
    # 1æ™‚é–“ä»¥å†…ã®ä½¿ç”¨å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    recent_usage = [timestamp for timestamp in user_usage if timestamp > hour_ago]
    usage_tracker[user_id] = recent_usage  # å¤ã„è¨˜éŒ²ã‚’å‰Šé™¤
    
    # åˆ¶é™ãƒã‚§ãƒƒã‚¯
    if len(recent_usage) >= USAGE_LIMIT_PER_HOUR:
        safe_print(f"Usage limit exceeded for user {user_id}: {len(recent_usage)}/{USAGE_LIMIT_PER_HOUR}")
        return False
    
    # æ–°ã—ã„ä½¿ç”¨ã‚’è¨˜éŒ²
    usage_tracker[user_id].append(current_time)
    return True

def record_usage(user_id: str, tokens_used: int = 0):
    """
    ä½¿ç”¨é‡ã‚’è¨˜éŒ²
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        tokens_used: ä½¿ç”¨ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°
    """
    try:
        cursor = get_db_cursor()
        if cursor:
            cursor.execute(
                "INSERT INTO usage_logs (user_id, tokens_used, timestamp) VALUES (%s, %s, NOW())",
                (user_id, tokens_used)
            )
            cursor.connection.commit()
    except Exception as e:
        safe_print(f"Error recording usage: {e}")

async def save_chat_history(
    user_id: str,
    user_message: str,
    bot_response: str,
    company_id: Optional[str] = None,
    category: Optional[str] = None,
    sentiment: Optional[str] = None,
    source_document: Optional[str] = None,
    source_page: Optional[str] = None,
    model_name: str = 'gemini-2.5-flash',
    input_tokens: int = 0,
    output_tokens: int = 0,
    cost_usd: float = 0.0,
    employee_id: Optional[str] = None,
    employee_name: Optional[str] = None,
) -> None:
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Supabaseã® chat_history ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã™ã‚‹
    """
    try:
        safe_print(f"[DB SAVE] save_chat_history called for user {user_id}. Message: {user_message[:50]}...")
        
        chat_id = str(uuid.uuid4())
        timestamp = datetime.now().isoformat()

        # company_id ãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã€user_id ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
        if company_id is None and user_id != "anonymous":
            safe_print(f"[DB SAVE] Attempting to get company_id for user {user_id}")
            user_data_result = select_data("users", filters={"id": user_id}, columns="company_id")
            if user_data_result and user_data_result.data:
                company_id = user_data_result.data[0].get("company_id")
                safe_print(f"[DB SAVE] Found company_id: {company_id} for user {user_id}")
            else:
                safe_print(f"[DB SAVE] No company_id found for user {user_id}")

        # ä¼šç¤¾åˆ¥æ–™é‡‘ä½“ç³»ã«åŸºã¥ã„ã¦æ­£ç¢ºãªã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
        if company_id and user_message and bot_response:
            try:
                from modules.token_counter import TokenCounter
                counter = TokenCounter()
                
                # ä¼šç¤¾åˆ¥æ–™é‡‘è¨ˆç®—ï¼ˆRAGå‡¦ç†ã®å ´åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§1å›ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼‰
                prompt_refs = 1 if use_context and search_results else 0
                cost_result = counter.calculate_cost_by_company(
                    user_message, bot_response, company_id, prompt_refs
                )
                
                # è¨ˆç®—çµæœã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ã
                input_tokens = cost_result["input_tokens"]
                output_tokens = cost_result["output_tokens"]
                cost_usd = cost_result["total_cost_usd"]
                
                safe_print(f"[DB SAVE] Company-specific cost calculated: ${cost_usd:.6f} for company {company_id}")
                
            except Exception as calc_error:
                safe_print(f"[DB SAVE] Error calculating company-specific cost: {calc_error}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å…ƒã®å€¤ã‚’ä½¿ç”¨

        # employee_id ãŒæ˜ç¤ºçš„ã«æ¸¡ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ user_id ã‚’åˆ©ç”¨ã™ã‚‹
        effective_employee_id = employee_id or user_id

        data = {
            "id": chat_id,
            "user_message": user_message,
            "bot_response": bot_response,
            "timestamp": timestamp,
            "category": category,
            "sentiment": sentiment,
            "employee_id": effective_employee_id,
            "employee_name": employee_name,
            "user_id": user_id,
            "company_id": company_id,
            "source_document": source_document,
            "source_page": source_page,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": input_tokens + output_tokens,
            "model_name": model_name,
            "cost_usd": cost_usd,
        }

        result = insert_data("chat_history", data)
        if result.success:
            safe_print(f"[DB SAVE] Chat history successfully saved to Supabase for user {user_id} with id {chat_id}")
        else:
            safe_print(f"[DB SAVE] Failed to save chat history to Supabase: {result.error}")
    except Exception as e:
        safe_print(f"[DB SAVE] Unexpected error saving chat history: {e}")
        import traceback
        safe_print(traceback.format_exc())

async def process_chat_message(
    message: str, 
    user_id: str = "anonymous", 
    conversation_history: List[Dict[str, str]] = None,
    use_context: bool = True
) -> Dict[str, Any]:
    """
    ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
    
    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        conversation_history: ä¼šè©±å±¥æ­´
        use_context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
        
    Returns:
        å‡¦ç†çµæœ
    """
    try:
        safe_print(f"Processing chat message from user {user_id}: {message[:100]}...")
        
        # ä½¿ç”¨é‡åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not check_usage_limit(user_id):
            raise HTTPException(
                status_code=429, 
                detail="ä½¿ç”¨é‡åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚1æ™‚é–“å¾Œã«å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
        
        # ä¼šè©±æ„å›³ã‚’æ¤œå‡º
        intent_info = detect_conversation_intent(message)
        safe_print(f"Detected intent: {intent_info}")
        
        # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªä¼šè©±ã®å ´åˆ
        if intent_info.get('is_casual', False):
            response = await generate_casual_response(message, intent_info)
            
            # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
            record_usage(user_id, len(response))
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ãƒ»ã‚³ã‚¹ãƒˆè¨ˆç®—å«ã‚€ï¼‰
            safe_print(f"[PROCESS] Saving casual chat history for user {user_id}")
            
            # company_idã‚’å–å¾—
            company_id = None
            if user_id != "anonymous":
                user_data_result = select_data("users", filters={"id": user_id}, columns="company_id")
                if user_data_result and user_data_result.data:
                    company_id = user_data_result.data[0].get("company_id")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆåŸºæœ¬å¿œç­”ã®å ´åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§ãªã—ï¼‰
            from modules.token_counter import TokenCounter
            counter = TokenCounter()
            cost_result = counter.calculate_cost_by_company(message, response, company_id, 0)
            
            await save_chat_history(user_id, message, response, 
                                  category=intent_info.get('category'),
                                  company_id=company_id,
                                  input_tokens=cost_result.get("input_tokens", 0),
                                  output_tokens=cost_result.get("output_tokens", 0),
                                  cost_usd=cost_result.get("total_cost_usd", 0.0))
            
            return {
                'response': response,
                'intent': intent_info,
                'search_results': [],
                'processing_type': 'casual'
            }
        
        # RAGæ¤œç´¢ãŒå¿…è¦ãªå ´åˆ
        if should_use_rag_search(message, intent_info):
            # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
            search_query = extract_search_query(message, intent_info)
            safe_print(f"Extracted search query: {search_query}")
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
            context = ""
            if use_context and conversation_history:
                context_parts = []
                for entry in conversation_history[-3:]:  # æœ€å¾Œã®3ã¤ã®ä¼šè©±ã‚’ä½¿ç”¨
                    if entry.get('user'):
                        context_parts.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {entry['user']}")
                    if entry.get('assistant'):
                        context_parts.append(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {entry['assistant']}")
                context = "\n".join(context_parts)
            
            # RAGæ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆæ‹¡å¼µRAGã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼‰
            try:
                # æ‹¡å¼µRAGã‚·ã‚¹ãƒ†ãƒ ã‚’æœ€å„ªå…ˆã§å®Ÿè¡Œï¼ˆPDFå¾ŒåŠæƒ…å ±ã€å‹•çš„LIMITã€æ–‡æ›¸å¤šæ§˜æ€§ï¼‰
                search_results = await enhanced_rag_search(
                    query=search_query,
                    context=context,
                    company_id=None,  # å¾Œã§ä¼šç¤¾IDãƒ•ã‚£ãƒ«ã‚¿ã‚’è¿½åŠ å¯èƒ½
                    adaptive_limits=True  # ã‚¯ã‚¨ãƒªè¤‡é›‘ã•ã«å¿œã˜ãŸå‹•çš„LIMITèª¿æ•´
                )
                
                if search_results:
                    safe_print(f"æ‹¡å¼µRAGæ¤œç´¢æˆåŠŸ: {len(search_results)}ä»¶ã®é«˜å“è³ªçµæœã‚’å–å¾—")
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯1: åŒ…æ‹¬çš„æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
                    safe_print("æ‹¡å¼µRAGæ¤œç´¢ã§çµæœãªã—ã€åŒ…æ‹¬çš„æ¤œç´¢ã‚’è©¦è¡Œ")
                    search_results = await comprehensive_search(
                        search_query, 
                        company_id=None,
                        initial_limit=40,
                        final_limit=12
                    )
                    
                    if not search_results:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯2: å¾“æ¥ã®æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
                        safe_print("åŒ…æ‹¬çš„æ¤œç´¢ã§ã‚‚çµæœãªã—ã€å¾“æ¥æ¤œç´¢ã‚’å®Ÿè¡Œ")
                        if context:
                            search_results = await contextual_rag_search(search_query, context, limit=12)
                        else:
                            search_results = await adaptive_rag_search(search_query, limit=12)
                        
            except Exception as e:
                safe_print(f"æ‹¡å¼µRAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œ")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
                if context:
                    search_results = await contextual_rag_search(search_query, context, limit=12)
                else:
                    search_results = await adaptive_rag_search(search_query, limit=12)
            
            # æ¤œç´¢çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ‹¡å¼µç‰ˆã‚’ä½¿ç”¨ï¼‰
            try:
                formatted_results = enhanced_format_search_results(search_results, max_length=3000)
            except Exception as e:
                safe_print(f"æ‹¡å¼µãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}ã€æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨")
                formatted_results = format_search_results(search_results, max_length=2000)
            
            # Geminiã§å¿œç­”ã‚’ç”Ÿæˆ
            response = await generate_response_with_context(
                message, formatted_results, context, intent_info
            )
            
            # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
            record_usage(user_id, len(response))
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜
            source_document = None
            source_page = None
            if search_results and isinstance(search_results, list) and len(search_results) > 0:
                first_result = search_results[0]
                if 'metadata' in first_result:
                    source_document = first_result['metadata'].get('source_document')
                    source_page = first_result['metadata'].get('source_page')

            safe_print(f"[PROCESS] Saving RAG chat history for user {user_id}. Source: {source_document}, Page: {source_page}")
            
            # company_idã‚’å–å¾—
            company_id = None
            if user_id != "anonymous":
                user_data_result = select_data("users", filters={"id": user_id}, columns="company_id")
                if user_data_result and user_data_result.data:
                    company_id = user_data_result.data[0].get("company_id")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆRAGæ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§1å›ï¼‰
            from modules.token_counter import TokenCounter
            counter = TokenCounter()
            prompt_refs = 1  # RAGæ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸã®ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§1å›
            cost_result = counter.calculate_cost_by_company(message, response, company_id, prompt_refs)
            
            await save_chat_history(
                user_id, message, response,
                category=intent_info.get('category'),
                source_document=source_document,
                source_page=source_page,
                company_id=company_id,
                input_tokens=cost_result.get("input_tokens", 0),
                output_tokens=cost_result.get("output_tokens", 0),
                cost_usd=cost_result.get("total_cost_usd", 0.0)
            )
            
            return {
                'response': response,
                'intent': intent_info,
                'search_results': search_results,
                'processing_type': 'rag_search',
                'search_query': search_query
            }
        
        # ãã®ä»–ã®å ´åˆï¼ˆåŸºæœ¬çš„ãªå¿œç­”ï¼‰
        response = await generate_basic_response(message, intent_info)
        
        # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        record_usage(user_id, len(response))
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜
        safe_print(f"[PROCESS] Saving basic chat history for user {user_id}")
        
        # company_idã‚’å–å¾—
        company_id = None
        if user_id != "anonymous":
            user_data_result = select_data("users", filters={"id": user_id}, columns="company_id")
            if user_data_result and user_data_result.data:
                company_id = user_data_result.data[0].get("company_id")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆRAGå‡¦ç†ã®å ´åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§1å›ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼‰
        from modules.token_counter import TokenCounter
        counter = TokenCounter()
        prompt_refs = 1  # RAGæ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸã®ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‚ç…§1å›
        cost_result = counter.calculate_cost_by_company(message, response, company_id, prompt_refs)
        
        await save_chat_history(user_id, message, response, 
                              category=intent_info.get('category'),
                              company_id=company_id,
                              input_tokens=cost_result.get("input_tokens", 0),
                              output_tokens=cost_result.get("output_tokens", 0),
                              cost_usd=cost_result.get("total_cost_usd", 0.0))
        
        return {
            'response': response,
            'intent': intent_info,
            'search_results': [],
            'processing_type': 'basic'
        }
        
    except HTTPException:
        raise
    except Exception as e:
        safe_print(f"Error processing chat message: {e}")
        raise HTTPException(status_code=500, detail=f"ãƒãƒ£ãƒƒãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

async def generate_response_with_context(
    message: str, 
    search_results: str, 
    conversation_context: str = "",
    intent_info: Dict[str, Any] = None
) -> str:
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
    
    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        search_results: æ¤œç´¢çµæœ
        conversation_context: ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        intent_info: æ„å›³æƒ…å ±
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
    """
    try:
        if not model:
            raise Exception("Gemini model is not available")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = build_response_prompt(message, search_results, conversation_context, intent_info)
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
        if CONTEXT_CACHING_ENABLED and len(search_results) > 1000:
            safe_print("Using context caching for large search results")
            # ã“ã“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…ã‚’è¿½åŠ å¯èƒ½
        
        # å¿œç­”ã‚’ç”Ÿæˆ
        response = model.generate_content(prompt)
        
        if response and response.text:
            generated_response = response.text.strip()
            safe_print(f"Generated response length: {len(generated_response)}")
            return generated_response
        else:
            raise Exception("No response generated from model")
            
    except Exception as e:
        safe_print(f"Error generating response with context: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
        return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

async def generate_basic_response(message: str, intent_info: Dict[str, Any] = None) -> str:
    """
    åŸºæœ¬çš„ãªå¿œç­”ã‚’ç”Ÿæˆ
    
    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        intent_info: æ„å›³æƒ…å ±
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
    """
    try:
        if not model:
            raise Exception("Gemini model is not available")
        
        prompt = f"""
ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ã€è¦ªåˆ‡ã§æœ‰ç”¨ãªå¿œç­”ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
å…·ä½“çš„ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€ä¸€èˆ¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}

å¿œç­”:"""
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text.strip()
        else:
            raise Exception("No response generated from model")
            
    except Exception as e:
        safe_print(f"Error generating basic response: {e}")
        return "ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã‚‹ã¨ã€ã‚ˆã‚Šè©³ã—ããŠç­”ãˆã§ãã¾ã™ã€‚"

def build_response_prompt(
    message: str, 
    search_results: str, 
    conversation_context: str = "",
    intent_info: Dict[str, Any] = None,
    company_id: str = None
) -> str:
    """
    å¿œç­”ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    
    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        search_results: æ¤œç´¢çµæœ
        conversation_context: ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        intent_info: æ„å›³æƒ…å ±
        company_id: ä¼šç¤¾IDï¼ˆç‰¹åˆ¥æŒ‡ç¤ºå–å¾—ç”¨ï¼‰
        
    Returns:
        æ§‹ç¯‰ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    prompt_parts = []
    
    # ğŸ¯ ç‰¹åˆ¥æŒ‡ç¤ºã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€ç•ªå‰ã«é…ç½®
    special_instructions_text = ""
    if company_id:
        try:
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªã‚½ãƒ¼ã‚¹ã®ç‰¹åˆ¥æŒ‡ç¤ºã‚’å–å¾—
            special_result = select_data(
                "document_sources", 
                columns="name,special", 
                filters={
                    "company_id": company_id,
                    "active": True
                }
            )
            
            if special_result.data:
                special_instructions = []
                for i, resource in enumerate(special_result.data, 1):
                    special_instruction = resource.get('special')
                    if special_instruction and special_instruction.strip():
                        resource_name = resource.get('name', 'Unknown')
                        special_instructions.append(f"{i}. ã€{resource_name}ã€‘: {special_instruction.strip()}")
                
                if special_instructions:
                    special_instructions_text = "ç‰¹åˆ¥ãªå›ç­”æŒ‡ç¤ºï¼ˆä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã™ã‚‹éš›ã¯ã€å„ãƒªã‚½ãƒ¼ã‚¹ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãã ã•ã„ï¼‰ï¼š\n" + "\n".join(special_instructions) + "\n\n"
                    
        except Exception as e:
            safe_print(f"âš ï¸ ç‰¹åˆ¥æŒ‡ç¤ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ç‰¹åˆ¥æŒ‡ç¤º + ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰
    prompt_parts.append(f"""{special_instructions_text}ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æœ‰ç”¨ãªå›ç­”ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã®éš›ã¯ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
1. æ¤œç´¢çµæœã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã‚Œã‚’æ´»ç”¨ã—ã¦å›ç­”ã™ã‚‹
2. æ¤œç´¢çµæœã®æƒ…å ±ã‹ã‚‰æ¨æ¸¬ã§ãã‚‹ã“ã¨ã‚„ã€é–¢é€£ã™ã‚‹å†…å®¹ãŒã‚ã‚Œã°ç©æ¥µçš„ã«æä¾›ã™ã‚‹
3. å®Œå…¨ã«ä¸€è‡´ã™ã‚‹æƒ…å ±ãŒãªãã¦ã‚‚ã€éƒ¨åˆ†çš„ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒã‚ã‚Œã°æœ‰åŠ¹æ´»ç”¨ã™ã‚‹
4. è¦ªã—ã¿ã‚„ã™ãã€ç†è§£ã—ã‚„ã™ã„è¨€è‘‰ã§èª¬æ˜ã™ã‚‹
5. å¿…è¦ã«å¿œã˜ã¦ã€æ‰‹é †ã‚„ä¾‹ã‚’ç¤ºã™
6. é–¢é€£ã™ã‚‹URLãŒã‚ã‚‹å ´åˆã¯ã€å‚è€ƒã¨ã—ã¦æç¤ºã™ã‚‹
7. å…¨ãé–¢é€£æ€§ãŒãªã„å ´åˆã®ã¿ã€ãã®æ—¨ã‚’ä¸å¯§ã«èª¬æ˜ã™ã‚‹
8. æƒ…å ±ã®å‡ºå…¸ã¨ã—ã¦ã€Œãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚„ã€Œè³‡æ–™åã€ã¯æ˜ç¤ºå¯èƒ½ã§ã™ãŒã€æŠ€è¡“çš„ãªå†…éƒ¨æ§‹é€ æƒ…å ±ï¼ˆè¡Œç•ªå·ã€åˆ†å‰²ç•ªå·ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹IDãªã©ï¼‰ã¯å‡ºåŠ›ã—ãªã„
""")
    
    # ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    if conversation_context:
        prompt_parts.append(f"\nã€ä¼šè©±ã®æµã‚Œã€‘\n{conversation_context}\n")
    
    # æ¤œç´¢çµæœ
    if search_results:
        prompt_parts.append(f"\nã€å‚è€ƒæƒ…å ±ã€‘\n{search_results}\n")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    prompt_parts.append(f"\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{message}\n")
    
    # æ„å›³ã«å¿œã˜ãŸæŒ‡ç¤º
    if intent_info:
        intent_type = intent_info.get('intent_type', '')
        if intent_type == 'technical_question':
            prompt_parts.append("\næŠ€è¡“çš„ãªè³ªå•ã®ãŸã‚ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚")
        elif intent_type == 'instruction_request':
            prompt_parts.append("\næ‰‹é †ã‚„æ–¹æ³•ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚")
    
    prompt_parts.append("\nã€å›ç­”ã€‘")
    
    return ''.join(prompt_parts)

def get_usage_stats(user_id: str) -> Dict[str, Any]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½¿ç”¨çµ±è¨ˆã‚’å–å¾—
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        
    Returns:
        ä½¿ç”¨çµ±è¨ˆ
    """
    try:
        cursor = get_db_cursor()
        if not cursor:
            return {'error': 'Database not available'}
        
        # ä»Šæ—¥ã®ä½¿ç”¨é‡
        cursor.execute("""
            SELECT COUNT(*), COALESCE(SUM(tokens_used), 0)
            FROM usage_logs 
            WHERE user_id = %s AND DATE(timestamp) = CURRENT_DATE
        """, (user_id,))
        
        today_count, today_tokens = cursor.fetchone() or (0, 0)
        
        # ä»Šæœˆã®ä½¿ç”¨é‡
        cursor.execute("""
            SELECT COUNT(*), COALESCE(SUM(tokens_used), 0)
            FROM usage_logs 
            WHERE user_id = %s AND DATE_TRUNC('month', timestamp) = DATE_TRUNC('month', CURRENT_DATE)
        """, (user_id,))
        
        month_count, month_tokens = cursor.fetchone() or (0, 0)
        
        # ç¾åœ¨ã®æ™‚é–“åˆ¶é™çŠ¶æ³
        current_hour_usage = len(usage_tracker.get(user_id, []))
        
        return {
            'today': {
                'requests': today_count,
                'tokens': today_tokens
            },
            'month': {
                'requests': month_count,
                'tokens': month_tokens
            },
            'current_hour': {
                'requests': current_hour_usage,
                'limit': USAGE_LIMIT_PER_HOUR,
                'remaining': max(0, USAGE_LIMIT_PER_HOUR - current_hour_usage)
            }
        }
        
    except Exception as e:
        safe_print(f"Error getting usage stats: {e}")
        return {'error': str(e)}