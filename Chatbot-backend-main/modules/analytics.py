"""
åˆ†æãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
queue@queueu-tech.jpç”¨ã®åˆ©ç”¨çŠ¶æ³åˆ†æã‚’æä¾›
"""

from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional
from supabase_adapter import select_data, execute_query
import json

# å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å¤‰æ›é–¢æ•°
def safe_int(value, default=0):
    """å®‰å…¨ã«intã«å¤‰æ›ã™ã‚‹"""
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return int(value)
    if isinstance(value, str):
        try:
            return int(value)
        except ValueError:
            return default
    if isinstance(value, dict):
        # Supabaseã‹ã‚‰è¾æ›¸å½¢å¼ã§è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if 'value' in value:
            return safe_int(value['value'], default)
        if len(value) == 1:
            return safe_int(list(value.values())[0], default)
    return default

def safe_float(value, default=0.0):
    """å®‰å…¨ã«floatã«å¤‰æ›ã™ã‚‹"""
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        try:
            return float(value)
        except ValueError:
            return default
    if isinstance(value, dict):
        # Supabaseã‹ã‚‰è¾æ›¸å½¢å¼ã§è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if 'value' in value:
            return safe_float(value['value'], default)
        if len(value) == 1:
            return safe_float(list(value.values())[0], default)
    return default

def safe_str(value, default=""):
    """å®‰å…¨ã«strã«å¤‰æ›ã™ã‚‹"""
    if value is None:
        return default
    if isinstance(value, str):
        return value
    if isinstance(value, dict):
        # Supabaseã‹ã‚‰è¾æ›¸å½¢å¼ã§è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if 'value' in value:
            return safe_str(value['value'], default)
        if len(value) == 1:
            return safe_str(list(value.values())[0], default)
    return str(value)

def get_usage_analytics(db) -> Dict[str, Any]:
    """
    queue@queueu-tech.jpç”¨ã®åˆ©ç”¨çŠ¶æ³åˆ†æã‚’å–å¾—
    
    Returns:
        Dict containing:
        - company_usage_periods: ä¼šç¤¾å˜ä½ã®ç´¯è¨ˆåˆ©ç”¨æœŸé–“
        - user_usage_periods: ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã®ç´¯è¨ˆåˆ©ç”¨æœŸé–“
        - active_users: éå»1é€±é–“ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼
        - plan_continuity: ãƒ—ãƒ©ãƒ³ç¶™ç¶šæ•°ã®åˆ†æ
    """
    try:
        analytics = {
            "company_usage_periods": get_company_usage_periods(db),
            "user_usage_periods": get_user_usage_periods(db),
            "active_users": get_active_users(db),
            "plan_continuity": get_plan_continuity_analysis(db)
        }
        return analytics
    except Exception as e:
        print(f"åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

def get_company_usage_periods(db) -> List[Dict[str, Any]]:
    """ä¼šç¤¾å˜ä½ã®ç´¯è¨ˆåˆ©ç”¨æœŸé–“ã‚’è¨ˆç®—"""
    try:
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼šç¤¾æƒ…å ±ã‚’å–å¾—
        users_result = select_data("users", columns="id,email,company_id,created_at")
        if not users_result or not users_result.data:
            return []
        
        # å…¨ä¼šç¤¾æƒ…å ±ã‚’å–å¾—
        companies_result = select_data("companies", columns="id,name")
        company_name_map = {}
        if companies_result and companies_result.data:
            for company in companies_result.data:
                company_name_map[company["id"]] = company["name"]
        
        # ä¼šç¤¾ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        companies = {}
        for user in users_result.data:
            company_id = user.get("company_id")
            company_name = company_name_map.get(company_id) or "ä¸æ˜ãªä¼šç¤¾"
            if company_name not in companies:
                companies[company_name] = {
                    "company_name": company_name,
                    "users": [],
                    "total_usage_days": 0,
                    "earliest_start": None
                }
            companies[company_name]["users"].append(user)
        
        # å„ä¼šç¤¾ã®åˆ©ç”¨æœŸé–“ã‚’è¨ˆç®—
        company_analytics = []
        for company_name, company_data in companies.items():
            # æœ€ã‚‚æ—©ã„é–‹å§‹æ—¥ã‚’å–å¾—
            earliest_dates = [user.get("created_at") for user in company_data["users"] if user.get("created_at")]
            if earliest_dates:
                earliest_start = min(earliest_dates)
                start_date = datetime.fromisoformat(earliest_start.replace('Z', '+00:00'))
                usage_days = (datetime.now() - start_date).days
                
                company_analytics.append({
                    "company_name": company_name,
                    "user_count": len(company_data["users"]),
                    "usage_days": usage_days,
                    "start_date": earliest_start,
                    "usage_months": round(usage_days / 30.44, 1)  # å¹³å‡æœˆæ—¥æ•°
                })
        
        return sorted(company_analytics, key=lambda x: x["usage_days"], reverse=True)
    
    except Exception as e:
        print(f"ä¼šç¤¾åˆ¥åˆ©ç”¨æœŸé–“è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def get_user_usage_periods(db) -> List[Dict[str, Any]]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã®ç´¯è¨ˆåˆ©ç”¨æœŸé–“ã‚’è¨ˆç®—"""
    try:
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
        users_result = select_data("users", columns="id,email,name,company_id,created_at")
        if not users_result or not users_result.data:
            return []
        
        # å…¨ä¼šç¤¾æƒ…å ±ã‚’å–å¾—
        companies_result = select_data("companies", columns="id,name")
        company_name_map = {}
        if companies_result and companies_result.data:
            for company in companies_result.data:
                company_name_map[company["id"]] = company["name"]
        
        user_analytics = []
        for user in users_result.data:
            if user.get("created_at"):
                start_date = datetime.fromisoformat(user["created_at"].replace('Z', '+00:00'))
                usage_days = (datetime.now() - start_date).days
                company_id = user.get("company_id")
                company_name = company_name_map.get(company_id) or "ä¸æ˜ãªä¼šç¤¾"
                
                user_analytics.append({
                    "user_id": user["id"],
                    "email": user["email"],
                    "name": user.get("name", ""),
                    "company_name": company_name,
                    "usage_days": usage_days,
                    "start_date": user["created_at"],
                    "usage_months": round(usage_days / 30.44, 1)
                })
        
        return sorted(user_analytics, key=lambda x: x["usage_days"], reverse=True)
    
    except Exception as e:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥åˆ©ç”¨æœŸé–“è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def get_active_users(db) -> Dict[str, Any]:
    """éå»1é€±é–“ä»¥å†…ã«ãƒãƒ£ãƒƒãƒˆã‚’è¡Œã£ãŸã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¨ˆç®—"""
    try:
        # 1é€±é–“å‰ã®æ—¥æ™‚ã‚’è¨ˆç®—
        one_week_ago = datetime.now() - timedelta(days=7)
        one_week_ago_str = one_week_ago.isoformat()
        
        # éå»1é€±é–“ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—
        chat_result = select_data(
            "chat_history", 
            columns="employee_id,employee_name,timestamp",
            filters={"timestamp": f"gte.{one_week_ago_str}"}
        )
        
        if not chat_result or not chat_result.data:
            return {
                "total_active_users": 0,
                "active_users_by_company": {},
                "active_users_list": []
            }
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é›†è¨ˆ
        active_users = {}
        for chat in chat_result.data:
            user_id = chat.get("employee_id")
            if user_id and user_id not in active_users:
                active_users[user_id] = {
                    "user_id": user_id,
                    "name": chat.get("employee_name", ""),
                    "last_chat": chat.get("timestamp"),
                    "chat_count": 0
                }
            if user_id:
                active_users[user_id]["chat_count"] += 1
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¦ä¼šç¤¾åˆ¥ã«åˆ†é¡
        users_result = select_data("users", columns="id,email,company_id")
        companies_result = select_data("companies", columns="id,name")
        company_name_map = {}
        if companies_result and companies_result.data:
            for company in companies_result.data:
                company_name_map[company["id"]] = company["name"]
        
        user_company_map = {}
        if users_result and users_result.data:
            for user in users_result.data:
                company_id = user.get("company_id")
                company_name = company_name_map.get(company_id) or "ä¸æ˜ãªä¼šç¤¾"
                user_company_map[user["id"]] = company_name
        
        # ä¼šç¤¾åˆ¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’è¨ˆç®—
        active_by_company = {}
        active_users_list = []
        
        for user_id, user_data in active_users.items():
            company = user_company_map.get(user_id, "ä¸æ˜")
            if company not in active_by_company:
                active_by_company[company] = 0
            active_by_company[company] += 1
            
            user_data["company_name"] = company
            active_users_list.append(user_data)
        
        return {
            "total_active_users": len(active_users),
            "active_users_by_company": active_by_company,
            "active_users_list": sorted(active_users_list, key=lambda x: x["chat_count"], reverse=True),
            "analysis_period": f"{one_week_ago.strftime('%Y-%m-%d')} ã‹ã‚‰ {datetime.now().strftime('%Y-%m-%d')}"
        }
    
    except Exception as e:
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            "total_active_users": 0,
            "active_users_by_company": {},
            "active_users_list": []
        }

def get_plan_continuity_analysis(db) -> Dict[str, Any]:
    """ãƒ—ãƒ©ãƒ³ç¶™ç¶šæ•°ã®åˆ†æ"""
    try:
        # ãƒ—ãƒ©ãƒ³å±¥æ­´ã‚’å–å¾—
        from modules.database import get_plan_history
        user_histories = get_plan_history(db=db)
        
        if not user_histories:
            return {
                "total_users": 0,
                "continuity_stats": {},
                "plan_retention": {}
            }
        
        continuity_stats = {
            "never_changed": 0,  # ä¸€åº¦ã‚‚å¤‰æ›´ã—ã¦ã„ãªã„
            "changed_once": 0,   # 1å›å¤‰æ›´
            "changed_multiple": 0,  # è¤‡æ•°å›å¤‰æ›´
            "demo_to_prod_stayed": 0,  # ãƒ‡ãƒ¢â†’æœ¬ç•ªã§ç¶™ç¶š
            "prod_to_demo_returned": 0  # æœ¬ç•ªâ†’ãƒ‡ãƒ¢ã«æˆ»ã£ãŸ
        }
        
        plan_retention = {
            "demo_users": 0,
            "production_users": 0,
            "demo_avg_duration": 0,
            "production_avg_duration": 0
        }
        
        demo_durations = []
        prod_durations = []
        
        for user in user_histories:
            total_changes = user.get("total_changes", 0)
            current_plan = user.get("current_plan", "")
            changes = user.get("changes", [])
            
            # ç¶™ç¶šæ€§çµ±è¨ˆ
            if total_changes == 0:
                continuity_stats["never_changed"] += 1
            elif total_changes == 1:
                continuity_stats["changed_once"] += 1
            else:
                continuity_stats["changed_multiple"] += 1
            
            # ãƒ—ãƒ©ãƒ³ä¿æŒçµ±è¨ˆ
            if current_plan == "demo":
                plan_retention["demo_users"] += 1
            elif current_plan == "production":
                plan_retention["production_users"] += 1
            
            # æœŸé–“åˆ†æ
            for change in changes:
                duration = change.get("duration_days")
                if duration:
                    if change.get("from_plan") == "demo":
                        demo_durations.append(duration)
                    elif change.get("from_plan") == "production":
                        prod_durations.append(duration)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            if len(changes) >= 1:
                first_change = changes[-1]  # æœ€åˆã®å¤‰æ›´ï¼ˆé…åˆ—ã¯æ–°ã—ã„é †ï¼‰
                if first_change.get("from_plan") == "demo" and first_change.get("to_plan") == "production":
                    # ãƒ‡ãƒ¢ã‹ã‚‰æœ¬ç•ªã«å¤‰æ›´ã—ã€ç¾åœ¨ã‚‚æœ¬ç•ªãªã‚‰ç¶™ç¶š
                    if current_plan == "production":
                        continuity_stats["demo_to_prod_stayed"] += 1
                elif first_change.get("from_plan") == "production" and first_change.get("to_plan") == "demo":
                    continuity_stats["prod_to_demo_returned"] += 1
        
        # å¹³å‡æœŸé–“è¨ˆç®—
        if demo_durations:
            plan_retention["demo_avg_duration"] = sum(demo_durations) / len(demo_durations)
        if prod_durations:
            plan_retention["production_avg_duration"] = sum(prod_durations) / len(prod_durations)
        
        return {
            "total_users": len(user_histories),
            "continuity_stats": continuity_stats,
            "plan_retention": plan_retention,
            "duration_analysis": {
                "demo_duration_samples": len(demo_durations),
                "production_duration_samples": len(prod_durations)
            }
        }
    
    except Exception as e:
        print(f"ãƒ—ãƒ©ãƒ³ç¶™ç¶šæ€§åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            "total_users": 0,
            "continuity_stats": {},
            "plan_retention": {}
        }

def get_enhanced_analytics(db, company_id: str = None) -> Dict[str, Any]:
    """
    å¼·åŒ–ã•ã‚ŒãŸåˆ†ææ©Ÿèƒ½ã‚’å–å¾—ï¼ˆsumry.mdã®è¦æ±‚é …ç›®ã«å¯¾å¿œï¼‰
    
    Args:
        db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        company_id: ä¼šç¤¾IDã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    
    Returns:
        Dict containing:
        - resource_reference_count: è³‡æ–™ã®å‚ç…§å›æ•°
        - category_distribution_analysis: è³ªå•ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã¨åã‚Š
        - active_user_trends: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨ç§»
        - unresolved_and_repeat_analysis: æœªè§£æ±ºãƒ»å†è³ªå•ã®å‚¾å‘åˆ†æ
        - sentiment_analysis: æ„Ÿæƒ…åˆ†æ
    """
    try:
        analytics = {
            "resource_reference_count": get_resource_reference_analysis(db, company_id),
            "category_distribution_analysis": get_category_distribution_analysis(db, company_id),
            "active_user_trends": get_active_user_trends(db, company_id),
            "unresolved_and_repeat_analysis": get_unresolved_repeat_analysis(db, company_id),
            "sentiment_analysis": get_detailed_sentiment_analysis(db, company_id),
            "analysis_metadata": {
                "generated_at": datetime.now().isoformat(),
                "analysis_type": "enhanced",
                "company_id": company_id
            }
        }
        return analytics
    except Exception as e:
        print(f"å¼·åŒ–åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

def get_resource_reference_analysis(db, company_id: str = None) -> Dict[str, Any]:
    """è³‡æ–™å‚ç…§å›æ•°åˆ†æï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        # chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="source_document, employee_id, timestamp, sentiment", 
                                 filters=chat_filters)
        
        if not chat_result or not chat_result.data:
            return {
                "resources": [],
                "total_references": 0,
                "most_referenced": None,
                "least_referenced": None,
                "summary": "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            }
        
        # document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰è³‡æ–™æƒ…å ±ã‚’å–å¾—
        doc_filters = {}
        if company_id:
            doc_filters["company_id"] = company_id
        
        doc_result = select_data("document_sources", 
                                columns="name, type, id",
                                filters=doc_filters)
        
        # è³‡æ–™åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        doc_mapping = {}
        if doc_result and doc_result.data:
            for doc in doc_result.data:
                doc_mapping[doc.get("name", "")] = {
                    "name": safe_str(doc.get("name", "ä¸æ˜")),
                    "type": safe_str(doc.get("type", "ä¸æ˜"))
                }
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰å‚ç…§å›æ•°ã‚’é›†è¨ˆ
        resource_stats = {}
        for chat in chat_result.data:
            source_doc = safe_str(chat.get("source_document", ""))
            if source_doc and source_doc != "" and source_doc != "None":
                if source_doc not in resource_stats:
                    doc_info = doc_mapping.get(source_doc, {"name": source_doc, "type": "ä¸æ˜"})
                    resource_stats[source_doc] = {
                        "name": doc_info["name"],
                        "type": doc_info["type"],
                        "reference_count": 0,
                        "unique_users": set(),
                        "unique_days": set(),
                        "last_referenced": None,
                        "sentiments": []
                    }
                
                resource_stats[source_doc]["reference_count"] += 1
                
                employee_id = safe_str(chat.get("employee_id", ""))
                if employee_id:
                    resource_stats[source_doc]["unique_users"].add(employee_id)
                
                timestamp = safe_str(chat.get("timestamp", ""))
                if timestamp:
                    date_part = timestamp.split(" ")[0] if " " in timestamp else timestamp.split("T")[0]
                    resource_stats[source_doc]["unique_days"].add(date_part)
                    resource_stats[source_doc]["last_referenced"] = timestamp
                
                sentiment = safe_str(chat.get("sentiment", "neutral"))
                resource_stats[source_doc]["sentiments"].append(sentiment)
        
        # çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        resources = []
        for source_doc, stats in resource_stats.items():
            # å¹³å‡æº€è¶³åº¦ã‚’è¨ˆç®—ï¼ˆsentiment basedï¼‰
            sentiments = stats["sentiments"]
            sentiment_score = 2.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            if sentiments:
                positive_count = sentiments.count("positive")
                neutral_count = sentiments.count("neutral") 
                negative_count = sentiments.count("negative")
                total_sentiments = len(sentiments)
                if total_sentiments > 0:
                    sentiment_score = (positive_count * 3 + neutral_count * 2 + negative_count * 1) / total_sentiments
            
            unique_users_count = len(stats["unique_users"])
            
            resources.append({
                "name": stats["name"],
                "type": stats["type"],
                "reference_count": stats["reference_count"],
                "unique_users": unique_users_count,
                "unique_days": len(stats["unique_days"]),
                "last_referenced": stats["last_referenced"],
                "avg_satisfaction": round(sentiment_score, 2),
                "usage_intensity": round(stats["reference_count"] / max(unique_users_count, 1), 2)
            })
        
        # å‚ç…§å›æ•°ã§é™é †ã‚½ãƒ¼ãƒˆ
        resources.sort(key=lambda x: x["reference_count"], reverse=True)
        
        total_references = sum(r["reference_count"] for r in resources)
        most_referenced = resources[0] if resources else None
        least_referenced = resources[-1] if resources else None
        
        return {
            "resources": resources,
            "total_references": total_references,
            "most_referenced": most_referenced,
            "least_referenced": least_referenced,
            "active_resources": len(resources),
            "summary": f"åˆè¨ˆ{total_references}å›ã®è³‡æ–™å‚ç…§ãŒã‚ã‚Šã€{len(resources)}å€‹ã®ãƒªã‚½ãƒ¼ã‚¹ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™"
        }
        
    except Exception as e:
        print(f"è³‡æ–™å‚ç…§åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            "resources": [],
            "total_references": 0,
            "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def get_category_distribution_analysis(db, company_id: str = None) -> Dict[str, Any]:
    """è³ªå•ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã¨åã‚Šåˆ†æï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        # chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªé–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="category, employee_id, timestamp, sentiment", 
                                 filters=chat_filters)
        
        if not chat_result or not chat_result.data:
            return {
                "categories": [],
                "distribution": {},
                "bias_analysis": {},
                "summary": "ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã‚’é›†è¨ˆ
        category_stats = {}
        total_questions = 0
        
        for chat in chat_result.data:
            category = safe_str(chat.get("category", "")).strip()
            if not category or category == "None":
                category = "æœªåˆ†é¡"
            
            if category not in category_stats:
                category_stats[category] = {
                    "category": category,
                    "count": 0,
                    "unique_users": set(),
                    "unique_days": set(),
                    "sentiments": []
                }
            
            category_stats[category]["count"] += 1
            total_questions += 1
            
            employee_id = safe_str(chat.get("employee_id", ""))
            if employee_id:
                category_stats[category]["unique_users"].add(employee_id)
            
            timestamp = safe_str(chat.get("timestamp", ""))
            if timestamp:
                date_part = timestamp.split(" ")[0] if " " in timestamp else timestamp.split("T")[0]
                category_stats[category]["unique_days"].add(date_part)
            
            sentiment = safe_str(chat.get("sentiment", "neutral"))
            category_stats[category]["sentiments"].append(sentiment)
        
        # ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆã‚’ä½œæˆ
        categories = []
        for category, stats in category_stats.items():
            sentiments = stats["sentiments"]
            
            # æ„Ÿæƒ…åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            positive_count = sentiments.count("positive")
            neutral_count = sentiments.count("neutral")
            negative_count = sentiments.count("negative")
            
            # å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢è¨ˆç®—
            if sentiments:
                avg_sentiment_score = (positive_count * 3 + neutral_count * 2 + negative_count * 1) / len(sentiments)
            else:
                avg_sentiment_score = 2.0
            
            categories.append({
                "category": category,
                "count": stats["count"],
                "unique_users": len(stats["unique_users"]),
                "unique_days": len(stats["unique_days"]),
                "avg_sentiment_score": round(avg_sentiment_score, 2),
                "positive_count": positive_count,
                "neutral_count": neutral_count,
                "negative_count": negative_count
            })
        
        # ã‚«ã‚¦ãƒ³ãƒˆé †ã§ã‚½ãƒ¼ãƒˆ
        categories.sort(key=lambda x: x["count"], reverse=True)
        
        # åˆ†å¸ƒã¨ãƒã‚¤ã‚¢ã‚¹åˆ†æ
        distribution = {}
        bias_analysis = {}
        
        for cat in categories:
            percentage = round((cat["count"] / total_questions) * 100, 2) if total_questions > 0 else 0
            distribution[cat["category"]] = {
                "count": cat["count"],
                "percentage": percentage
            }
            
            # ãƒã‚¤ã‚¢ã‚¹åˆ†æï¼ˆæœŸå¾…å€¤ã‹ã‚‰ã®åå·®ï¼‰
            expected_percentage = 100 / len(categories) if categories else 0
            bias = percentage - expected_percentage
            
            bias_analysis[cat["category"]] = {
                "bias_score": round(bias, 2),
                "is_over_represented": bias > 10,
                "is_under_represented": bias < -10,
                "sentiment_bias": "positive" if cat["avg_sentiment_score"] > 2.3 else "negative" if cat["avg_sentiment_score"] < 1.7 else "neutral"
            }
        
        # ãƒˆãƒƒãƒ—3ã¨ãƒœãƒˆãƒ 3ã‚’ç‰¹å®š
        top_categories = categories[:3]
        bottom_categories = categories[-3:] if len(categories) > 3 else []
        
        return {
            "categories": categories,
            "distribution": distribution,
            "bias_analysis": bias_analysis,
            "top_categories": top_categories,
            "bottom_categories": bottom_categories,
            "total_questions": total_questions,
            "category_diversity": len(categories),
            "summary": f"åˆè¨ˆ{len(categories)}ã‚«ãƒ†ã‚´ãƒªã§{total_questions}ä»¶ã®è³ªå•ãŒã‚ã‚Šã€æœ€ã‚‚å¤šã„ã®ã¯'{top_categories[0]['category']}'({top_categories[0]['count']}ä»¶)ã§ã™" if top_categories else "ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
        }
        
    except Exception as e:
        print(f"ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            "categories": [],
            "distribution": {},
            "bias_analysis": {},
            "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def get_active_user_trends(db, company_id: str = None, days: int = 30) -> Dict[str, Any]:
    """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨ç§»åˆ†æï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        from datetime import datetime, timedelta
        
        # éå»æŒ‡å®šæ—¥æ•°åˆ†ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="employee_id, employee_name, timestamp, sentiment", 
                                 filters=chat_filters)
        
        if not chat_result or not chat_result.data:
            return {
                "daily_trends": [],
                "weekly_trends": [],
                "summary": "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            }
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        start_date = datetime.now() - timedelta(days=days)
        filtered_chats = []
        
        for chat in chat_result.data:
            timestamp_str = safe_str(chat.get("timestamp", ""))
            if timestamp_str:
                try:
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
                    if "T" in timestamp_str:
                        chat_date = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')).replace(tzinfo=None)
                    else:
                        chat_date = datetime.strptime(timestamp_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
                    
                    if chat_date >= start_date:
                        filtered_chats.append({
                            "employee_id": safe_str(chat.get("employee_id", "")),
                            "employee_name": safe_str(chat.get("employee_name", "")),
                            "date": chat_date.date(),
                            "sentiment": safe_str(chat.get("sentiment", "neutral"))
                        })
                except:
                    continue  # ãƒ‘ãƒ¼ã‚¹ã§ããªã„æ—¥ä»˜ã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # æ—¥åˆ¥çµ±è¨ˆã‚’é›†è¨ˆ
        daily_stats = {}
        for chat in filtered_chats:
            date_str = chat["date"].strftime('%Y-%m-%d')
            
            if date_str not in daily_stats:
                daily_stats[date_str] = {
                    "date": date_str,
                    "active_users": set(),
                    "unique_names": set(),
                    "total_messages": 0,
                    "positive_count": 0
                }
            
            daily_stats[date_str]["active_users"].add(chat["employee_id"])
            daily_stats[date_str]["unique_names"].add(chat["employee_name"])
            daily_stats[date_str]["total_messages"] += 1
            
            if chat["sentiment"] == "positive":
                daily_stats[date_str]["positive_count"] += 1
        
        # æ—¥æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        daily_trends = []
        for date_str, stats in sorted(daily_stats.items()):
            positive_ratio = round(stats["positive_count"] / stats["total_messages"], 2) if stats["total_messages"] > 0 else 0
            
            daily_trends.append({
                "date": date_str,
                "active_users": len(stats["active_users"]),
                "total_messages": stats["total_messages"],
                "unique_names": len(stats["unique_names"]),
                "positive_ratio": positive_ratio
            })
        
        # é€±æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        weekly_trends = []
        if daily_trends:
            for i in range(0, len(daily_trends), 7):
                week_data = daily_trends[i:i+7]
                if week_data:
                    week_start = week_data[0]["date"]
                    week_end = week_data[-1]["date"]
                    total_active = sum(d["active_users"] for d in week_data)
                    avg_active = round(total_active / len(week_data), 1)
                    total_messages = sum(d["total_messages"] for d in week_data)
                    
                    weekly_trends.append({
                        "week_start": week_start,
                        "week_end": week_end,
                        "avg_active_users": avg_active,
                        "total_messages": total_messages,
                        "days_with_activity": len([d for d in week_data if d["active_users"] > 0])
                    })
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trend_direction = "insufficient_data"
        trend_percentage = 0
        
        if len(daily_trends) >= 7:
            recent_week = daily_trends[-7:]
            previous_week = daily_trends[-14:-7] if len(daily_trends) >= 14 else []
            
            recent_avg = sum(d["active_users"] for d in recent_week) / len(recent_week)
            previous_avg = sum(d["active_users"] for d in previous_week) / len(previous_week) if previous_week else recent_avg
            
            trend_direction = "increasing" if recent_avg > previous_avg else "decreasing" if recent_avg < previous_avg else "stable"
            trend_percentage = round(((recent_avg - previous_avg) / previous_avg * 100), 2) if previous_avg > 0 else 0
        
        return {
            "daily_trends": daily_trends,
            "weekly_trends": weekly_trends,
            "trend_analysis": {
                "direction": trend_direction,
                "percentage_change": trend_percentage,
                "period": f"éå»{days}æ—¥é–“"
            },
            "peak_day": max(daily_trends, key=lambda x: x["active_users"]) if daily_trends else None,
            "total_unique_users": len(set(d["active_users"] for d in daily_trends)) if daily_trends else 0,
            "summary": f"éå»{days}æ—¥é–“ã§æœ€å¤§{max(d['active_users'] for d in daily_trends) if daily_trends else 0}äºº/æ—¥ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¨˜éŒ²"
        }
        
    except Exception as e:
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨ç§»åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            "daily_trends": [],
            "weekly_trends": [],
            "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def get_unresolved_repeat_analysis(db, company_id: str = None) -> Dict[str, Any]:
    """æœªè§£æ±ºãƒ»å†è³ªå•ã®å‚¾å‘åˆ†æï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        # chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="employee_id, employee_name, user_message, bot_response, timestamp, sentiment, category", 
                                 filters=chat_filters)
        
        if not chat_result or not chat_result.data:
            return {
                "repeat_questions": [],
                "unresolved_patterns": [],
                "summary": "è³ªå•ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            }
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã®è³ªå•å±¥æ­´ã‚’æ§‹ç¯‰
        user_questions = {}
        for chat in chat_result.data:
            employee_id = safe_str(chat.get("employee_id", ""))
            if not employee_id or employee_id == "None":
                continue
                
            if employee_id not in user_questions:
                user_questions[employee_id] = []
            
            user_questions[employee_id].append({
                "message": safe_str(chat.get("user_message", "")),
                "response": safe_str(chat.get("bot_response", "")),
                "timestamp": safe_str(chat.get("timestamp", "")),
                "sentiment": safe_str(chat.get("sentiment", "neutral")),
                "category": safe_str(chat.get("category", "")),
                "response_length": len(safe_str(chat.get("bot_response", ""))),
                "employee_name": safe_str(chat.get("employee_name", ""))
            })
        
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
        for employee_id in user_questions:
            user_questions[employee_id].sort(key=lambda x: x["timestamp"])
        
        # å†è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        repeat_questions = []
        unresolved_patterns = []
        
        for employee_id, questions in user_questions.items():
            if len(questions) < 2:
                continue
            
            for i in range(len(questions) - 1):
                current = questions[i]
                next_q = questions[i + 1]
                
                # ç°¡æ˜“çš„ãªé¡ä¼¼æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
                current_words = set(current["message"].lower().split())
                next_words = set(next_q["message"].lower().split())
                
                if len(current_words) > 2 and len(next_words) > 2:
                    common_words = current_words.intersection(next_words)
                    similarity = len(common_words) / min(len(current_words), len(next_words))
                    
                    if similarity > 0.3:  # 30%ä»¥ä¸Šã®é¡ä¼¼æ€§
                        try:
                            from datetime import datetime
                            if "T" in current["timestamp"] and "T" in next_q["timestamp"]:
                                time1 = datetime.fromisoformat(current["timestamp"].replace('Z', '+00:00'))
                                time2 = datetime.fromisoformat(next_q["timestamp"].replace('Z', '+00:00'))
                                time_diff = time2 - time1
                            else:
                                time_diff = "ä¸æ˜"
                        except:
                            time_diff = "ä¸æ˜"
                        
                        repeat_questions.append({
                            "employee_id": employee_id,
                            "employee_name": current["employee_name"],
                            "first_question": current["message"][:100] + "..." if len(current["message"]) > 100 else current["message"],
                            "repeat_question": next_q["message"][:100] + "..." if len(next_q["message"]) > 100 else next_q["message"],
                            "time_between": str(time_diff),
                            "similarity_score": round(similarity, 2),
                            "first_sentiment": current["sentiment"],
                            "repeat_sentiment": next_q["sentiment"],
                            "category": current["category"]
                        })
                
                # æœªè§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆçŸ­ã„å›ç­”ï¼‹ãƒã‚¬ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ï¼‰
                if (current["response_length"] < 50 or 
                    current["sentiment"] == "negative" or
                    "ç”³ã—è¨³" in current["response"] or
                    "ã‚ã‹ã‚Šã¾ã›ã‚“" in current["response"]):
                    
                    unresolved_patterns.append({
                        "employee_id": employee_id,
                        "employee_name": current["employee_name"],
                        "question": current["message"][:100] + "..." if len(current["message"]) > 100 else current["message"],
                        "response": current["response"][:100] + "..." if len(current["response"]) > 100 else current["response"],
                        "timestamp": current["timestamp"],
                        "sentiment": current["sentiment"],
                        "category": current["category"],
                        "response_length": current["response_length"],
                        "issue_type": "short_response" if current["response_length"] < 50 else 
                                     "negative_sentiment" if current["sentiment"] == "negative" else
                                     "apologetic_response"
                    })
        
        # çµ±è¨ˆæƒ…å ±
        total_conversations = sum(len(questions) for questions in user_questions.values())
        repeat_rate = round((len(repeat_questions) / total_conversations * 100), 2) if total_conversations > 0 else 0
        unresolved_rate = round((len(unresolved_patterns) / total_conversations * 100), 2) if total_conversations > 0 else 0
        
        return {
            "repeat_questions": sorted(repeat_questions, key=lambda x: x["similarity_score"], reverse=True)[:20],
            "unresolved_patterns": sorted(unresolved_patterns, key=lambda x: x["timestamp"], reverse=True)[:20],
            "statistics": {
                "total_conversations": total_conversations,
                "repeat_questions_count": len(repeat_questions),
                "unresolved_patterns_count": len(unresolved_patterns),
                "repeat_rate": repeat_rate,
                "unresolved_rate": unresolved_rate
            },
            "summary": f"ç·ä¼šè©±{total_conversations}ä»¶ä¸­ã€å†è³ªå•{len(repeat_questions)}ä»¶({repeat_rate}%)ã€æœªè§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³{len(unresolved_patterns)}ä»¶({unresolved_rate}%)ã‚’æ¤œå‡º"
        }
        
    except Exception as e:
        print(f"æœªè§£æ±ºãƒ»å†è³ªå•åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            "repeat_questions": [],
            "unresolved_patterns": [],
            "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def get_detailed_sentiment_analysis(db, company_id: str = None) -> Dict[str, Any]:
    """è©³ç´°ãªæ„Ÿæƒ…åˆ†æï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        # chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="sentiment, category, employee_id, user_message, bot_response, timestamp", 
                                 filters=chat_filters)
        
        if not chat_result or not chat_result.data:
            return {
                "sentiment_distribution": {},
                "sentiment_by_category": {},
                "temporal_sentiment": [],
                "summary": "æ„Ÿæƒ…åˆ†æãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            }
        
        # æ„Ÿæƒ…åˆ†å¸ƒ
        sentiment_distribution = {}
        sentiment_by_category = {}
        temporal_sentiment = {}
        
        for chat in chat_result.data:
            sentiment = safe_str(chat.get("sentiment", "neutral"))
            category = safe_str(chat.get("category", "ãã®ä»–"))
            timestamp = safe_str(chat.get("timestamp", ""))
            
            # æ—¥ä»˜ã‚’æŠ½å‡º
            if timestamp:
                date = timestamp.split(" ")[0] if " " in timestamp else timestamp.split("T")[0]
            else:
                date = "ä¸æ˜"
            
            # å…¨ä½“ã®æ„Ÿæƒ…åˆ†å¸ƒ
            if sentiment not in sentiment_distribution:
                sentiment_distribution[sentiment] = 0
            sentiment_distribution[sentiment] += 1
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ„Ÿæƒ…åˆ†å¸ƒ
            if category not in sentiment_by_category:
                sentiment_by_category[category] = {}
            if sentiment not in sentiment_by_category[category]:
                sentiment_by_category[category][sentiment] = 0
            sentiment_by_category[category][sentiment] += 1
            
            # æ™‚ç³»åˆ—æ„Ÿæƒ…æ¨ç§»
            if date not in temporal_sentiment:
                temporal_sentiment[date] = {}
            if sentiment not in temporal_sentiment[date]:
                temporal_sentiment[date][sentiment] = 0
            temporal_sentiment[date][sentiment] += 1
        
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_responses = sum(sentiment_distribution.values())
        sentiment_score = 0
        if total_responses > 0:
            sentiment_score = (
                sentiment_distribution.get("positive", 0) * 1 +
                sentiment_distribution.get("neutral", 0) * 0.5 +
                sentiment_distribution.get("negative", 0) * 0
            ) / total_responses
        
        return {
            "sentiment_distribution": sentiment_distribution,
            "sentiment_by_category": sentiment_by_category,
            "temporal_sentiment": [
                {"date": date, "sentiments": sentiments}
                for date, sentiments in sorted(temporal_sentiment.items())
            ],
            "overall_sentiment_score": round(sentiment_score, 3),
            "total_responses": total_responses,
            "summary": f"ç·å›ç­”{total_responses}ä»¶ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {round(sentiment_score * 100, 1)}ç‚¹/100ç‚¹"
        }
        
    except Exception as e:
        print(f"è©³ç´°æ„Ÿæƒ…åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            "sentiment_distribution": {},
            "sentiment_by_category": {},
            "temporal_sentiment": [],
            "summary": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

async def generate_gemini_insights(analytics_data: Dict[str, Any], db, company_id: str = None) -> str:
    """Geminiã‚’ä½¿ç”¨ã—ã¦åˆ†æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿæˆï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰"""
    try:
        # Geminiè¨­å®šã‚’ç¢ºèª
        from modules.config import setup_gemini
        model = setup_gemini()
        
        if not model:
            return "Gemini APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬çš„ãªçµ±è¨ˆåˆ†æã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚"
        
        # å…¨ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ï¼ˆCRUDæ“ä½œã§å®Ÿè£…ï¼‰
        chat_filters = {}
        if company_id:
            chat_filters["company_id"] = company_id
        
        chat_result = select_data("chat_history", 
                                 columns="employee_name, user_message, bot_response, timestamp, sentiment, category, company_id",
                                 filters=chat_filters)
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
        chat_history_text = ""
        recent_patterns = []
        
        if chat_result and chat_result.data:
            # æœ€æ–°300ä»¶ã®è©³ç´°ãªã‚„ã‚Šå–ã‚Šã‚’åˆ†æç”¨ã«æ•´å½¢
            chat_data = chat_result.data
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„ã‚‚ã®ã‹ã‚‰ï¼‰
            chat_data.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            for i, chat in enumerate(chat_data[:300]):
                timestamp = safe_str(chat.get('timestamp', ''))
                employee_name = safe_str(chat.get('employee_name', 'åŒ¿å'))
                sentiment = safe_str(chat.get('sentiment', 'neutral'))
                user_message = safe_str(chat.get('user_message', ''))
                bot_response = safe_str(chat.get('bot_response', ''))
                category = safe_str(chat.get('category', 'ãªã—'))
                
                # è©³ç´°ãªãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
                recent_patterns.append({
                    'index': i + 1,
                    'employee': employee_name,
                    'sentiment': sentiment,
                    'question': user_message[:300],
                    'response': bot_response[:300],
                    'category': category,
                    'timestamp': timestamp[:10]  # æ—¥ä»˜ã®ã¿
                })
            
            # æ§‹é€ åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆ
            chat_history_text = "### æœ€æ–°ã®ã‚„ã‚Šå–ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæœ€æ–°300ä»¶ï¼‰\n\n"
            for pattern in recent_patterns[:50]:  # ä»£è¡¨çš„ãª50ä»¶ã‚’è©³ç´°è¡¨ç¤º
                chat_history_text += f"**{pattern['index']}. [{pattern['timestamp']}] {pattern['employee']} ({pattern['sentiment']})**\n"
                chat_history_text += f"è³ªå•: {pattern['question']}\n"
                chat_history_text += f"å›ç­”: {pattern['response']}\n"
                chat_history_text += f"ã‚«ãƒ†ã‚´ãƒª: {pattern['category']}\n\n"
        
        # è©³ç´°ã§å®Ÿç”¨çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = f"""
ã‚ãªãŸã¯ä¼æ¥­ã®AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆåˆ†æå°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰6ã¤ã®åˆ†æé …ç›®ã«åˆ†ã‘ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

# ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
- ç·ãƒãƒ£ãƒƒãƒˆå±¥æ­´æ•°: {len(chat_result.data) if chat_result and chat_result.data else 0}ä»¶
- ç·å‚ç…§å›æ•°: {analytics_data.get('resource_reference_count', {}).get('total_references', 0)}å›
- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒªã‚½ãƒ¼ã‚¹: {analytics_data.get('resource_reference_count', {}).get('active_resources', 0)}å€‹
- ç·è³ªå•æ•°: {analytics_data.get('category_distribution_analysis', {}).get('total_questions', 0)}ä»¶
- ã‚«ãƒ†ã‚´ãƒªæ•°: {analytics_data.get('category_distribution_analysis', {}).get('category_diversity', 0)}ç¨®é¡
- å†è³ªå•ç‡: {analytics_data.get('unresolved_and_repeat_analysis', {}).get('statistics', {}).get('repeat_rate', 0)}%
- æœªè§£æ±ºç‡: {analytics_data.get('unresolved_and_repeat_analysis', {}).get('statistics', {}).get('unresolved_rate', 0)}%
- æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {analytics_data.get('sentiment_analysis', {}).get('overall_sentiment_score', 0) * 100:.1f}ç‚¹/100ç‚¹

{chat_history_text}

# ğŸ¯ åˆ†æè¦æ±‚
ä»¥ä¸‹ã®6é …ç›®ã«ã¤ã„ã¦ã€å¿…ãšé …ç›®ç•ªå·ã¨è¦‹å‡ºã—ã‚’æ˜è¨˜ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š

**1. åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ**
- æœ€ã‚‚å¤šã„è³ªå•ã‚«ãƒ†ã‚´ãƒªä¸Šä½3ã¤ã¨ãã®ä»¶æ•°ã‚’æ˜è¨˜
- åˆ©ç”¨é »åº¦ã®é«˜ã„æ™‚é–“å¸¯ã‚„æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³
- ãƒ¦ãƒ¼ã‚¶ãƒ¼1äººã‚ãŸã‚Šã®å¹³å‡è³ªå•æ•°

**2. å“è³ªèª²é¡Œã®ç‰¹å®š**
- å†è³ªå•ç‡{analytics_data.get('unresolved_and_repeat_analysis', {}).get('statistics', {}).get('repeat_rate', 0)}%ã®å…·ä½“çš„åŸå› 
- æœªè§£æ±ºç‡{analytics_data.get('unresolved_and_repeat_analysis', {}).get('statistics', {}).get('unresolved_rate', 0)}%ã®æ”¹å–„å¿…è¦é ˜åŸŸ
- ãƒã‚¬ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ã®å…·ä½“çš„ãªä»¶æ•°ã¨åŸå› 

**3. å„ªå…ˆæ”¹å–„é …ç›®**
- æœ€å„ªå…ˆã§æ”¹å–„ã™ã¹ãé …ç›®ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã®æ”¹å–„ã«ã‚ˆã‚Šå‰Šæ¸›ã§ãã‚‹è³ªå•æ•°ã‚’æ¨å®š
- å„æ”¹å–„é …ç›®ã®å®Ÿè£…é›£æ˜“åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
- ROIé †ã§ã®å„ªå…ˆé †ä½

**4. ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤è©•ä¾¡**
- ç¾åœ¨ã®æ™‚é–“å‰Šæ¸›åŠ¹æœã‚’æ™‚é–“æ•°ã§æ¨å®š
- æœˆé–“ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœã‚’é‡‘é¡ã§æ¨å®š
- æº€è¶³åº¦å‘ä¸Šã«ã‚ˆã‚‹å®šé‡çš„åŠ¹æœ

**5. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æˆ¦ç•¥**
- è¿½åŠ ã™ã¹ãè³‡æ–™ã®ç¨®é¡ã‚’å…·ä½“çš„ã«3ã¤
- FAQåŒ–ã™ã¹ãè³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å…·ä½“ä¾‹ã‚’ä»¶æ•°ä»˜ãã§
- æ—¢å­˜è³‡æ–™ã®æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ

**6. å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—**
- çŸ­æœŸï¼ˆ1ãƒ¶æœˆä»¥å†…ï¼‰ï¼šå®Ÿè¡Œå¯èƒ½ãªæ”¹å–„é …ç›®ã‚’3ã¤
- ä¸­æœŸï¼ˆ3-6ãƒ¶æœˆï¼‰ï¼šæ©Ÿèƒ½æ‹¡å¼µé …ç›®ã‚’2ã¤
- é•·æœŸï¼ˆ6ãƒ¶æœˆ-1å¹´ï¼‰ï¼šã‚·ã‚¹ãƒ†ãƒ ç™ºå±•é …ç›®ã‚’1ã¤

å„é …ç›®ã¯150æ–‡å­—ç¨‹åº¦ã§ã€å¿…ãšå…·ä½“çš„ãªæ•°å€¤ã‚’å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚é …ç›®ã”ã¨ã«æ˜ç¢ºã«åˆ†ã‘ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
"""
        
        # Geminiã§åˆ†æ
        response = model.generate_content(prompt)
        
        if response and hasattr(response, 'text') and response.text:
            return response.text.strip()
        else:
            return "AIåˆ†æã‚’å®Ÿè¡Œã—ã¾ã—ãŸãŒã€çµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            
    except Exception as e:
        print(f"Geminiæ´å¯Ÿç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
