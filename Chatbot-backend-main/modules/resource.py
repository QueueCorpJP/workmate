from psycopg2.extensions import connection as Connection
from .database import ensure_string

def _clean_nan_values(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰NaNå€¤ã‚„ç„¡åŠ¹ãªæ–‡å­—åˆ—ã‚’é™¤å»ã™ã‚‹"""
    if not text:
        return ""
    
    import re
    
    # 1. NaNå€¤ã®é™¤å»
    text = re.sub(r'\bnan\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\bNaN\b', '', text)
    text = re.sub(r'\bNAN\b', '', text)
    text = re.sub(r'\bnone\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\bnull\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\b<na>\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\bn/a\b', '', text, flags=re.IGNORECASE)
    
    # 2. é€£ç¶šã™ã‚‹nanã‚’é™¤å»
    text = re.sub(r'(\s*nan\s*){2,}', ' ', text, flags=re.IGNORECASE)
    
    # 3. ä½™åˆ†ãªç©ºç™½ã®é™¤å»
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text

async def get_uploaded_resources_by_company_id(company_id: str, db: Connection, uploaded_by: str = None):
    """ä¼šç¤¾IDã«åŸºã¥ã„ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™"""
    try:
        print(f"ğŸ” [DEBUG] get_uploaded_resources_by_company_id é–‹å§‹")
        print(f"ğŸ” [DEBUG] å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        print(f"  - company_id: {company_id} (type: {type(company_id)})")
        print(f"  - uploaded_by: {uploaded_by} (type: {type(uploaded_by)})")
        print(f"  - db: {db} (type: {type(db)})")
        
        from supabase_adapter import execute_query, select_data, get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        print(f"ğŸ” [DEBUG] Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—å®Œäº†: {supabase}")
        
        # document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿å–å¾—ï¼ˆcontentã¯é™¤å¤–ï¼‰
        query = supabase.table("document_sources").select("id,name,type,page_count,uploaded_at,active,uploaded_by,special")
        print(f"ğŸ” [DEBUG] åŸºæœ¬ã‚¯ã‚¨ãƒªä½œæˆå®Œäº†ï¼ˆcontentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰é™¤å¤–ã§é«˜é€ŸåŒ–ï¼‰")
        
        # ä¼šç¤¾IDã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if company_id is not None:
            query = query.eq("company_id", company_id)
            print(f"ğŸ” [DEBUG] company_idãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {company_id}")
        else:
            print(f"ğŸ” [DEBUG] company_idãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆå…¨ä»¶å–å¾—ï¼‰")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è€…IDã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç®¡ç†è€…ç”¨ï¼‰
        if uploaded_by is not None:
            query = query.eq("uploaded_by", uploaded_by)
            print(f"ğŸ” [DEBUG] uploaded_byãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {uploaded_by}")
        else:
            print(f"ğŸ” [DEBUG] uploaded_byãƒ•ã‚£ãƒ«ã‚¿ãªã—")
        
        # ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        print(f"ğŸ” [DEBUG] Supabaseã‚¯ã‚¨ãƒªå®Ÿè¡Œé–‹å§‹...")
        sources_result = query.execute()
        print(f"ğŸ” [DEBUG] Supabaseã‚¯ã‚¨ãƒªå®Ÿè¡Œå®Œäº†")
        print(f"ğŸ” [DEBUG] sources_result: {sources_result}")
        print(f"ğŸ” [DEBUG] sources_result.data: {sources_result.data}")
        print(f"ğŸ” [DEBUG] sources_result.count: {getattr(sources_result, 'count', 'N/A')}")
        
        # çµæœã‚’å–å¾—
        sources = sources_result.data if sources_result.data else []
        print(f"ğŸ” [DEBUG] å–å¾—ã—ãŸsourcesã®æ•°: {len(sources)}")
        print(f"ğŸ” [DEBUG] sourcesè©³ç´°:")
        for i, source in enumerate(sources):
            print(f"  [{i+1}] ID: {source.get('id')}, Name: {source.get('name')}, Type: {source.get('type')}, Active: {source.get('active')}")
        
        print(f"Supabase APIã‹ã‚‰ç›´æ¥å–å¾—ã—ãŸãƒªã‚½ãƒ¼ã‚¹: {len(sources)}ä»¶")
        
        resources = []
        
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’ä¸€åº¦ã«å–å¾—
        print(f"ğŸ” [DEBUG] ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—é–‹å§‹...")
        all_users = {}
        if sources:
            unique_uploader_ids = list(set([source.get("uploaded_by") for source in sources if source.get("uploaded_by")]))
            print(f"ğŸ” [DEBUG] ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ID: {unique_uploader_ids}")
            if unique_uploader_ids:
                users_query = supabase.table("users").select("id, name").in_("id", unique_uploader_ids)
                users_result = users_query.execute()
                print(f"ğŸ” [DEBUG] ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚¯ã‚¨ãƒªçµæœ: {users_result.data}")
                if users_result.data:
                    all_users = {user["id"]: user.get("name", "ä¸æ˜") for user in users_result.data}
                    print(f"ğŸ” [DEBUG] all_usersãƒãƒƒãƒ—: {all_users}")
        else:
            print(f"ğŸ” [DEBUG] sourcesãŒç©ºã®ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        
        # å…¨ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¸€åº¦ã«å–å¾—ï¼ˆä½¿ç”¨å›æ•°è¨ˆç®—ç”¨ï¼‰
        print(f"ğŸ” [DEBUG] ãƒãƒ£ãƒƒãƒˆå±¥æ­´å–å¾—é–‹å§‹...")
        all_usage_counts = {}
        all_last_used = {}
        if sources:
            resource_ids = [source.get("id") for source in sources if source.get("id")]
            print(f"ğŸ” [DEBUG] ãƒãƒ£ãƒƒãƒˆå±¥æ­´å–å¾—å¯¾è±¡ã®ãƒªã‚½ãƒ¼ã‚¹ID: {resource_ids}")
            if resource_ids:
                # ä½¿ç”¨å›æ•°ã‚’ä¸€åº¦ã«å–å¾—
                usage_query = supabase.table("chat_history").select("source_document, timestamp").in_("source_document", resource_ids)
                usage_result = usage_query.execute()
                print(f"ğŸ” [DEBUG] ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ã‚¨ãƒªçµæœ: {len(usage_result.data) if usage_result.data else 0}ä»¶")
                if usage_result.data:
                    # ä½¿ç”¨å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    for chat in usage_result.data:
                        source_doc = chat.get("source_document")
                        if source_doc:
                            all_usage_counts[source_doc] = all_usage_counts.get(source_doc, 0) + 1
                            # æœ€æ–°ã®ä½¿ç”¨æ—¥æ™‚ã‚’è¨˜éŒ²
                            timestamp = chat.get("timestamp")
                            if timestamp:
                                if source_doc not in all_last_used or timestamp > all_last_used[source_doc]:
                                    all_last_used[source_doc] = timestamp
                    print(f"ğŸ” [DEBUG] ä½¿ç”¨å›æ•°ã‚«ã‚¦ãƒ³ãƒˆçµæœ: {all_usage_counts}")
                    print(f"ğŸ” [DEBUG] æœ€çµ‚ä½¿ç”¨æ—¥æ™‚: {all_last_used}")
        else:
            print(f"ğŸ” [DEBUG] sourcesãŒç©ºã®ãŸã‚ã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        
        # å„ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†
        print(f"ğŸ” [DEBUG] ãƒªã‚½ãƒ¼ã‚¹å‡¦ç†é–‹å§‹...")
        for i, source in enumerate(sources):
            print(f"ğŸ” [DEBUG] [{i+1}/{len(sources)}] ãƒªã‚½ãƒ¼ã‚¹å‡¦ç†: {source}")
            resource_id = source.get("id")
            if not resource_id:
                print(f"ğŸ” [DEBUG] ãƒªã‚½ãƒ¼ã‚¹IDãŒãªã„ - ã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼åã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ï¼‰
            uploader_id = source.get("uploaded_by")
            uploader_name = all_users.get(uploader_id, "ä¸æ˜") if uploader_id else "ä¸æ˜"
            print(f"ğŸ” [DEBUG] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼: ID={uploader_id}, Name={uploader_name}")
            
            # ä½¿ç”¨å›æ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ï¼‰
            usage_count = all_usage_counts.get(resource_id, 0)
            print(f"ğŸ” [DEBUG] ä½¿ç”¨å›æ•°: {usage_count}")
            
            # æœ€çµ‚ä½¿ç”¨æ—¥æ™‚ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ï¼‰
            last_used = all_last_used.get(resource_id)
            print(f"ğŸ” [DEBUG] æœ€çµ‚ä½¿ç”¨æ—¥æ™‚: {last_used}")
            
            # ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’æ§‹ç¯‰
            resource_data = {
                "id": resource_id,
                "name": source.get("name", ""),
                "type": source.get("type", ""),
                "page_count": source.get("page_count"),
                "timestamp": source.get("uploaded_at"),
                "active": source.get("active", True),
                "uploaded_by": uploader_id or "",
                "uploader_name": uploader_name,
                "usage_count": usage_count,
                "last_used": last_used
            }
            print(f"ğŸ” [DEBUG] æ§‹ç¯‰ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿: {resource_data}")
            resources.append(resource_data)
        
        print(f"ğŸ” [DEBUG] æœ€çµ‚ãƒªã‚½ãƒ¼ã‚¹é…åˆ—:")
        for i, resource in enumerate(resources):
            print(f"  [{i+1}] {resource}")
        
        result = {
            "resources": resources,
            "message": f"{len(resources)}ä»¶ã®ãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ"
        }
        
        print(f"ğŸ” [DEBUG] æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {result}")
        print(f"å‡¦ç†å¾Œã®ãƒªã‚½ãƒ¼ã‚¹: {len(resources)}ä»¶")
        return result
    except Exception as e:
        print(f"âŒ [ERROR] ãƒªã‚½ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ [ERROR] ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{error_details}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç©ºã®ãƒªã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™
        return {
            "resources": [],
            "message": f"ãƒªã‚½ãƒ¼ã‚¹ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        }

async def toggle_resource_active_by_id(resource_id: str, db: Connection):
    try:
        from supabase_adapter import get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        
        # ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
        query = supabase.table("document_sources").select("name, active").eq("id", resource_id)
        result = query.execute()
        
        if not result.data or len(result.data) == 0:
            print(f"ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {
                "name": "",
                "active": False,
                "message": "ãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            }
            
        current_active_state = result.data[0].get("active", False)
        resource_name = result.data[0].get("name", "")
        new_active_state = not current_active_state
        
        print(f"ãƒªã‚½ãƒ¼ã‚¹ '{resource_name}' ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã‚’ {current_active_state} ã‹ã‚‰ {new_active_state} ã«å¤‰æ›´ã—ã¾ã™")
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã‚’æ›´æ–°
        update_query = supabase.table("document_sources").update({"active": new_active_state}).eq("id", resource_id)
        update_result = update_query.execute()
        
        print(f"æ›´æ–°çµæœ: {update_result.data if update_result.data else 'æ›´æ–°å¤±æ•—'}")
        
        return {
            "name": resource_name,
            "active": new_active_state,
            "message": f"ãƒªã‚½ãƒ¼ã‚¹ '{resource_name}' ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã‚’ {new_active_state} ã«å¤‰æ›´ã—ã¾ã—ãŸ"
        }
    except Exception as e:
        print(f"ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹å¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(traceback.format_exc())
        return {
            "name": "",
            "active": False,
            "message": f"ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹ã®å¤‰æ›´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        }

async def remove_resource_by_id(resource_id: str, db: Connection):
    try:
        from supabase_adapter import get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        
        # ãƒªã‚½ãƒ¼ã‚¹åã‚’å–å¾—ï¼ˆãƒ­ã‚°ç”¨ï¼‰
        query = supabase.table("document_sources").select("name").eq("id", resource_id)
        result = query.execute()
        
        resource_name = ""
        if result.data and len(result.data) > 0:
            resource_name = result.data[0].get("name", "")
            print(f"å‰Šé™¤ã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹å: {resource_name}")
        else:
            print(f"ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {
                "name": "",
                "message": "ãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            }
        
        # ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤
        delete_query = supabase.table("document_sources").delete().eq("id", resource_id)
        delete_result = delete_query.execute()
        
        print(f"å‰Šé™¤çµæœ: {delete_result.data if delete_result.data else 'å‰Šé™¤å¤±æ•—'}")
        
        return {
            "name": resource_name,
            "message": f"ãƒªã‚½ãƒ¼ã‚¹ '{resource_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        }
    except Exception as e:
        print(f"ãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(traceback.format_exc())
        return {
            "name": "",
            "message": f"ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        }

async def get_active_resources_by_company_id(company_id: str, db: Connection, uploaded_by: str = None):
    """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªã‚½ãƒ¼ã‚¹ã®IDãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™"""
    try:
        from supabase_adapter import get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        
        # ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
        query = supabase.table("document_sources").select("id").eq("active", True)
        
        if company_id is not None:
            query = query.eq("company_id", company_id)
        
        if uploaded_by is not None:
            query = query.eq("uploaded_by", uploaded_by)
        
        # ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        result = query.execute()
        
        # IDã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        resources = [source.get("id") for source in result.data if source.get("id")]
        
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªã‚½ãƒ¼ã‚¹ID: {len(resources)}ä»¶")
        return resources
    except Exception as e:
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒªã‚½ãƒ¼ã‚¹IDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(traceback.format_exc())
        return []

async def get_active_resource_names_by_company_id(company_id: str, db: Connection):
    """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªã‚½ãƒ¼ã‚¹ã®åå‰ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™"""
    try:
        from supabase_adapter import get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        
        # ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
        query = supabase.table("document_sources").select("name").eq("active", True)
        
        if company_id is not None:
            query = query.eq("company_id", company_id)
        
        # ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        result = query.execute()
        
        # åå‰ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        resources = [source.get("name") for source in result.data if source.get("name")]
        
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªã‚½ãƒ¼ã‚¹å: {len(resources)}ä»¶")
        return resources
    except Exception as e:
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒªã‚½ãƒ¼ã‚¹åå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(traceback.format_exc())
        return []

async def get_active_resources_content_by_ids(resource_ids: list[str], db: Connection) -> str:
    """
    ğŸ” æŒ‡å®šã•ã‚ŒãŸIDã®ãƒªã‚½ãƒ¼ã‚¹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦çµåˆã—ã¾ã™
    
    æœ¬ç•ªç’°å¢ƒã§ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹å–å¾—å•é¡Œã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ãŸã‚ã€è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›
    """
    # Check if resource_ids is None or empty
    if not resource_ids:
        print("âŒ ãƒªã‚½ãƒ¼ã‚¹IDãƒªã‚¹ãƒˆãŒç©ºã§ã™")
        return ""
    
    try:
        from supabase_adapter import get_supabase_client
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        supabase = get_supabase_client()
        
        print(f"ğŸ“‹ ãƒªã‚½ãƒ¼ã‚¹IDä¸€è¦§ ({len(resource_ids)}ä»¶): {resource_ids}")
        
        combined_content = []
        failed_resources = []
        
        # å„ãƒªã‚½ãƒ¼ã‚¹IDã«å¯¾ã—ã¦å€‹åˆ¥ã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        for i, resource_id in enumerate(resource_ids):
            print(f"ğŸ” [{i+1}/{len(resource_ids)}] ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ã®å‡¦ç†é–‹å§‹")
            
            try:
                # ã¾ãšãƒªã‚½ãƒ¼ã‚¹ã®åŸºæœ¬æƒ…å ±ã‚’ç¢ºèªï¼ˆcontentã‚«ãƒ©ãƒ é™¤å¤–ï¼‰
                info_query = supabase.table("document_sources").select("id,name,active").eq("id", resource_id)
                info_result = info_query.execute()
                
                if not info_result.data or len(info_result.data) == 0:
                    print(f"âŒ ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                    failed_resources.append({"id": resource_id, "reason": "ãƒªã‚½ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„"})
                    continue
                
                resource_info = info_result.data[0]
                resource_name = resource_info.get("name", "ä¸æ˜")
                is_active = resource_info.get("active", False)
                
                # âœ… ä¿®æ­£: chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
                content = await _get_content_from_chunks(resource_id, supabase)
                
                print(f"ğŸ“„ ãƒªã‚½ãƒ¼ã‚¹å: {resource_name}")
                print(f"ğŸ”˜ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹: {is_active}")
                print(f"ğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å­˜åœ¨: {'ã‚ã‚Š' if content else 'ãªã—'}")
                
                if not is_active:
                    print(f"âš ï¸ ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ({resource_name}) ã¯ç„¡åŠ¹ã§ã™")
                    failed_resources.append({"id": resource_id, "name": resource_name, "reason": "ãƒªã‚½ãƒ¼ã‚¹ãŒç„¡åŠ¹"})
                    continue
                
                if content is None or content == "":
                    print(f"âŒ ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} ({resource_name}) ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒç©ºã§ã™")
                    failed_resources.append({"id": resource_id, "name": resource_name, "reason": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒç©º"})
                    continue
                
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è©³ç´°æƒ…å ±ã‚’å‡ºåŠ›
                content_length = len(str(content))
                content_preview = str(content)[:200] + "..." if content_length > 200 else str(content)
                print(f"ğŸ“Š ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·: {content_length:,} æ–‡å­—")
                print(f"ğŸ‘€ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å…ˆé ­: {content_preview}")
                
                # âœ… ä¿®æ­£: chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥ä½¿ç”¨
                processed_content = ensure_string(content, for_db=True)
                
                # è¿½åŠ ã®NaNå€¤å‡¦ç†
                processed_content = _clean_nan_values(processed_content)
                
                combined_content.append(f"=== {resource_name} ===\n{processed_content}")
                print(f"âœ… chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—å®Œäº†: {resource_name}")
                
            except Exception as resource_error:
                print(f"âŒ ãƒªã‚½ãƒ¼ã‚¹ID {resource_id} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(resource_error)}")
                failed_resources.append({"id": resource_id, "reason": f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(resource_error)}"})
                continue
        
        # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
        print(f"\nğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼:")
        print(f"âœ… æˆåŠŸ: {len(combined_content)} ä»¶")
        print(f"âŒ å¤±æ•—: {len(failed_resources)} ä»¶")
        
        if failed_resources:
            print(f"ğŸ” å¤±æ•—ã—ãŸãƒªã‚½ãƒ¼ã‚¹è©³ç´°:")
            for failed in failed_resources:
                print(f"  - ID: {failed['id']}, åå‰: {failed.get('name', 'ä¸æ˜')}, ç†ç”±: {failed['reason']}")
        
        # çµåˆ
        combined = "\n\n".join(combined_content)
        final_length = len(combined)
        print(f"ğŸ“ æœ€çµ‚çš„ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹é•·: {final_length:,} æ–‡å­—")
        
        if final_length == 0:
            print("âŒ æœ€çµ‚çš„ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãŒç©ºã§ã™ - ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ãŒå¤±æ•—")
        else:
            print(f"âœ… çŸ¥è­˜ãƒ™ãƒ¼ã‚¹çµåˆå®Œäº† - {len(combined_content)} ä»¶ã®ãƒªã‚½ãƒ¼ã‚¹")
        
        return combined
        
    except Exception as e:
        print(f"âŒ ãƒªã‚½ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã§é‡å¤§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{traceback.format_exc()}")
        return ""

async def _get_content_from_chunks(doc_id: str, supabase) -> str:
    """chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦çµåˆã™ã‚‹"""
    try:
        # chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ï¼ˆdocument_sourcesã®activeãƒ•ãƒ©ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        # ã¾ãšdocument_sourcesã§activeã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        doc_query = supabase.table("document_sources").select("active").eq("id", doc_id).single()
        doc_result = doc_query.execute()
        
        if not doc_result.data or not doc_result.data.get("active", False):
            print(f"âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“: {doc_id}")
            return ""
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å ´åˆã®ã¿chunksã‚’å–å¾—
        chunks_query = supabase.table("chunks").select("content,chunk_index").eq("doc_id", doc_id).order("chunk_index")
        chunks_result = chunks_query.execute()
        
        if not chunks_result.data or len(chunks_result.data) == 0:
            print(f"âš ï¸ chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {doc_id}")
            return ""
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«çµåˆ
        chunks = sorted(chunks_result.data, key=lambda x: x.get("chunk_index", 0))
        full_content = "".join([chunk.get("content", "") for chunk in chunks])
        
        print(f"ğŸ“¦ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ: {doc_id}")
        return full_content
        
    except Exception as e:
        print(f"âŒ chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return ""
