"""
ğŸ§  è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã«è‡ªå‹•çš„ã«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›
"""

import os
import logging
import asyncio
from typing import List, Optional
from dotenv import load_dotenv
import google.generativeai as genai
from supabase_adapter import get_supabase_client, select_data, update_data
from .vertex_ai_embedding import get_vertex_ai_embedding_client, vertex_ai_embedding_available

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

class AutoEmbeddingGenerator:
    """è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        self.embedding_model = os.getenv("EMBEDDING_MODEL", "models/gemini-embedding-001")
        self.auto_generate = os.getenv("AUTO_GENERATE_EMBEDDINGS", "false").lower() == "true"
        self.use_vertex_ai = os.getenv("USE_VERTEX_AI", "true").lower() == "true"
        self.supabase = None
        self.vertex_ai_client = None
        
        # Vertex AIä½¿ç”¨æ™‚ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if self.use_vertex_ai and vertex_ai_embedding_available():
            self.vertex_ai_client = get_vertex_ai_embedding_client()
            logger.info(f"ğŸ§  Vertex AI Embeddingä½¿ç”¨: {self.embedding_model}")
        else:
            # æ¨™æº–Gemini APIä½¿ç”¨æ™‚ã®ãƒ¢ãƒ‡ãƒ«åæ­£è¦åŒ–
            if not self.embedding_model.startswith("models/"):
                self.embedding_model = f"models/{self.embedding_model}"
            logger.info(f"ğŸ§  æ¨™æº–Gemini APIä½¿ç”¨: {self.embedding_model}")
    
    def _init_clients(self):
        """APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        if not self.api_key:
            logger.error("âŒ GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            # Gemini APIåˆæœŸåŒ–
            genai.configure(api_key=self.api_key)
            
            # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            self.supabase = get_supabase_client()
            
            logger.info(f"ğŸ§  è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”ŸæˆåˆæœŸåŒ–å®Œäº†: {self.embedding_model}")
            return True
        except Exception as e:
            logger.error(f"âŒ APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def generate_embeddings_for_document(self, doc_id: str, max_chunks: int = 50) -> bool:
        """æŒ‡å®šã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ã«å¯¾ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
        # å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã§ã¯ auto_generate ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if not self.auto_generate:
            logger.info("ğŸ”„ AUTO_GENERATE_EMBEDDINGS=false ã§ã™ãŒã€å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            # return True ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ
        
        if not self._init_clients():
            return False
        
        try:
            logger.info(f"ğŸ§  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {doc_id} ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆé–‹å§‹")
            
            # è©²å½“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®embeddingæœªç”Ÿæˆãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
            chunks_result = select_data(
                "chunks",
                columns="id,content,chunk_index",
                filters={
                    "doc_id": doc_id,
                    "embedding": None
                },
                limit=max_chunks
            )
            
            if not chunks_result.data:
                logger.info("âœ… æ–°ã—ãå‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
                return True
            
            chunks = chunks_result.data
            logger.info(f"ğŸ“‹ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆã—ã¾ã™")
            
            success_count = 0
            for chunk in chunks:
                try:
                    chunk_id = chunk['id']
                    content = chunk['content']
                    chunk_index = chunk['chunk_index']
                    
                    if not content or not content.strip():
                        logger.warning(f"âš ï¸ ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—: chunk_index={chunk_index}")
                        continue
                    
                    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
                    logger.info(f"  - ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆä¸­...")
                    
                    embedding_vector = None
                    
                    if self.use_vertex_ai and self.vertex_ai_client:
                        # Vertex AIä½¿ç”¨
                        embedding_vector = self.vertex_ai_client.generate_embedding(content)
                    else:
                        # æ¨™æº–Gemini APIä½¿ç”¨
                        response = genai.embed_content(
                            model=self.embedding_model,
                            content=content
                        )
                        
                        # gemini-embedding-exp-03-07ã¯è¾æ›¸å½¢å¼ã§{'embedding': [...]}ã‚’è¿”ã™
                        if isinstance(response, dict) and 'embedding' in response:
                            embedding_vector = response['embedding']
                        elif hasattr(response, 'embedding') and response.embedding:
                            embedding_vector = response.embedding
                        else:
                            logger.error(f"  ğŸ” äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
                    
                    if embedding_vector and len(embedding_vector) > 0:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        update_result = update_data(
                            "chunks",
                            {"embedding": embedding_vector},
                            "id",
                            chunk_id
                        )
                        
                        if update_result:
                            success_count += 1
                            logger.info(f"  âœ… ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å®Œäº† ({len(embedding_vector)}æ¬¡å…ƒ)")
                        else:
                            logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å¤±æ•—")
                    else:
                        logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•—: ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                
                except Exception as chunk_error:
                    logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk.get('chunk_index', 'unknown')} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {chunk_error}")
                    continue
            
            logger.info(f"ğŸ‰ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Œäº†: {success_count}/{len(chunks)} æˆåŠŸ")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def generate_chunk_embedding(self, chunk_id: str, content: str) -> bool:
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
        if not self._init_clients():
            return False
        
        try:
            if not content or not content.strip():
                logger.warning(f"âš ï¸ ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—: chunk_id={chunk_id}")
                return False
            
            embedding_vector = None
            
            if self.use_vertex_ai and self.vertex_ai_client:
                # Vertex AIä½¿ç”¨
                embedding_vector = self.vertex_ai_client.generate_embedding(content)
            else:
                # æ¨™æº–Gemini APIä½¿ç”¨
                response = genai.embed_content(
                    model=self.embedding_model,
                    content=content
                )
                
                # gemini-embedding-exp-03-07ã¯è¾æ›¸å½¢å¼ã§{'embedding': [...]}ã‚’è¿”ã™
                if isinstance(response, dict) and 'embedding' in response:
                    embedding_vector = response['embedding']
                elif hasattr(response, 'embedding') and response.embedding:
                    embedding_vector = response.embedding
                else:
                    logger.error(f"ğŸ” äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
            
            if embedding_vector and len(embedding_vector) > 0:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                update_result = update_data(
                    "chunks",
                    {"embedding": embedding_vector},
                    "id",
                    chunk_id
                )
                
                if update_result.success:
                    logger.info(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å®Œäº† ({len(embedding_vector)}æ¬¡å…ƒ)")
                    return True
                else:
                    logger.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å¤±æ•—: {update_result.error}")
                    return False
            else:
                logger.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•—: ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def generate_embeddings_for_chunks(self, chunk_ids: List[str]) -> bool:
        """æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯IDãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
        # å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã§ã¯ auto_generate ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if not self.auto_generate:
            logger.info("ğŸ”„ AUTO_GENERATE_EMBEDDINGS=false ã§ã™ãŒã€å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            # return True ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å‡¦ç†ã‚’ç¶šè¡Œ
        
        if not chunk_ids:
            logger.info("ğŸ“‹ å‡¦ç†å¯¾è±¡ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return True
        
        if not self._init_clients():
            return False
        
        try:
            logger.info(f"ğŸ§  {len(chunk_ids)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆé–‹å§‹")
            
            success_count = 0
            for chunk_id in chunk_ids:
                try:
                    # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã‚’å–å¾—
                    chunk_result = select_data(
                        "chunks",
                        columns="id,content,chunk_index,doc_id",
                        filters={"id": chunk_id}
                    )
                    
                    if not chunk_result.data:
                        logger.warning(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        continue
                    
                    chunk = chunk_result.data[0]
                    content = chunk['content']
                    chunk_index = chunk['chunk_index']
                    
                    if not content or not content.strip():
                        logger.warning(f"âš ï¸ ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—: chunk_id={chunk_id}")
                        continue
                    
                    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
                    logger.info(f"  - ãƒãƒ£ãƒ³ã‚¯ {chunk_index} (ID: {chunk_id}) ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆä¸­...")
                    
                    embedding_vector = None
                    
                    if self.use_vertex_ai and self.vertex_ai_client:
                        # Vertex AIä½¿ç”¨
                        embedding_vector = self.vertex_ai_client.generate_embedding(content)
                    else:
                        # æ¨™æº–Gemini APIä½¿ç”¨
                        response = genai.embed_content(
                            model=self.embedding_model,
                            content=content
                        )
                        
                        # gemini-embedding-exp-03-07ã¯è¾æ›¸å½¢å¼ã§{'embedding': [...]}ã‚’è¿”ã™
                        if isinstance(response, dict) and 'embedding' in response:
                            embedding_vector = response['embedding']
                        elif hasattr(response, 'embedding') and response.embedding:
                            embedding_vector = response.embedding
                        else:
                            logger.error(f"  ğŸ” äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
                    
                    if embedding_vector and len(embedding_vector) > 0:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        update_result = update_data(
                            "chunks",
                            {"embedding": embedding_vector},
                            "id",
                            chunk_id
                        )
                        
                        if update_result:
                            success_count += 1
                            logger.info(f"  âœ… ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å®Œäº† ({len(embedding_vector)}æ¬¡å…ƒ)")
                        else:
                            logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜å¤±æ•—")
                    else:
                        logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•—: ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                
                except Exception as chunk_error:
                    logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {chunk_error}")
                    continue
            
            logger.info(f"ğŸ‰ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Œäº†: {success_count}/{len(chunk_ids)} æˆåŠŸ")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
auto_embedding_generator = AutoEmbeddingGenerator()

async def auto_generate_embeddings_for_document(doc_id: str, max_chunks: int = 50) -> bool:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆï¼ˆå¤–éƒ¨å‘¼ã³å‡ºã—ç”¨ï¼‰"""
    return await auto_embedding_generator.generate_embeddings_for_document(doc_id, max_chunks)

async def auto_generate_embeddings_for_chunks(chunk_ids: List[str]) -> bool:
    """ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã®è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆï¼ˆå¤–éƒ¨å‘¼ã³å‡ºã—ç”¨ï¼‰"""
    return await auto_embedding_generator.generate_embeddings_for_chunks(chunk_ids)