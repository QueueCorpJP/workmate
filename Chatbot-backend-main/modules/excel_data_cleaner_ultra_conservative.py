"""
ğŸ“Š Excel ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»æ§‹é€ åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
ãƒ‡ãƒ¼ã‚¿æå¤±ã‚’æ¥µé™ã¾ã§æŠ‘åˆ¶ã—ã€ã»ã¼å…¨ã¦ã®æƒ…å ±ã‚’ä¿æŒ
ç©ºç™½ãƒ»"nan"ãƒ»å®Œå…¨ã«ç„¡æ„å‘³ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’é™¤å¤–
"""

import pandas as pd
import numpy as np
import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from io import BytesIO
import unicodedata

logger = logging.getLogger(__name__)

class ExcelDataCleanerUltraConservative:
    """Excelãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ§‹é€ åŒ–ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰"""
    
    def __init__(self):
        self.max_cell_length = 5000     # ã‚»ãƒ«å†…å®¹ã®æœ€å¤§æ–‡å­—æ•°ã‚’ã•ã‚‰ã«å¢—åŠ 
        
        # é™¤å¤–å¯¾è±¡ã®ç„¡æ„å‘³ãªå€¤ï¼ˆæœ€å°é™ï¼‰
        self.meaningless_values = {
            'nan', 'NaN', 'null', 'NULL', 'None', 'NONE', '',
            '#N/A', '#VALUE!', '#REF!', '#DIV/0!', '#NAME?', '#NUM!', '#NULL!',
            'naan', 'naaN', 'NAAN'  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®é™¤å¤–å¯¾è±¡
        }
        
    def clean_excel_data(self, content: bytes) -> str:
        """
        ä¹±é›‘ãªExcelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        ãƒ‡ãƒ¼ã‚¿æå¤±ã‚’æ¥µé™ã¾ã§æŠ‘åˆ¶ã™ã‚‹è¶…ä¿å®ˆç‰ˆ
        """
        try:
            excel_file = pd.ExcelFile(BytesIO(content))
            cleaned_parts = []
            
            for sheet_name in excel_file.sheet_names:
                try:
                    logger.info(f"ğŸ“Š ã‚·ãƒ¼ãƒˆå‡¦ç†é–‹å§‹: {sheet_name}")
                    
                    # è¤‡æ•°ã®èª­ã¿è¾¼ã¿æ–¹æ³•ã‚’è©¦è¡Œ
                    df = self._read_excel_sheet_robust(excel_file, sheet_name)
                    
                    if df is None or df.empty:
                        logger.warning(f"âš ï¸ ã‚·ãƒ¼ãƒˆ {sheet_name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—")
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
                    cleaned_df = self._clean_dataframe_ultra_conservative(df)
                    
                    if cleaned_df.empty:
                        logger.warning(f"âš ï¸ ã‚·ãƒ¼ãƒˆ {sheet_name} ã«ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        continue
                    
                    # æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
                    structured_text = self._convert_to_structured_text_ultra_conservative(cleaned_df, sheet_name)
                    
                    if structured_text.strip():
                        cleaned_parts.append(structured_text)
                        logger.info(f"âœ… ã‚·ãƒ¼ãƒˆ {sheet_name} å‡¦ç†å®Œäº†: {len(structured_text)} æ–‡å­—")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ ã‚·ãƒ¼ãƒˆ {sheet_name} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if not cleaned_parts:
                logger.warning("âš ï¸ å‡¦ç†å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return "ã“ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å‡¦ç†å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            
            result = "\n\n".join(cleaned_parts)
            logger.info(f"ğŸ‰ Excelå‡¦ç†å®Œäº†ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰: {len(cleaned_parts)}ã‚·ãƒ¼ãƒˆ, ç·æ–‡å­—æ•°: {len(result)}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Excelå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _read_excel_sheet_robust(self, excel_file, sheet_name: str) -> Optional[pd.DataFrame]:
        """
        Excelã‚·ãƒ¼ãƒˆã‚’å …ç‰¢ã«èª­ã¿è¾¼ã‚€ï¼ˆè¤‡æ•°ã®æ–¹æ³•ã‚’è©¦è¡Œï¼‰
        """
        read_methods = [
            # æ–¹æ³•1: ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§èª­ã¿è¾¼ã¿
            lambda: pd.read_excel(excel_file, sheet_name=sheet_name, header=None),
            # æ–¹æ³•2: æœ€åˆã®è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦èª­ã¿è¾¼ã¿
            lambda: pd.read_excel(excel_file, sheet_name=sheet_name, header=0),
            # æ–¹æ³•3: è¤‡æ•°è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦èª­ã¿è¾¼ã¿
            lambda: pd.read_excel(excel_file, sheet_name=sheet_name, header=None, skiprows=1),
            # æ–¹æ³•4: æ–‡å­—åˆ—ã¨ã—ã¦å…¨ã¦èª­ã¿è¾¼ã¿
            lambda: pd.read_excel(excel_file, sheet_name=sheet_name, header=None, dtype=str)
        ]
        
        for i, method in enumerate(read_methods):
            try:
                df = method()
                if df is not None and not df.empty:
                    logger.info(f"ğŸ“– ã‚·ãƒ¼ãƒˆ {sheet_name} èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆæ–¹æ³•{i+1}ï¼‰")
                    return df
            except Exception as e:
                logger.debug(f"èª­ã¿è¾¼ã¿æ–¹æ³•{i+1}å¤±æ•—: {e}")
                continue
        
        logger.warning(f"âš ï¸ ã‚·ãƒ¼ãƒˆ {sheet_name} ã®å…¨ã¦ã®èª­ã¿è¾¼ã¿æ–¹æ³•ãŒå¤±æ•—")
        return None
    
    def _clean_dataframe_ultra_conservative(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        DataFrameã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¶…ä¿å®ˆç‰ˆ - ã»ã¼å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
        """
        # 1. å®Œå…¨ã«ç©ºã®è¡Œãƒ»åˆ—ã®ã¿ã‚’å‰Šé™¤
        df = df.dropna(how='all').dropna(axis=1, how='all')
        
        if df.empty:
            return df
        
        # 2. ã‚»ãƒ«å†…å®¹ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæœ€å°é™ï¼‰
        for col in df.columns:
            df[col] = df[col].apply(self._clean_cell_content_ultra_conservative)
        
        # 3. å®Œå…¨ã«ç„¡æ„å‘³ãªè¡Œã®ã¿ã‚’å‰Šé™¤ï¼ˆåŸºæº–ã‚’æ¥µé™ã¾ã§ç·©å’Œï¼‰
        df = df[df.apply(self._is_meaningful_row_ultra_conservative, axis=1)]
        
        # 4. é‡è¤‡è¡Œã¯å‰Šé™¤ã—ãªã„ï¼ˆãƒ‡ãƒ¼ã‚¿ã®é‡è¦æ€§ã‚’å„ªå…ˆï¼‰
        
        # 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
        df = df.reset_index(drop=True)
        
        return df
    
    def _clean_cell_content_ultra_conservative(self, cell_value) -> str:
        """
        ã‚»ãƒ«å†…å®¹ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¶…ä¿å®ˆç‰ˆ - æœ€å°é™ã®å‡¦ç†ï¼‰
        """
        if pd.isna(cell_value):
            return ""
        
        # æ–‡å­—åˆ—ã«å¤‰æ›
        text = str(cell_value).strip()
        
        # ç„¡æ„å‘³ãªå€¤ã‚’ãƒã‚§ãƒƒã‚¯
        if text.lower() in [v.lower() for v in self.meaningless_values]:
            return ""
        
        # é•·ã™ãã‚‹ã‚»ãƒ«ã¯åˆ‡ã‚Šè©°ã‚ï¼ˆä¸Šé™ã‚’ã•ã‚‰ã«å¢—åŠ ï¼‰
        if len(text) > self.max_cell_length:
            text = text[:self.max_cell_length] + "..."
        
        # Unicodeæ­£è¦åŒ–ï¼ˆæœ€å°é™ï¼‰
        text = unicodedata.normalize('NFKC', text)
        
        # ç‰¹æ®Šæ–‡å­—ã®å‡¦ç†ï¼ˆæœ€å°é™ï¼‰
        text = text.replace('\x00', '')  # NULLæ–‡å­—å‰Šé™¤
        text = text.replace('\ufeff', '')  # BOMå‰Šé™¤
        
        # ç©ºç™½ã®æ•´ç†ã¯æœ€å°é™ã«
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def _is_meaningful_row_ultra_conservative(self, row: pd.Series) -> bool:
        """
        è¡ŒãŒæ„å‘³ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚“ã§ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        for cell in row:
            if pd.notna(cell):
                cell_text = str(cell).strip()
                # ç„¡æ„å‘³ãªå€¤ã§ãªã‘ã‚Œã°æ„å‘³ãŒã‚ã‚‹ã¨åˆ¤å®š
                if cell_text and cell_text.lower() not in [v.lower() for v in self.meaningless_values]:
                    return True
        
        return False
    
    def _convert_to_structured_text_ultra_conservative(self, df: pd.DataFrame, sheet_name: str) -> str:
        """
        ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸDataFrameã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        if df.empty:
            return ""
        
        text_parts = [f"=== ã‚·ãƒ¼ãƒˆ: {sheet_name} ==="]
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’åˆ†æï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        structure_info = self._analyze_data_structure_ultra_conservative(df)
        
        if structure_info["has_headers"]:
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚‹å ´åˆã®å‡¦ç†ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
            text_parts.append(self._format_with_headers_ultra_conservative(df, structure_info))
        else:
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„å ´åˆã®å‡¦ç†ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
            text_parts.append(self._format_without_headers_ultra_conservative(df))
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        stats = self._generate_data_statistics_ultra_conservative(df)
        if stats:
            text_parts.append(f"\nã€ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã€‘\n{stats}")
        
        return "\n".join(text_parts)
    
    def _analyze_data_structure_ultra_conservative(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’åˆ†æï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        structure = {
            "has_headers": False,
            "header_row": None,
            "data_types": {},
            "patterns": []
        }
        
        # æœ€åˆã®æ•°è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¢ã™ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿã«ï¼‰
        for i in range(min(5, len(df))):  # 5è¡Œã¾ã§ç¢ºèª
            row = df.iloc[i]
            if self._looks_like_header_ultra_conservative(row):
                structure["has_headers"] = True
                structure["header_row"] = i
                break
        
        return structure
    
    def _looks_like_header_ultra_conservative(self, row: pd.Series) -> bool:
        """
        è¡ŒãŒãƒ˜ãƒƒãƒ€ãƒ¼ã‚‰ã—ã„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        non_null_count = row.notna().sum()
        if non_null_count < 1:
            return False
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‰ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§å¹…æ‹¡å¼µï¼‰
        header_keywords = [
            'åå‰', 'name', 'ä¼šç¤¾', 'company', 'ä½æ‰€', 'address', 
            'é›»è©±', 'phone', 'tel', 'æ—¥ä»˜', 'date', 'id', 'no',
            'ç•ªå·', 'ç¨®é¡', 'type', 'çŠ¶æ…‹', 'status', 'é‡‘é¡', 'amount',
            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'é¡§å®¢', 'ç²å¾—', 'ç‰©ä»¶', 'å¥‘ç´„', 'æ›¸é¡',
            'ç™ºè¡Œ', 'è«‹æ±‚', 'mail', 'è§£ç´„', 'å‚™è€ƒ', '#', 'é …ç›®',
            'ãƒ—ãƒ­ãƒã‚¤ãƒ€', 'ISP', 'æ¡ˆä»¶', 'ä¸€è¦§', 'ç®¡ç†', 'æƒ…å ±',
            'æ‹…å½“', 'éƒ¨ç½²', 'æ”¯åº—', 'å–¶æ¥­', 'å£²ä¸Š', 'åˆ©ç›Š', 'è²»ç”¨',
            'é–‹å§‹', 'çµ‚äº†', 'æœŸé–“', 'æœŸé™', 'äºˆå®š', 'å®Ÿç¸¾', 'é€²æ—',
            'é¡§å®¢ç•ªå·', 'ç¤¾å', 'æ³•äºº', 'å€‹äºº', 'é€£çµ¡å…ˆ', 'ãƒ¡ãƒ¼ãƒ«',
            'éƒµä¾¿ç•ªå·', 'éƒ½é“åºœçœŒ', 'å¸‚åŒºç”ºæ‘', 'å»ºç‰©', 'ãƒ“ãƒ«',
            'å›ç·š', 'é€Ÿåº¦', 'æ–™é‡‘', 'ãƒ—ãƒ©ãƒ³', 'ã‚³ãƒ¼ã‚¹', 'ã‚ªãƒ—ã‚·ãƒ§ãƒ³'
        ]
        
        text_content = ' '.join([str(cell).lower() for cell in row if pd.notna(cell)])
        
        for keyword in header_keywords:
            if keyword.lower() in text_content:
                return True
        
        # æ•°å€¤ãŒå°‘ãªãã€ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã„å ´åˆã‚‚ãƒ˜ãƒƒãƒ€ãƒ¼ã®å¯èƒ½æ€§
        text_cells = 0
        numeric_cells = 0
        for cell in row:
            if pd.notna(cell):
                cell_str = str(cell).strip()
                if re.match(r'^-?\d+\.?\d*$', cell_str):
                    numeric_cells += 1
                else:
                    text_cells += 1
        
        # ãƒ†ã‚­ã‚¹ãƒˆãŒæ•°å€¤ä»¥ä¸Šã®å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã®å¯èƒ½æ€§
        return text_cells >= numeric_cells
    
    def _format_with_headers_ultra_conservative(self, df: pd.DataFrame, structure_info: Dict) -> str:
        """
        ãƒ˜ãƒƒãƒ€ãƒ¼ã‚ã‚Šã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        header_row = structure_info["header_row"]
        headers = df.iloc[header_row].tolist()
        data_rows = df.iloc[header_row + 1:]
        
        formatted_parts = []
        formatted_parts.append("ã€ãƒ‡ãƒ¼ã‚¿é …ç›®ã€‘")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ï¼ˆå…¨ã¦ä¿æŒï¼‰
        valid_headers = []
        for i, header in enumerate(headers):
            if pd.notna(header):
                clean_header = str(header).strip()
                if clean_header:  # ç©ºã§ãªã‘ã‚Œã°å…¨ã¦ä¿æŒ
                    valid_headers.append((i, clean_header))
                    formatted_parts.append(f"- {clean_header}")
                else:
                    valid_headers.append((i, f"åˆ—{i+1}"))  # ç©ºã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‚ç•ªå·ã§ä¿æŒ
                    formatted_parts.append(f"- åˆ—{i+1}")
        
        formatted_parts.append("\nã€ãƒ‡ãƒ¼ã‚¿å†…å®¹ã€‘")
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†ï¼ˆè¶…ä¿å®ˆç‰ˆ - å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
        for idx, row in data_rows.iterrows():
            row_data = []
            for col_idx, header_name in valid_headers:
                if col_idx < len(row):
                    cell_value = row.iloc[col_idx]
                    if pd.notna(cell_value):
                        clean_value = str(cell_value).strip()
                        # ç„¡æ„å‘³ãªå€¤ä»¥å¤–ã¯å…¨ã¦ä¿æŒ
                        if clean_value and clean_value.lower() not in [v.lower() for v in self.meaningless_values]:
                            row_data.append(f"{header_name}: {clean_value}")
            
            if row_data:
                formatted_parts.append(f"â€¢ {' | '.join(row_data)}")
        
        return "\n".join(formatted_parts)
    
    def _format_without_headers_ultra_conservative(self, df: pd.DataFrame) -> str:
        """
        ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        formatted_parts = []
        formatted_parts.append("ã€ãƒ‡ãƒ¼ã‚¿å†…å®¹ã€‘")
        
        for idx, row in df.iterrows():
            row_data = []
            for col_idx, cell_value in enumerate(row):
                if pd.notna(cell_value):
                    clean_value = str(cell_value).strip()
                    # ç„¡æ„å‘³ãªå€¤ä»¥å¤–ã¯å…¨ã¦ä¿æŒ
                    if clean_value and clean_value.lower() not in [v.lower() for v in self.meaningless_values]:
                        row_data.append(clean_value)
            
            if row_data:
                formatted_parts.append(f"è¡Œ{idx + 1}: {' | '.join(row_data)}")
        
        return "\n".join(formatted_parts)
    
    def _generate_data_statistics_ultra_conservative(self, df: pd.DataFrame) -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆï¼ˆè¶…ä¿å®ˆç‰ˆï¼‰
        """
        stats_parts = []
        
        # åŸºæœ¬çµ±è¨ˆ
        stats_parts.append(f"ç·è¡Œæ•°: {len(df)}")
        stats_parts.append(f"ç·åˆ—æ•°: {len(df.columns)}")
        
        # éç©ºã‚»ãƒ«æ•°
        non_empty_cells = 0
        meaningful_cells = 0
        total_cells = len(df) * len(df.columns)
        
        for col in df.columns:
            for cell in df[col]:
                if pd.notna(cell):
                    cell_str = str(cell).strip()
                    if cell_str:
                        non_empty_cells += 1
                        if cell_str.lower() not in [v.lower() for v in self.meaningless_values]:
                            meaningful_cells += 1
        
        fill_rate = (non_empty_cells / total_cells * 100) if total_cells > 0 else 0
        meaningful_rate = (meaningful_cells / total_cells * 100) if total_cells > 0 else 0
        
        stats_parts.append(f"ãƒ‡ãƒ¼ã‚¿å……å¡«ç‡: {fill_rate:.1f}%")
        stats_parts.append(f"æœ‰æ„ç¾©ãƒ‡ãƒ¼ã‚¿ç‡: {meaningful_rate:.1f}%")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
        unique_values = df.nunique().sum()
        stats_parts.append(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°: {unique_values}")
        
        return " | ".join(stats_parts)