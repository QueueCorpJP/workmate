"""
ğŸ¯ è¶…é«˜ç²¾åº¦RAGã‚·ã‚¹ãƒ†ãƒ 
ã€Œã»ã£ã¨ã‚‰ã„ãµã€ãªã©ã®å›ºæœ‰åè©æ¤œç´¢ã«ç‰¹åŒ–ã—ãŸæœ€é«˜ç²¾åº¦ã®RAGå‡¦ç†
"""

import os
import logging
import asyncio
import re
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
# æ–°ã—ã„Google GenAI SDKã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from google import genai
    from google.genai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    genai = None
    types = None
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from datetime import datetime

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

logger = logging.getLogger(__name__)

class UltraAccurateRAGProcessor:
    """è¶…é«˜ç²¾åº¦RAGå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.use_vertex_ai = os.getenv("USE_VERTEX_AI", "true").lower() == "true"
        self.embedding_model = os.getenv("EMBEDDING_MODEL", "text-multilingual-embedding-002")
        self.expected_dimensions = 768 if "text-multilingual-embedding-002" in self.embedding_model else 3072
        
        # API ã‚­ãƒ¼ã®è¨­å®š
        self.api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        
        self.chat_model = "gemini-2.5-flash"
        self.db_url = self._get_db_url()
        
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
        genai.configure(api_key=self.api_key)
        self.chat_client = genai.GenerativeModel(self.chat_model)
        
        # è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        try:
            from .ultra_accurate_search import get_ultra_accurate_search_instance, ultra_accurate_search_available
            if ultra_accurate_search_available():
                self.ultra_search = get_ultra_accurate_search_instance()
                logger.info(f"âœ… è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ: {self.embedding_model} ({self.expected_dimensions}æ¬¡å…ƒ)")
            else:
                logger.error("âŒ è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                raise ValueError("è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        except ImportError as e:
            logger.error(f"âŒ è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            raise ValueError("è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # å›ç­”å“è³ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_context_length = 150000  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’å¤§å¹…ã«å¢—åŠ 
        self.min_confidence_threshold = 0.1  # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã‚‹
        self.context_diversity_threshold = 0.8  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å¤šæ§˜æ€§é–¾å€¤
        
        logger.info(f"âœ… è¶…é«˜ç²¾åº¦RAGãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–å®Œäº†")
    
    def _get_db_url(self) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’æ§‹ç¯‰"""
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        
        if not supabase_url or not supabase_key:
            raise ValueError("SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if "supabase.co" in supabase_url:
            project_id = supabase_url.split("://")[1].split(".")[0]
            return f"postgresql://postgres.{project_id}:{os.getenv('DB_PASSWORD', '')}@aws-0-ap-northeast-1.pooler.supabase.com:6543/postgres"
        else:
            db_url = os.getenv("DATABASE_URL")
            if not db_url:
                raise ValueError("DATABASE_URL ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return db_url
    
    def analyze_query_intent(self, question: str) -> Dict:
        """ã‚¯ã‚¨ãƒªã®æ„å›³åˆ†æ"""
        intent_analysis = {
            'query_type': 'general',
            'is_company_specific': False,
            'is_contact_inquiry': False,
            'is_service_inquiry': False,
            'confidence_boost': 1.0,
            'search_strategy': 'standard'
        }
        
        question_lower = question.lower()
        
        # ä¼šç¤¾åãƒ»å›ºæœ‰åè©ã®æ¤œå‡º
        company_patterns = [
            'ã»ã£ã¨ã‚‰ã„ãµ', 'ãƒ›ãƒƒãƒˆãƒ©ã‚¤ãƒ•', 'hotlife', 'hot life',
            'ntt', 'ã‚¨ãƒŒãƒ†ã‚£ãƒ†ã‚£', 'ãƒ‰ã‚³ãƒ¢', 'docomo'
        ]
        
        for pattern in company_patterns:
            if pattern in question_lower:
                intent_analysis['is_company_specific'] = True
                intent_analysis['confidence_boost'] = 0.5  # é–¾å€¤ã‚’å¤§å¹…ã«ä¸‹ã’ã‚‹
                intent_analysis['search_strategy'] = 'company_focused'
                break
        
        # é€£çµ¡å…ˆå•ã„åˆã‚ã›ã®æ¤œå‡º
        contact_patterns = [
            'é€£çµ¡å…ˆ', 'é›»è©±', 'tel', 'ãƒ¡ãƒ¼ãƒ«', 'mail', 'å•ã„åˆã‚ã›', 'ãŠå•ã„åˆã‚ã›',
            'é€£çµ¡', 'ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ', 'contact', 'çª“å£'
        ]
        
        for pattern in contact_patterns:
            if pattern in question_lower:
                intent_analysis['is_contact_inquiry'] = True
                intent_analysis['query_type'] = 'contact'
                break
        
        # ã‚µãƒ¼ãƒ“ã‚¹å•ã„åˆã‚ã›ã®æ¤œå‡º
        service_patterns = [
            'ã‚µãƒ¼ãƒ“ã‚¹', 'service', 'æä¾›', 'åˆ©ç”¨', 'ä½¿ç”¨', 'æ©Ÿèƒ½', 'æ–™é‡‘', 'ä¾¡æ ¼'
        ]
        
        for pattern in service_patterns:
            if pattern in question_lower:
                intent_analysis['is_service_inquiry'] = True
                intent_analysis['query_type'] = 'service'
                break
        
        logger.info(f"ğŸ§  ã‚¯ã‚¨ãƒªæ„å›³åˆ†æ: {intent_analysis}")
        return intent_analysis
    
    async def step1_receive_question(self, question: str, company_id: str = None) -> Dict:
        """
        âœï¸ Step 1. è³ªå•å…¥åŠ›ï¼ˆè¶…é«˜ç²¾åº¦ç‰ˆï¼‰
        è³ªå•ã®å‰å‡¦ç†ã¨æ„å›³åˆ†æã‚’å®Ÿè¡Œ
        """
        # ChatMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æ–‡å­—åˆ—ã‚’å–å¾—
        if hasattr(question, 'text'):
            question_text = question.text
        else:
            question_text = str(question)
        
        logger.info(f"âœï¸ Step 1: è¶…é«˜ç²¾åº¦è³ªå•å—ä»˜ - '{question_text[:50]}...'")
        
        if not question or not question.strip():
            raise ValueError("è³ªå•ãŒç©ºã§ã™")
        
        # è³ªå•ã®å‰å‡¦ç†
        processed_question = question.strip()
        
        # æ„å›³åˆ†æ
        intent_analysis = self.analyze_query_intent(processed_question)
        
        return {
            'original_question': question,
            'processed_question': processed_question,
            'company_id': company_id,
            'intent_analysis': intent_analysis,
            'timestamp': datetime.now().isoformat(),
            'step': 'question_received'
        }
    
    async def step2_ultra_accurate_search(self, question_data: Dict) -> Dict:
        """
        ğŸ” Step 2. è¶…é«˜ç²¾åº¦ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        æ„å›³ã«åŸºã¥ã„ãŸæœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢ã‚’å®Ÿè¡Œ
        """
        logger.info(f"ğŸ” Step 2: è¶…é«˜ç²¾åº¦ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢é–‹å§‹")
        
        question = question_data['processed_question']
        company_id = question_data.get('company_id')
        intent_analysis = question_data['intent_analysis']
        
        try:
            # æ¤œç´¢æˆ¦ç•¥ã«åŸºã¥ã„ãŸçµæœæ•°èª¿æ•´
            if intent_analysis['is_company_specific']:
                max_results = 120  # ä¼šç¤¾ç‰¹åŒ–ã®å ´åˆã¯å¤šã‚ã«å–å¾—
            elif intent_analysis['is_contact_inquiry']:
                max_results = 100
            else:
                max_results = 80
            
            # è¶…é«˜ç²¾åº¦æ¤œç´¢å®Ÿè¡Œ
            search_results = await self.ultra_search.ultra_accurate_search(
                question, 
                company_id=company_id, 
                max_results=max_results
            )
            
            if not search_results:
                logger.warning("è¶…é«˜ç²¾åº¦æ¤œç´¢ã§çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {
                    **question_data,
                    'search_results': [],
                    'search_success': False,
                    'step': 'search_completed'
                }
            
            # çµæœã®å“è³ªåˆ†æ
            high_confidence_results = [r for r in search_results if r.confidence_score >= 0.3]
            medium_confidence_results = [r for r in search_results if 0.1 <= r.confidence_score < 0.3]
            
            logger.info(f"âœ… è¶…é«˜ç²¾åº¦æ¤œç´¢å®Œäº†: {len(search_results)}ä»¶")
            logger.info(f"   é«˜ä¿¡é ¼åº¦: {len(high_confidence_results)}ä»¶")
            logger.info(f"   ä¸­ä¿¡é ¼åº¦: {len(medium_confidence_results)}ä»¶")
            
            return {
                **question_data,
                'search_results': search_results,
                'high_confidence_count': len(high_confidence_results),
                'medium_confidence_count': len(medium_confidence_results),
                'search_success': True,
                'step': 'search_completed'
            }
        
        except Exception as e:
            logger.error(f"âŒ è¶…é«˜ç²¾åº¦æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                **question_data,
                'search_results': [],
                'search_success': False,
                'search_error': str(e),
                'step': 'search_failed'
            }
    
    def build_ultra_context(self, search_data: Dict) -> str:
        """
        ğŸ“ Step 3. è¶…é«˜ç²¾åº¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        æ¤œç´¢çµæœã‹ã‚‰æœ€é©ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        """
        logger.info(f"ğŸ“ Step 3: è¶…é«˜ç²¾åº¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰é–‹å§‹")
        
        search_results = search_data.get('search_results', [])
        intent_analysis = search_data['intent_analysis']
        
        if not search_results:
            logger.warning("æ¤œç´¢çµæœãŒãªã„ãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã§ãã¾ã›ã‚“")
            return ""
        
        context_parts = []
        total_length = 0
        
        # æ„å›³ã«åŸºã¥ã„ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰æˆ¦ç•¥
        if intent_analysis['is_company_specific']:
            context_intro = f"ä»¥ä¸‹ã¯ã€Œ{search_data['processed_question']}ã€ã«é–¢ã™ã‚‹è©³ç´°æƒ…å ±ã§ã™ï¼š\n\n"
        elif intent_analysis['is_contact_inquiry']:
            context_intro = "ä»¥ä¸‹ã¯é€£çµ¡å…ˆãƒ»å•ã„åˆã‚ã›ã«é–¢ã™ã‚‹æƒ…å ±ã§ã™ï¼š\n\n"
        else:
            context_intro = "ä»¥ä¸‹ã¯é–¢é€£ã™ã‚‹æƒ…å ±ã§ã™ï¼š\n\n"
        
        context_parts.append(context_intro)
        total_length += len(context_intro)
        
        # çµæœã‚’ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_results = sorted(search_results, key=lambda x: x.confidence_score, reverse=True)
        
        for i, result in enumerate(sorted_results):
            if total_length >= self.max_context_length:
                break
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ”ãƒ¼ã‚¹ã®æ§‹ç¯‰
            context_piece = f"""
ã€å‚è€ƒè³‡æ–™{i+1}: {result.document_name}ã€‘
ä¿¡é ¼åº¦: {result.confidence_score:.3f} | é–¢é€£åº¦: {result.relevance_score:.3f}

{result.content}

---
"""
            
            if total_length + len(context_piece) <= self.max_context_length:
                context_parts.append(context_piece)
                total_length += len(context_piece)
                logger.info(f"  {i+1}. è¿½åŠ : {result.document_name} (ã‚»ã‚¯ã‚·ãƒ§ãƒ³{result.chunk_index}) ({len(context_piece)}æ–‡å­—)")
            else:
                logger.info(f"  {i+1}. æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Šé™¤å¤–")
                break
        
        final_context = "".join(context_parts)
        logger.info(f"âœ… è¶…é«˜ç²¾åº¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰å®Œäº†: {len(context_parts)}å€‹ã®å‚è€ƒè³‡æ–™ã€{len(final_context)}æ–‡å­—")
        
        return final_context
    
    def build_ultra_prompt(self, search_data: Dict, context: str) -> str:
        """
        ğŸ¯ Step 4. è¶…é«˜ç²¾åº¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        æ„å›³ã«åŸºã¥ã„ãŸæœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        """
        logger.info(f"ğŸ¯ Step 4: è¶…é«˜ç²¾åº¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰é–‹å§‹")
        
        question = search_data['processed_question']
        intent_analysis = search_data['intent_analysis']
        
        # åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        base_prompt = f"""ã‚ãªãŸã¯ç¤¾å†…ã®ä¸å¯§ã§è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ã”è³ªå•ï¼š
{question}

å‚è€ƒã¨ãªã‚‹è³‡æ–™ï¼š
{context}

å›ç­”ã®éš›ã®é‡è¦ãªæŒ‡é‡ï¼š
â€¢ å›ç­”ã¯ä¸å¯§ãªæ•¬èªã§è¡Œã£ã¦ãã ã•ã„
â€¢ æƒ…å ±ã®å‡ºå…¸ã¨ã—ã¦ã€Œãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚„ã€Œè³‡æ–™åã€ã¾ã§ã¯æ˜ç¤ºã—ã¦æ§‹ã„ã¾ã›ã‚“ãŒã€åˆ—ç•ªå·ã€è¡Œç•ªå·ã€ãƒãƒ£ãƒ³ã‚¯ç•ªå·ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®IDãªã©ã®å†…éƒ¨çš„ãªæ§‹é€ æƒ…å ±ã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„
â€¢ ä»£è¡¨è€…åã‚„ä¼šç¤¾åãªã©ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèã„ã¦ã„ã‚‹æƒ…å ±ã ã‘ã‚’ç«¯çš„ã«ç­”ãˆã€è¡¨å½¢å¼ã‚„ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®è¨€åŠã¯ä¸è¦ã§ã™
â€¢ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚ã€å¤±ç¤¼ã®ãªã„è‡ªç„¶ãªæ—¥æœ¬èªã§ã€Œç¾åœ¨ã®è³‡æ–™ã«ã¯è©²å½“æƒ…å ±ãŒã”ã–ã„ã¾ã›ã‚“ã€ã¨æ¡ˆå†…ã—ã¦ãã ã•ã„
â€¢ æ–‡æœ«ã«ã¯ã€Œã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ãŠæ°—è»½ã«ãŠç”³ã—ä»˜ã‘ãã ã•ã„ã€‚ã€ã¨æ·»ãˆã¦ãã ã•ã„

ãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š"""
        
        # æ„å›³ã«åŸºã¥ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´
        if intent_analysis['is_company_specific']:
            specific_instruction = """
ç‰¹ã«é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š
â€¢ ä¼šç¤¾åã‚„ã‚µãƒ¼ãƒ“ã‚¹åã¯æ­£ç¢ºã«ãŠä¼ãˆã—ã€ãã®ç‰¹å¾´ã‚„å¼·ã¿ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã”èª¬æ˜ã—ã¾ã™
â€¢ ãŠå®¢æ§˜ãŒçŸ¥ã‚ŠãŸã„ã‚µãƒ¼ãƒ“ã‚¹ã®è©³ç´°ã«ã¤ã„ã¦ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’ãŠä¼ãˆã—ã¾ã™
â€¢ ã”é€£çµ¡å…ˆã‚„ãŠå•ã„åˆã‚ã›æ–¹æ³•ã«ã¤ã„ã¦ã‚‚ã€å¿…è¦ã«å¿œã˜ã¦ã”æ¡ˆå†…ã„ãŸã—ã¾ã™
"""
            base_prompt = base_prompt.replace("ãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š", specific_instruction + "\nãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š")
        
        elif intent_analysis['is_contact_inquiry']:
            contact_instruction = """
ãŠå•ã„åˆã‚ã›ã«é–¢ã™ã‚‹ç‰¹åˆ¥ãªã”æ¡ˆå†…ï¼š
â€¢ é›»è©±ç•ªå·ã€ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ä½æ‰€ãªã©ã€å¿…è¦ãªé€£çµ¡å…ˆã‚’åˆ†ã‹ã‚Šã‚„ã™ããŠä¼ãˆã—ã¾ã™
â€¢ å–¶æ¥­æ™‚é–“ã‚„æœ€é©ãªãŠå•ã„åˆã‚ã›æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è©³ã—ãã”æ¡ˆå†…ã—ã¾ã™
â€¢ è¤‡æ•°ã®é€£çµ¡æ‰‹æ®µãŒã‚ã‚‹å ´åˆã¯ã€ãŠå®¢æ§˜ã®çŠ¶æ³ã«å¿œã˜ã¦æœ€é©ãªæ–¹æ³•ã‚’ã”ææ¡ˆã—ã¾ã™
"""
            base_prompt = base_prompt.replace("ãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š", contact_instruction + "\nãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š")
        
        logger.info(f"âœ… è¶…é«˜ç²¾åº¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº†: {len(base_prompt)}æ–‡å­—")
        return base_prompt
    
    async def step5_generate_ultra_response(self, search_data: Dict, context: str, prompt: str) -> Dict:
        """
        ğŸ¤– Step 5. è¶…é«˜ç²¾åº¦å›ç­”ç”Ÿæˆ
        æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é«˜å“è³ªãªå›ç­”ã‚’ç”Ÿæˆ
        """
        logger.info(f"ğŸ¤– Step 5: è¶…é«˜ç²¾åº¦å›ç­”ç”Ÿæˆé–‹å§‹")
        
        try:
            # Gemini APIã§å›ç­”ç”Ÿæˆ
            response = await asyncio.to_thread(
                self.chat_client.generate_content,
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,  # ã‚ˆã‚Šä¸€è²«ã—ãŸå›ç­”ã®ãŸã‚ä½ã‚ã«è¨­å®š
                    top_p=0.8,
                    top_k=50,
                    max_output_tokens=16384,  # 16Kãƒˆãƒ¼ã‚¯ãƒ³ã«å¢—åŠ 
                )
            )
            
            if response and response.text:
                generated_answer = response.text.strip()
                
                # å›ç­”å“è³ªã®è©•ä¾¡
                quality_score = self._evaluate_answer_quality(
                    generated_answer, 
                    search_data['processed_question'],
                    search_data.get('search_results', [])
                )
                
                logger.info(f"âœ… è¶…é«˜ç²¾åº¦å›ç­”ç”Ÿæˆå®Œäº†: {len(generated_answer)}æ–‡å­— (å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.3f})")
                
                return {
                    **search_data,
                    'context': context,
                    'prompt': prompt,
                    'generated_answer': generated_answer,
                    'quality_score': quality_score,
                    'generation_success': True,
                    'step': 'response_generated'
                }
            else:
                logger.error("âŒ å›ç­”ç”Ÿæˆã«å¤±æ•—: ç©ºã®å¿œç­”")
                return {
                    **search_data,
                    'context': context,
                    'prompt': prompt,
                    'generated_answer': "æã‚Œå…¥ã‚Šã¾ã™ã€‚ä»Šå›ã®ã”è³ªå•ã«ã¯æ­£ç¢ºã«ãŠç­”ãˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å†…å®¹ã‚’å°‘ã—å¤‰ãˆã¦ã€ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚",
                    'quality_score': 0.0,
                    'generation_success': False,
                    'step': 'response_failed'
                }
        
        except Exception as e:
            logger.error(f"âŒ å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                **search_data,
                'context': context,
                'prompt': prompt,
                'generated_answer': "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€æŠ€è¡“çš„ãªå•é¡Œã«ã‚ˆã‚Šå›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                'quality_score': 0.0,
                'generation_success': False,
                'generation_error': str(e),
                'step': 'response_failed'
            }
    
    def _evaluate_answer_quality(self, answer: str, question: str, search_results: List) -> float:
        """å›ç­”å“è³ªã®è©•ä¾¡"""
        if not answer or not question:
            return 0.0
        
        quality_score = 0.0
        
        # 1. é•·ã•ã«ã‚ˆã‚‹è©•ä¾¡
        if 100 <= len(answer) <= 2000:
            quality_score += 0.3
        elif 50 <= len(answer) <= 3000:
            quality_score += 0.2
        
        # 2. è³ªå•ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å«æœ‰
        question_words = set(question.lower().split())
        answer_words = set(answer.lower().split())
        keyword_overlap = len(question_words & answer_words) / len(question_words) if question_words else 0
        quality_score += keyword_overlap * 0.3
        
        # 3. æ¤œç´¢çµæœã¨ã®é–¢é€£æ€§
        if search_results:
            high_confidence_count = sum(1 for r in search_results if r.confidence_score >= 0.3)
            if high_confidence_count > 0:
                quality_score += 0.2
        
        # 4. æ§‹é€ çš„è¦ç´ ã®å­˜åœ¨
        if any(pattern in answer for pattern in ['é›»è©±', 'ãƒ¡ãƒ¼ãƒ«', 'é€£çµ¡å…ˆ', 'å•ã„åˆã‚ã›']):
            quality_score += 0.1
        
        # 5. ä¸å¯§èªã®ä½¿ç”¨
        if any(pattern in answer for pattern in ['ã§ã™', 'ã¾ã™', 'ã”ã–ã„ã¾ã™']):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    async def process_ultra_accurate_rag(self, question: str, company_id: str = None, include_chunk_visibility: bool = False) -> Dict:
        """
        ğŸ¯ è¶…é«˜ç²¾åº¦RAGå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼
        å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ±åˆã—ãŸæœ€é«˜ç²¾åº¦ã®å‡¦ç†
        """
        # ChatMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æ–‡å­—åˆ—ã‚’å–å¾—
        if hasattr(question, 'text'):
            question_text = question.text
        else:
            question_text = str(question)
        
        logger.info(f"ğŸ¯ è¶…é«˜ç²¾åº¦RAGå‡¦ç†é–‹å§‹: '{question_text[:50]}...'")
        
        try:
            # Step 1: è³ªå•å—ä»˜
            question_data = await self.step1_receive_question(question, company_id)
            
            # Step 2: è¶…é«˜ç²¾åº¦æ¤œç´¢
            search_data = await self.step2_ultra_accurate_search(question_data)
            
            if not search_data['search_success']:
                return {
                    **search_data,
                    'final_answer': "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ãŠå•ã„åˆã‚ã›ã„ãŸã ã„ãŸå†…å®¹ã«é–¢ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è¡¨ç¾ã§è³ªå•ã—ã¦ã„ãŸã ãã‹ã€ç›´æ¥ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
                    'processing_success': False,
                    'chunk_visibility': None
                }
            
            # Step 3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            context = self.build_ultra_context(search_data)
            
            if not context:
                return {
                    **search_data,
                    'final_answer': "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚",
                    'processing_success': False,
                    'chunk_visibility': None
                }
            
            # Step 4: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            prompt = f"""ã‚ãªãŸã¯{company_name}ã®ç¤¾å†…å‘ã‘ä¸å¯§ã§è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

å›ç­”ã®éš›ã®é‡è¦ãªæŒ‡é‡ï¼š
â€¢ å›ç­”ã¯ä¸å¯§ãªæ•¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚
â€¢ **æ‰‹å…ƒã®å‚è€ƒè³‡æ–™ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã‚Œã‚’æ´»ç”¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚**
â€¢ **å‚è€ƒè³‡æ–™ã®æƒ…å ±ã‹ã‚‰æ¨æ¸¬ã§ãã‚‹ã“ã¨ã‚„ã€é–¢é€£ã™ã‚‹å†…å®¹ãŒã‚ã‚Œã°ç©æ¥µçš„ã«æä¾›ã—ã¦ãã ã•ã„ã€‚**
â€¢ **å®Œå…¨ã«ä¸€è‡´ã™ã‚‹æƒ…å ±ãŒãªãã¦ã‚‚ã€éƒ¨åˆ†çš„ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒã‚ã‚Œã°æœ‰åŠ¹æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚**
â€¢ æƒ…å ±ã®å‡ºå…¸ã¨ã—ã¦ã€Œãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚„ã€Œè³‡æ–™åã€ã¾ã§ã¯æ˜ç¤ºã—ã¦æ§‹ã„ã¾ã›ã‚“ãŒã€æŠ€è¡“çš„ãªå†…éƒ¨ç®¡ç†æƒ…å ±ï¼ˆåˆ—ç•ªå·ã€è¡Œç•ªå·ã€åˆ†å‰²ç•ªå·ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®IDãªã©ï¼‰ã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„
â€¢ ä»£è¡¨è€…åã‚„ä¼šç¤¾åãªã©ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèã„ã¦ã„ã‚‹æƒ…å ±ã ã‘ã‚’ç«¯çš„ã«ç­”ãˆã€è¡¨å½¢å¼ã‚„ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®è¨€åŠã¯ä¸è¦ã§ã™ã€‚
â€¢ **å…¨ãé–¢é€£æ€§ãŒãªã„å ´åˆã®ã¿ã€ãã®æ—¨ã‚’ä¸å¯§ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚**
â€¢ å°‚é–€çš„ãªå†…å®¹ã‚‚ã€æ—¥å¸¸ã®è¨€è‘‰ã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
â€¢ æ‰‹ç¶šãã‚„é€£çµ¡å…ˆã«ã¤ã„ã¦ã¯ã€æ­£ç¢ºãªæƒ…å ±ã‚’æ¼ã‚Œãªãã”æ¡ˆå†…ã—ã¦ãã ã•ã„ã€‚
â€¢ æ–‡æœ«ã«ã¯ã€Œã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ãŠæ°—è»½ã«ãŠç”³ã—ä»˜ã‘ãã ã•ã„ã€‚ã€ã¨æ·»ãˆã¦ãã ã•ã„ã€‚

ãŠå®¢æ§˜ã‹ã‚‰ã®ã”è³ªå•ï¼š
{question}

æ‰‹å…ƒã®å‚è€ƒè³‡æ–™ï¼š
{final_context}

ãã‚Œã§ã¯ã€ã”è³ªå•ã«ãŠç­”ãˆã„ãŸã—ã¾ã™ï¼š"""
            
            # Step 5: å›ç­”ç”Ÿæˆ
            final_result = await self.step5_generate_ultra_response(search_data, context, prompt)
            
            # ãƒãƒ£ãƒ³ã‚¯å¯è¦–åŒ–æƒ…å ±ã®ç”Ÿæˆ
            chunk_visibility_info = None
            if include_chunk_visibility and search_data.get('search_results'):
                chunk_visibility_info = self._generate_chunk_visibility_info(
                    search_data['search_results'],
                    question,
                    search_data.get('intent_analysis', {})
                )
            
            # æœ€çµ‚çµæœã®æ§‹ç¯‰
            return {
                **final_result,
                'final_answer': final_result['generated_answer'],
                'processing_success': final_result['generation_success'],
                'processing_time': (datetime.now() - datetime.fromisoformat(question_data['timestamp'])).total_seconds(),
                'chunk_visibility': chunk_visibility_info
            }
        
        except Exception as e:
            logger.error(f"âŒ è¶…é«˜ç²¾åº¦RAGå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            
            return {
                'original_question': question,
                'final_answer': "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                'processing_success': False,
                'processing_error': str(e),
                'chunk_visibility': None
            }
    
    def _generate_chunk_visibility_info(self, search_results: List, query: str, intent_analysis: Dict) -> Dict:
        """ãƒãƒ£ãƒ³ã‚¯å¯è¦–åŒ–æƒ…å ±ã®ç”Ÿæˆ"""
        try:
            from .chunk_visibility import get_chunk_visibility_system
            
            # ãƒãƒ£ãƒ³ã‚¯å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’å–å¾—
            visibility_system = get_chunk_visibility_system()
            
            # å‹•çš„é–¾å€¤ã‚’è¨ˆç®—ï¼ˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å–å¾—ï¼‰
            similarities = [r.similarity_score for r in search_results]
            dynamic_threshold = self.ultra_search.calculate_dynamic_threshold(similarities, query)
            
            # ãƒãƒ£ãƒ³ã‚¯é¸æŠåˆ†æ
            selection_analysis = visibility_system.analyze_chunk_selection(
                search_results, query, dynamic_threshold, intent_analysis
            )
            
            # ãƒãƒ£ãƒ³ã‚¯å‚ç…§æƒ…å ±ã®ä½œæˆ
            chunk_references = visibility_system.create_chunk_references(search_results, query)
            
            # å¯è¦–åŒ–æƒ…å ±ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            return visibility_system.format_chunk_visibility_info(chunk_references, selection_analysis)
        
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ³ã‚¯å¯è¦–åŒ–æƒ…å ±ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "error": "ãƒãƒ£ãƒ³ã‚¯å¯è¦–åŒ–æƒ…å ±ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                "chunk_references": [],
                "selection_analysis": {},
                "metadata": {}
            }

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—é–¢æ•°
def get_ultra_accurate_rag_instance() -> Optional[UltraAccurateRAGProcessor]:
    """è¶…é«˜ç²¾åº¦RAGãƒ—ãƒ­ã‚»ãƒƒã‚µã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    try:
        return UltraAccurateRAGProcessor()
    except Exception as e:
        logger.error(f"è¶…é«˜ç²¾åº¦RAGãƒ—ãƒ­ã‚»ãƒƒã‚µã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        return None

def ultra_accurate_rag_available() -> bool:
    """è¶…é«˜ç²¾åº¦RAGãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
    try:
        instance = get_ultra_accurate_rag_instance()
        return instance is not None
    except Exception:
        return False