"""
PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
PDFãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼ˆæ–‡å­—åŒ–ã‘å¯¾å¿œå¼·åŒ–ç‰ˆï¼‰
"""
import pandas as pd
import PyPDF2
from io import BytesIO
import re
import traceback
import asyncio
import logging
import tempfile
import os
from .ocr import ocr_pdf_to_text_from_bytes
from ..database import ensure_string

logger = logging.getLogger(__name__)

def check_text_corruption(text: str) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆãŒæ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
    if not text or len(text.strip()) == 0:
        return True
    
    # CSVå‡¦ç†ã®æ–‡å­—åŒ–ã‘æ¤œå‡ºæ©Ÿèƒ½ã‚’åˆ©ç”¨
    from .csv_processor import detect_mojibake_in_text
    
    # æ—¢å­˜ã®æ¤œå‡ºçµæœ
    legacy_corruption = _check_legacy_corruption(text)
    
    # CSVå‡¦ç†ã®é«˜åº¦ãªæ–‡å­—åŒ–ã‘æ¤œå‡º
    advanced_corruption = detect_mojibake_in_text(text)
    
    # ã©ã¡ã‚‰ã‹ã§æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
    if legacy_corruption or advanced_corruption:
        logger.info(f"PDFæ–‡å­—åŒ–ã‘æ¤œå‡º: legacy={legacy_corruption}, advanced={advanced_corruption}")
        return True
    
    return False

def _check_legacy_corruption(text: str) -> bool:
    """å¾“æ¥ã®PDFæ–‡å­—åŒ–ã‘æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯"""
    if not text or len(text.strip()) == 0:
        return True
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•
    text_length = len(text)
    
    # æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    corruption_indicators = [
        # æ„å‘³ã®ãªã„æ–‡å­—ã®é€£ç¶š
        '\ufffd' in text,  # ç½®æ›æ–‡å­—ï¼ˆæ–‡å­—åŒ–ã‘ï¼‰
        'ï¿½ï¿½' in text,      # æ–‡å­—åŒ–ã‘è¨˜å·
        
        # æ¥µç«¯ã«çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç”»åƒã‚„è¤‡é›‘ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å ´åˆï¼‰
        text_length < 50 and not any(char.isalnum() for char in text),
        
        # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãƒ»ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ã®æ¯”ç‡ãŒæ¥µç«¯ã«ä½ã„
        len([char for char in text if char.isalpha() or 
             '\u3040' <= char <= '\u309F' or  # ã²ã‚‰ãŒãª
             '\u30A0' <= char <= '\u30FF' or  # ã‚«ã‚¿ã‚«ãƒŠ
             '\u4E00' <= char <= '\u9FAF'     # æ¼¢å­—
            ]) / text_length < 0.05 if text_length > 0 else True,
        
        # æ¥µç«¯ã«å¤šãã®æ”¹è¡Œã‚„ç©ºç™½
        text.count('\n') / text_length > 0.6 if text_length > 0 else False,
        text.count(' ') / text_length > 0.8 if text_length > 0 else False,
        
        # åˆ¶å¾¡æ–‡å­—ãŒå¤šã„
        len([char for char in text if ord(char) < 32 and char not in '\n\r\t']) / text_length > 0.1 if text_length > 0 else False,
        
        # é«˜ä½Unicodeæ–‡å­—ãŒå¤šã„ï¼ˆæ–‡å­—åŒ–ã‘å¯èƒ½æ€§ï¼‰
        len([char for char in text if ord(char) > 65535]) / text_length > 0.05 if text_length > 0 else False,
        
        # æ„å‘³ã®ãªã„æ–‡å­—åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³
        text.count('ï¿½') > 10,  # æ–‡å­—åŒ–ã‘æ–‡å­—ãŒå¤šã„
        
        # PDFã‹ã‚‰ã‚ˆãå‡ºã‚‹æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³
        text.count('(cid:') > 5,  # PDFã®CIDã‚¨ãƒ©ãƒ¼
        
        # åŒã˜æ–‡å­—ã®ç•°å¸¸ãªç¹°ã‚Šè¿”ã—
        any(text.count(char) / text_length > 0.3 for char in set(text) if char.isprintable()) if text_length > 10 else False,
    ]
    
    corruption_count = sum(corruption_indicators)
    
    # è¤‡æ•°ã®æŒ‡æ¨™ã§æ–‡å­—åŒ–ã‘ã¨åˆ¤å®š
    if corruption_count >= 2:
        return True
    
    # ç‰¹ã«å¼·ã„æŒ‡æ¨™ã®å ´åˆã¯å˜ç‹¬ã§ã‚‚æ–‡å­—åŒ–ã‘ã¨åˆ¤å®š
    strong_indicators = [
        '\ufffd' in text,
        'ï¿½ï¿½' in text,
        text.count('(cid:') > 5,
        len([char for char in text if ord(char) > 65535]) / text_length > 0.1 if text_length > 0 else False,
    ]
    
    return any(strong_indicators)

def split_ocr_text_into_sections(text: str, filename: str) -> list:
    """OCRçµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã™ã‚‹"""
    sections = []
    
    # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šã§åˆ†å‰²
    page_parts = text.split('--- Page ')
    
    for i, part in enumerate(page_parts):
        if not part.strip():
            continue
            
        # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æŠ½å‡º
        lines = part.split('\n')
        if i == 0:
            # æœ€åˆã®éƒ¨åˆ†ï¼ˆãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šã®å‰ã®éƒ¨åˆ†ï¼‰
            section_name = "æ¦‚è¦"
            content = part.strip()
        else:
            # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æŠ½å‡º
            page_line = lines[0] if lines else ""
            page_num = page_line.split('---')[0].strip() if '---' in page_line else str(i)
            section_name = f"ãƒšãƒ¼ã‚¸ {page_num}"
            content = '\n'.join(lines[1:]).strip() if len(lines) > 1 else ""
        
        if content:
            sections.append({
                'section': str(section_name),
                'content': str(content),
                'source': 'PDF',
                'file': filename,
                'url': None
            })
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒç©ºã®å ´åˆã¯å…¨ä½“ã‚’ä¸€ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦è¿”ã™
    if not sections:
        sections.append({
            'section': "å…¨ä½“",
            'content': str(text),
            'source': 'PDF', 
            'file': filename,
            'url': None
        })
    
    return sections

async def process_pdf_file(contents, filename):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™"""
    try:
        # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        pdf_file = BytesIO(contents)
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        all_text = ""
        sections = {}
        extracted_text = f"=== ãƒ•ã‚¡ã‚¤ãƒ«: {filename} ===\n\n"
        
        corrupted_pages = []  # æ–‡å­—åŒ–ã‘ã—ãŸãƒšãƒ¼ã‚¸ã‚’è¨˜éŒ²
        
        for i, page in enumerate(pdf_reader.pages):
            try:
                page_text = page.extract_text()
                # Ensure page_text is not None and convert to string if needed
                if page_text is not None:
                    page_text = ensure_string(page_text).replace('\x00', '') # ğŸ§¼ Remove NUL characters
                    
                    # ãƒšãƒ¼ã‚¸ã”ã¨ã«æ–‡å­—åŒ–ã‘ã‚’ãƒã‚§ãƒƒã‚¯
                    if check_text_corruption(page_text):
                        print(f"ãƒšãƒ¼ã‚¸ {i+1} ã§æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º: {page_text[:100]}...")
                        corrupted_pages.append(i)
                        # æ–‡å­—åŒ–ã‘ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã¯sectionsã«ä¿å­˜ã—ãªã„
                    else:
                        section_name = f"ãƒšãƒ¼ã‚¸ {i+1}"
                        sections[section_name] = page_text
                        all_text += page_text + "\n"
                        extracted_text += f"=== {section_name} ===\n{page_text}\n\n"
                else:
                    print(f"ãƒšãƒ¼ã‚¸ {i+1} ã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
                    corrupted_pages.append(i)  # ãƒ†ã‚­ã‚¹ãƒˆãªã—ã‚‚æ–‡å­—åŒ–ã‘ã¨ã—ã¦æ‰±ã†
                    # ãƒ†ã‚­ã‚¹ãƒˆãªã—ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã¯sectionsã«ä¿å­˜ã—ãªã„
            except Exception as page_error:
                print(f"ãƒšãƒ¼ã‚¸ {i+1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(page_error)}")
                corrupted_pages.append(i)  # ã‚¨ãƒ©ãƒ¼ã‚‚æ–‡å­—åŒ–ã‘ã¨ã—ã¦æ‰±ã†
                # ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã¯sectionsã«ä¿å­˜ã—ãªã„
        
        # åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆOCRãŒå¿…è¦ã§ãªã„å ´åˆã®ã¿ï¼‰
        all_data = []
        
        # æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿Geminiæ–‡å­—æŠ½å‡ºã‚’å®Ÿè¡Œ
        if len(corrupted_pages) > 0 or (all_text and check_text_corruption(all_text)):
            logger.info(f"PDFæ–‡å­—åŒ–ã‘æ¤œå‡º (ãƒšãƒ¼ã‚¸: {corrupted_pages}) - Geminiæ–‡å­—æŠ½å‡ºã‚’å®Ÿè¡Œ: {filename}")
            
            # Geminiæ–‡å­—æŠ½å‡ºã‚’å®Ÿè¡Œ
            gemini_result = await process_pdf_with_gemini(contents, filename)
            if gemini_result:
                logger.info("Geminiæ–‡å­—æŠ½å‡ºãŒæˆåŠŸã—ã¾ã—ãŸ")
                return gemini_result
            
            logger.warning("Geminiæ–‡å­—æŠ½å‡ºå¤±æ•— - å¤ã„OCRå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            
            # Geminiæ–‡å­—æŠ½å‡ºãŒå¤±æ•—ã—ãŸå ´åˆã¯å¤ã„OCRå‡¦ç†ã‚’è©¦è¡Œ
            try:
                print(f"æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚OCRã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™...")
                ocr_text = await ocr_pdf_to_text_from_bytes(contents)
                
                if ocr_text:
                    # OCRçµæœã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
                    ocr_sections_list = split_ocr_text_into_sections(ocr_text, filename)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                    result_df = pd.DataFrame(ocr_sections_list) if ocr_sections_list else pd.DataFrame({
                        'section': ["OCRçµæœ"],
                        'content': [ensure_string(ocr_text)],
                        'source': ['PDF (OCR)'],
                        'file': [filename],
                        'url': [None]
                    })
                    
                    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¾æ›¸ã‚’ä½œæˆ
                    ocr_sections = {item['section']: item['content'] for item in ocr_sections_list} if ocr_sections_list else {"OCRçµæœ": ensure_string(ocr_text)}
                    
                    # æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
                    ocr_extracted_text = f"=== ãƒ•ã‚¡ã‚¤ãƒ«: {filename} (OCRå‡¦ç†) ===\n\n"
                    for section_name, content in ocr_sections.items():
                        ocr_extracted_text += f"=== {section_name} ===\n{content}\n\n"
                    
                    return result_df, ocr_sections, ocr_extracted_text
                else:
                    raise Exception("OCRã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            except Exception as ocr_error:
                logger.error(f"OCRå‡¦ç†å¤±æ•—: {str(ocr_error)}")
                # OCRå¤±æ•—æ™‚ã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå‡¦ç†ã‚’ç¶šè¡Œ
                pass
        
        # Geminiå‡¦ç†ãŒå¤±æ•—ã—ãŸå ´åˆã€é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’è©¦è¡Œ
        # æ–‡å­—åŒ–ã‘ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã®ã¿ã€é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’è¡Œã†
        if len(corrupted_pages) == 0 and all_text and not check_text_corruption(all_text):
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
            # è¦‹å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³
            heading_pattern = r'^(?:\d+[\.\s]+|ç¬¬\d+[ç« ç¯€]\s+|[\*\#]+\s+)?([A-Za-z\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]{2,}[ï¼š:ã€ã€‚])'
            
            current_section = "ä¸€èˆ¬æƒ…å ±"
            current_content = []
            
            # Ensure all_text is not empty and is a string
            all_text_str = str(all_text) if all_text is not None else ""
            if all_text_str:
                for line in all_text_str.split("\n"):
                    line = str(line).strip()
                    if not line:
                        continue
                    
                    # è¦‹å‡ºã—ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                    if re.search(heading_pattern, line):
                        # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                        if current_content:
                            # å¿…ãšæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‹ã‚‰çµåˆ
                            content_text = "\n".join([ensure_string(item) for item in current_content])
                            all_data.append({
                                'section': str(current_section),
                                'content': content_text,
                                'source': 'PDF',
                                'file': filename,
                                'url': None
                            })
                        
                        # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
                        current_section = str(line)
                        current_content = []
                    else:
                        current_content.append(str(line))
                
                # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                if current_content:
                    # å¿…ãšæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‹ã‚‰çµåˆ
                    content_text = "\n".join([ensure_string(item) for item in current_content])
                    all_data.append({
                        'section': str(current_section),
                        'content': content_text,
                        'source': 'PDF',
                        'file': filename,
                        'url': None
                    })
        else:
            print("æ–‡å­—åŒ–ã‘ã¾ãŸã¯å•é¡Œã®ã‚ã‚‹ãƒšãƒ¼ã‚¸ãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        
        # Geminiå‡¦ç†å¤±æ•—å¾Œã®æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®ã¿ 
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        result_df = pd.DataFrame(all_data) if all_data else pd.DataFrame({
            'section': ["ã‚¨ãƒ©ãƒ¼"],
            'content': ["PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            'source': ['PDF'],
            'file': [filename],
            'url': [None]
        })
        
        # ã™ã¹ã¦ã®åˆ—ã®å€¤ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        for col in result_df.columns:
            result_df[col] = result_df[col].apply(ensure_string)
        
        return result_df, sections, extracted_text
    except Exception as e:
        print(f"PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(traceback.format_exc())
        
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        empty_df = pd.DataFrame({
            'section': ["ã‚¨ãƒ©ãƒ¼"],
            'content': [f"PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"],
            'source': ['PDF'],
            'file': [filename],
            'url': [None]
        })
        empty_sections = {"ã‚¨ãƒ©ãƒ¼": f"PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"}
        error_text = f"=== ãƒ•ã‚¡ã‚¤ãƒ«: {filename} ===\n\n=== ã‚¨ãƒ©ãƒ¼ ===\nPDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n\n"
        
        return empty_df, empty_sections, error_text

async def process_pdf_with_gemini(contents: bytes, filename: str):
    """Geminiç”Ÿãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ä½¿ç”¨ã—ã¦PDFã‹ã‚‰æ–‡å­—ã‚’æŠ½å‡ºã™ã‚‹"""
    try:
        from ..config import setup_gemini
        
        logger.info(f"PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹ï¼ˆGeminiæ–‡å­—æŠ½å‡ºä½¿ç”¨ï¼‰: {filename}")
        
        # Geminiãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        model = setup_gemini()
        if not model:
            logger.error("Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—")
            return None
        
        # ç”Ÿã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp_file:
            tmp_file.write(contents)
            tmp_file_path = tmp_file.name
        
        # Geminiç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆPDFæ–‡å­—æŠ½å‡ºç‰¹åŒ–ï¼‰
        prompt = """
        ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        
        **é‡è¦ãªæŒ‡ç¤ºï¼š**
        1. PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥è§£æã—ã€ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„
        2. æ–‡å­—åŒ–ã‘æ–‡å­—ï¼ˆã€Œ?ã€ã€Œç¸ºã€ã€Œç¹§ã€ã€Œè®’ã€ã€Œ(cid:ã€ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯ã€æ–‡è„ˆã‹ã‚‰æ¨æ¸¬ã—ã¦æ­£ã—ã„æ—¥æœ¬èªã«å¾©å…ƒã—ã¦ãã ã•ã„
        3. PDFã®æ§‹é€ ï¼ˆè¦‹å‡ºã—ã€æ®µè½ã€è¡¨ã€ãƒªã‚¹ãƒˆãªã©ï¼‰ã‚’æ­£ç¢ºã«ä¿æŒã—ã¦ãã ã•ã„
        4. ãƒšãƒ¼ã‚¸ç•ªå·ã‚„ç« æ§‹æˆãŒã‚ã‚Œã°é©åˆ‡ã«è­˜åˆ¥ã—ã¦ãã ã•ã„
        5. å›³è¡¨ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚„æ³¨é‡ˆã‚‚å«ã‚ã¦æŠ½å‡ºã—ã¦ãã ã•ã„
        6. è¡¨ãŒã‚ã‚‹å ´åˆã¯ã€è¡Œã¨åˆ—ã®æ§‹é€ ã‚’ä¿æŒã—ã¦ãã ã•ã„

        **PDFç‰¹æœ‰ã®æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒä¾‹ï¼š**
        - (cid:XXX) â†’ å¯¾å¿œã™ã‚‹æ–‡å­—ã«å¾©å…ƒ
        - ç¸ºã‚…â†’ç¸º â†’ ã‚ã¨
        - è¿ºï½¾é¶ â†’ ç’°å¢ƒ  
        - è³?èŸ‹ â†’ ä¼šç¤¾
        - ç¹§ï½³ç¹ï½³ç¹æ–Î—ç¹ï½¼ç¹§ï½¿ â†’ ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿

        **å‡ºåŠ›å½¢å¼ï¼š**
        å…ƒã®PDFæ§‹é€ ã‚’ä¿ã£ãŸå½¢ã§ã€æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        å„ãƒšãƒ¼ã‚¸ã‚„ç« ç¯€ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«è¦‹å‡ºã—ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
        å¾©å…ƒã§ããªã„æ–‡å­—åŒ–ã‘ã¯ [æ–‡å­—åŒ–ã‘] ã¨æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
        """
        
        def sync_gemini_call():
            try:
                # PDFã‚’ãƒšãƒ¼ã‚¸ã”ã¨ã«ç”»åƒã«å¤‰æ›ã—ã¦Geminiã§å‡¦ç†
                from PIL import Image
                import io
                import fitz  # PyMuPDF
                
                logger.info("PyMuPDFã‚’ä½¿ç”¨ã—ã¦PDFã‚’ç”»åƒã«å¤‰æ›")
                doc = fitz.open(tmp_file_path)
                all_text = ""
                
                # å„ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã¨ã—ã¦å‡¦ç†
                for page_num in range(min(len(doc), 10)):  # æœ€å¤§10ãƒšãƒ¼ã‚¸ã¾ã§
                    try:
                        page = doc[page_num]
                        # ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã«å¤‰æ›
                        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # é«˜è§£åƒåº¦
                        img_data = pix.tobytes("png")
                        
                        # PILã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã—ã¦èª­ã¿è¾¼ã¿
                        img = Image.open(io.BytesIO(img_data))
                        
                        # ãƒšãƒ¼ã‚¸å°‚ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        page_prompt = f"{prompt}\n\nã“ã‚Œã¯PDFã®{page_num + 1}ãƒšãƒ¼ã‚¸ç›®ã§ã™ã€‚"
                        
                        # Geminiã§ç”»åƒã‚’è§£æ
                        response = model.generate_content([page_prompt, img])
                        page_text = response.text if response.text else ""
                        
                        if page_text:
                            all_text += f"\n\n=== ãƒšãƒ¼ã‚¸ {page_num + 1} ===\n{page_text}"
                        
                        logger.info(f"ãƒšãƒ¼ã‚¸ {page_num + 1} ã®å‡¦ç†å®Œäº†: {len(page_text)}æ–‡å­—")
                        
                    except Exception as page_error:
                        logger.error(f"ãƒšãƒ¼ã‚¸ {page_num + 1} ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(page_error)}")
                        all_text += f"\n\n=== ãƒšãƒ¼ã‚¸ {page_num + 1} (ã‚¨ãƒ©ãƒ¼) ===\n[ãƒšãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(page_error)}]"
                
                doc.close()
                return all_text if all_text else ""
                    
            except Exception as e:
                logger.error(f"Gemini PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return ""
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    if os.path.exists(tmp_file_path):
                        os.unlink(tmp_file_path)
                except:
                    pass
        
        extracted_text = await asyncio.to_thread(sync_gemini_call)
        
        if not extracted_text:
            logger.warning("Geminiæ–‡å­—æŠ½å‡ºã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        logger.info(f"Geminiæ–‡å­—æŠ½å‡ºçµæœï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰: {extracted_text[:500]}...")
        
        # æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰DataFrameã‚’ä½œæˆ
        sections = {}
        all_data = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒšãƒ¼ã‚¸ã‚„ç« ç¯€ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
        # ãƒšãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„è¦‹å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        section_patterns = [
            r'^(?:ãƒšãƒ¼ã‚¸\s*\d+|Page\s*\d+|\d+\s*ãƒšãƒ¼ã‚¸)',  # ãƒšãƒ¼ã‚¸ç•ªå·
            r'^(?:ç¬¬\s*\d+\s*[ç« ç¯€]|Chapter\s*\d+|\d+[\.\s]*[ç« ç¯€])',  # ç« ç¯€
            r'^(?:â– |â—|â–²|â—†|ã€[^ã€‘]*ã€‘|\d+[\.\)]\s*)',  # è¦‹å‡ºã—è¨˜å·
        ]
        
        current_section = "å¾©å…ƒã•ã‚ŒãŸPDFãƒ†ã‚­ã‚¹ãƒˆ"
        current_content = []
        
        for line in extracted_text.split("\n"):
            line = ensure_string(line).strip()
            if not line:
                continue
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã‹ã©ã†ã‹ã‚’åˆ¤å®š
            is_section_break = False
            for pattern in section_patterns:
                if re.search(pattern, line):
                    is_section_break = True
                    break
            
            if is_section_break:
                # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                if current_content:
                    content_text = "\n".join([ensure_string(item) for item in current_content])
                    sections[ensure_string(current_section)] = content_text
                    all_data.append({
                        'section': ensure_string(current_section),
                        'content': content_text,
                        'source': 'PDF (Geminiæ–‡å­—æŠ½å‡º)',
                        'file': filename,
                        'url': None
                    })
                
                # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
                current_section = ensure_string(line)
                current_content = []
            else:
                current_content.append(ensure_string(line))
        
        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
        if current_content:
            content_text = "\n".join([ensure_string(item) for item in current_content])
            sections[ensure_string(current_section)] = content_text
            all_data.append({
                'section': ensure_string(current_section),
                'content': content_text,
                'source': 'PDF (Geminiæ–‡å­—æŠ½å‡º)',
                'file': filename,
                'url': None
            })
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã®å ´åˆã®å¯¾å¿œ
        if not all_data:
            all_data.append({
                'section': "æŠ½å‡ºã•ã‚ŒãŸPDFãƒ†ã‚­ã‚¹ãƒˆ",
                'content': ensure_string(extracted_text),
                'source': 'PDF (Geminiæ–‡å­—æŠ½å‡º)',
                'file': filename,
                'url': None
            })
            sections["æŠ½å‡ºã•ã‚ŒãŸPDFãƒ†ã‚­ã‚¹ãƒˆ"] = ensure_string(extracted_text)
        
        result_df = pd.DataFrame(all_data)
        
        # ã™ã¹ã¦ã®åˆ—ã®å€¤ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        for col in result_df.columns:
            result_df[col] = result_df[col].apply(ensure_string)
        
        # å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        full_text = f"=== ãƒ•ã‚¡ã‚¤ãƒ«: {filename} (Gemini PDFæ–‡å­—æŠ½å‡º) ===\n\n"
        for section_name, content in sections.items():
            full_text += f"=== {section_name} ===\n{content}\n\n"
        
        logger.info(f"PDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†ï¼ˆGeminiæ–‡å­—æŠ½å‡ºï¼‰: {len(result_df)} ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
        return result_df, sections, full_text
        
    except Exception as e:
        logger.error(f"GeminiPDFãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None 