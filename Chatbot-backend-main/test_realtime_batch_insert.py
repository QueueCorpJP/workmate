#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒæŒ¿å…¥ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
50å€‹å˜ä½ã§embeddingç”Ÿæˆâ†’å³åº§ã«insertã‚’ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import logging
import sys
import os
from datetime import datetime
from typing import List, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.document_processor import DocumentProcessor

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_realtime_batch_processing():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        # DocumentProcessorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        processor = DocumentProcessor()
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆ120å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§50å€‹å˜ä½ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆï¼‰
        test_chunks = []
        for i in range(120):
            test_chunks.append({
                "chunk_index": i,
                "content": f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ {i}: " + 
                          "ã“ã®ãƒãƒ£ãƒ³ã‚¯ã¯50å€‹å˜ä½ã§embeddingç”Ÿæˆã¨åŒæ™‚ã«Supabaseã«ä¿å­˜ã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆã§ã™ã€‚" +
                          ("ãƒ†ã‚¹ãƒˆå†…å®¹ã‚’å……å®Ÿã•ã›ã‚‹ãŸã‚ã®è¿½åŠ ãƒ†ã‚­ã‚¹ãƒˆã€‚" * 5)
            })
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        doc_id = f"realtime_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        company_id = "test_company_realtime"
        doc_name = "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆæ–‡æ›¸"
        
        logger.info(f"ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        logger.info(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
        logger.info(f"ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: 50å€‹")
        logger.info(f"ğŸ¯ äºˆæƒ³ãƒãƒƒãƒæ•°: {(len(test_chunks) + 49) // 50}")
        logger.info(f"ğŸ’¡ æœŸå¾…å‹•ä½œ: 50å€‹ã®embeddingå®Œæˆâ†’å³åº§ã«insert")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒä¿å­˜ã®å®Ÿè¡Œ
        start_time = datetime.now()
        result = await processor._save_chunks_to_database(
            doc_id=doc_id,
            chunks=test_chunks,
            company_id=company_id,
            doc_name=doc_name
        )
        end_time = datetime.now()
        
        # çµæœã®è¡¨ç¤º
        processing_time = (end_time - start_time).total_seconds()
        logger.info(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        logger.info(f"ğŸ“ˆ å‡¦ç†çµæœ:")
        logger.info(f"  - ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {result['total_chunks']}")
        logger.info(f"  - ä¿å­˜æˆåŠŸ: {result['saved_chunks']}")
        logger.info(f"  - embeddingæˆåŠŸ: {result['successful_embeddings']}")
        logger.info(f"  - embeddingå¤±æ•—: {result['failed_embeddings']}")
        logger.info(f"  - å†è©¦è¡Œå›æ•°: {result['retry_attempts']}")
        
        # æˆåŠŸç‡ã®è¨ˆç®—
        if result['total_chunks'] > 0:
            save_rate = (result['saved_chunks'] / result['total_chunks']) * 100
            embedding_rate = (result['successful_embeddings'] / result['total_chunks']) * 100
            logger.info(f"ğŸ“Š æˆåŠŸç‡:")
            logger.info(f"  - ä¿å­˜æˆåŠŸç‡: {save_rate:.1f}%")
            logger.info(f"  - embeddingæˆåŠŸç‡: {embedding_rate:.1f}%")
        
        # ãƒ†ã‚¹ãƒˆçµæœã®åˆ¤å®š
        if result['saved_chunks'] > 0:
            logger.info(f"ğŸ‰ ãƒ†ã‚¹ãƒˆæˆåŠŸ: {result['saved_chunks']}/{result['total_chunks']} ãƒãƒ£ãƒ³ã‚¯ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            return True
        else:
            logger.warning(f"âš ï¸ ãƒ†ã‚¹ãƒˆå¤±æ•—: ãƒãƒ£ãƒ³ã‚¯ãŒä¿å­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
        return False

async def test_small_realtime_batch():
    """å°ã•ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒã§ã®ãƒ†ã‚¹ãƒˆï¼ˆ75å€‹ â†’ 50å€‹ + 25å€‹ï¼‰"""
    try:
        processor = DocumentProcessor()
        
        # 75å€‹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆ50å€‹ + 25å€‹ã®ãƒãƒƒãƒã«ãªã‚‹ï¼‰
        test_chunks = []
        for i in range(75):
            test_chunks.append({
                "chunk_index": i,
                "content": f"å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ {i}: " + "ãƒ†ã‚¹ãƒˆå†…å®¹ " * 15
            })
        
        doc_id = f"small_realtime_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        company_id = "test_company_small_realtime"
        doc_name = "å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ"
        
        logger.info(f"ğŸ”¬ å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆé–‹å§‹: {len(test_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
        logger.info(f"ğŸ’¡ æœŸå¾…å‹•ä½œ: 1å›ç›®50å€‹â†’insert, 2å›ç›®25å€‹â†’insert")
        
        result = await processor._save_chunks_to_database(
            doc_id=doc_id,
            chunks=test_chunks,
            company_id=company_id,
            doc_name=doc_name
        )
        
        logger.info(f"âœ… å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆçµæœ: {result['saved_chunks']}/{result['total_chunks']} ä¿å­˜æˆåŠŸ")
        return result['saved_chunks'] > 0
        
    except Exception as e:
        logger.error(f"âŒ å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("=" * 70)
    logger.info("ğŸ§ª ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒæŒ¿å…¥ãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info("=" * 70)
    
    # å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "=" * 50)
    logger.info("1ï¸âƒ£ å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆï¼ˆ75å€‹ â†’ 50å€‹+25å€‹ï¼‰")
    logger.info("=" * 50)
    small_test_result = await test_small_realtime_batch()
    
    # å¤§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "=" * 50)
    logger.info("2ï¸âƒ£ å¤§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆï¼ˆ120å€‹ â†’ 50å€‹Ã—2+20å€‹ï¼‰")
    logger.info("=" * 50)
    large_test_result = await test_realtime_batch_processing()
    
    # æœ€çµ‚çµæœ
    logger.info("\n" + "=" * 70)
    logger.info("ğŸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    logger.info("=" * 70)
    logger.info(f"å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if small_test_result else 'âŒ å¤±æ•—'}")
    logger.info(f"å¤§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if large_test_result else 'âŒ å¤±æ•—'}")
    
    if small_test_result and large_test_result:
        logger.info("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒƒãƒæŒ¿å…¥ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        logger.info("ğŸ’¡ 50å€‹ã®embeddingå®Œæˆâ†’å³åº§ã«insertãŒå®Ÿè£…ã•ã‚Œã¾ã—ãŸ")
    else:
        logger.warning("âš ï¸ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    asyncio.run(main())