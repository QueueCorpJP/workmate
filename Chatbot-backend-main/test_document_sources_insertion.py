"""
ğŸ“¤ document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æŒ¿å…¥ãƒ†ã‚¹ãƒˆ
ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«doc_idãŒæ­£ã—ãæŒ¿å…¥ã•ã‚Œã‚‹ã‹ã‚’ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import asyncio
import tempfile
import uuid
from datetime import datetime
from fastapi import UploadFile
from io import BytesIO

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from supabase_adapter import get_supabase_client, insert_data, select_data
from modules.document_processor import DocumentProcessor
from modules.document_processor_record_based import DocumentProcessorRecordBased

async def test_document_sources_insertion():
    """document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æŒ¿å…¥ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
    test_user_id = "test-user-" + str(uuid.uuid4())[:8]
    test_company_id = "test-company-" + str(uuid.uuid4())[:8]
    test_filename = "test_document.txt"
    test_content = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚\n\nãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã¨chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸¡æ–¹ã«doc_idãŒæ­£ã—ãæŒ¿å…¥ã•ã‚Œã‚‹ã‹ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™ã€‚"
    
    try:
        # 1. Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
        print("1ï¸âƒ£ Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç¢ºèª")
        supabase = get_supabase_client()
        if not supabase:
            raise Exception("Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("âœ… Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—æˆåŠŸ")
        
        # 2. ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ã‚’ä½œæˆ
        print("2ï¸âƒ£ ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ä½œæˆ")
        
        # ãƒ†ã‚¹ãƒˆç”¨ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ä½œæˆ
        company_data = {
            "id": test_company_id,
            "name": "Test Company",
            "created_at": datetime.now().isoformat()
        }
        
        try:
            company_result = insert_data("companies", company_data)
            print(f"âœ… ãƒ†ã‚¹ãƒˆç”¨ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ä½œæˆ: {test_company_id}")
        except Exception as e:
            print(f"âš ï¸ ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼ï¼ˆæ—¢å­˜ã®å¯èƒ½æ€§ï¼‰: {e}")
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
        user_data = {
            "id": test_user_id,
            "company_id": test_company_id,
            "name": "Test User",
            "email": f"test-{test_user_id}@example.com",
            "created_at": datetime.now().isoformat()
        }
        
        try:
            user_result = insert_data("users", user_data)
            print(f"âœ… ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ: {test_user_id}")
        except Exception as e:
            print(f"âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼ï¼ˆæ—¢å­˜ã®å¯èƒ½æ€§ï¼‰: {e}")
        
        # 3. ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        print("3ï¸âƒ£ ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")
        test_file_content = test_content.encode('utf-8')
        test_file = UploadFile(
            filename=test_filename,
            file=BytesIO(test_file_content),
            size=len(test_file_content)
        )
        
        # 4. DocumentProcessorã§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        print("4ï¸âƒ£ DocumentProcessorã§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ")
        processor = DocumentProcessor()
        
        try:
            result = await processor.process_uploaded_file(
                file=test_file,
                user_id=test_user_id,
                company_id=test_company_id
            )
            
            print(f"âœ… DocumentProcessorå‡¦ç†æˆåŠŸ:")
            print(f"   - document_id: {result.get('document_id')}")
            print(f"   - filename: {result.get('filename')}")
            print(f"   - total_chunks: {result.get('total_chunks')}")
            
            doc_id = result.get('document_id')
            
            # 5. document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
            print("5ï¸âƒ£ document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª")
            doc_sources_result = select_data(
                "document_sources",
                columns="*",
                filters={"id": doc_id}
            )
            
            if doc_sources_result.data and len(doc_sources_result.data) > 0:
                print(f"âœ… document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ç™ºè¦‹:")
                doc_record = doc_sources_result.data[0]
                print(f"   - id: {doc_record.get('id')}")
                print(f"   - name: {doc_record.get('name')}")
                print(f"   - company_id: {doc_record.get('company_id')}")
                print(f"   - uploaded_by: {doc_record.get('uploaded_by')}")
            else:
                print("âŒ document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # 6. chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
            print("6ï¸âƒ£ chunksãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª")
            chunks_result = select_data(
                "chunks",
                columns="*",
                filters={"doc_id": doc_id}
            )
            
            if chunks_result.data and len(chunks_result.data) > 0:
                print(f"âœ… chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ç™ºè¦‹: {len(chunks_result.data)}ä»¶")
                for i, chunk in enumerate(chunks_result.data[:3]):  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                    print(f"   - chunk {i}: doc_id={chunk.get('doc_id')}, chunk_index={chunk.get('chunk_index')}")
            else:
                print("âŒ chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            print("ğŸ‰ DocumentProcessor ãƒ†ã‚¹ãƒˆæˆåŠŸ: document_sourcesã¨chunksã®ä¸¡æ–¹ã«doc_idãŒæ­£ã—ãæŒ¿å…¥ã•ã‚Œã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ DocumentProcessorå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        # 7. DocumentProcessorRecordBasedã§Excelãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ
        print("\n7ï¸âƒ£ DocumentProcessorRecordBasedã§Excelãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ")
        
        # ç°¡å˜ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        try:
            import pandas as pd
            excel_data = pd.DataFrame({
                'Name': ['ç”°ä¸­å¤ªéƒ', 'ä½è—¤èŠ±å­', 'éˆ´æœ¨ä¸€éƒ'],
                'Age': [30, 25, 35],
                'Department': ['å–¶æ¥­éƒ¨', 'é–‹ç™ºéƒ¨', 'ç·å‹™éƒ¨']
            })
            
            excel_buffer = BytesIO()
            excel_data.to_excel(excel_buffer, index=False, engine='openpyxl')
            excel_buffer.seek(0)
            
            excel_file = UploadFile(
                filename="test_excel.xlsx",
                file=excel_buffer,
                size=len(excel_buffer.getvalue())
            )
            
            record_processor = DocumentProcessorRecordBased()
            
            excel_result = await record_processor.process_uploaded_file(
                file=excel_file,
                user_id=test_user_id,
                company_id=test_company_id
            )
            
            print(f"âœ… DocumentProcessorRecordBasedå‡¦ç†æˆåŠŸ:")
            print(f"   - document_id: {excel_result.get('document_id')}")
            print(f"   - filename: {excel_result.get('filename')}")
            print(f"   - total_chunks: {excel_result.get('total_chunks')}")
            
            excel_doc_id = excel_result.get('document_id')
            
            # document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
            excel_doc_sources_result = select_data(
                "document_sources",
                columns="*",
                filters={"id": excel_doc_id}
            )
            
            if excel_doc_sources_result.data and len(excel_doc_sources_result.data) > 0:
                print(f"âœ… Excel document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ç™ºè¦‹:")
                excel_doc_record = excel_doc_sources_result.data[0]
                print(f"   - id: {excel_doc_record.get('id')}")
                print(f"   - name: {excel_doc_record.get('name')}")
                print(f"   - type: {excel_doc_record.get('type')}")
            else:
                print("âŒ Excel document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
            excel_chunks_result = select_data(
                "chunks",
                columns="*",
                filters={"doc_id": excel_doc_id}
            )
            
            if excel_chunks_result.data and len(excel_chunks_result.data) > 0:
                print(f"âœ… Excel chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ç™ºè¦‹: {len(excel_chunks_result.data)}ä»¶")
            else:
                print("âŒ Excel chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            print("ğŸ‰ DocumentProcessorRecordBased ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except ImportError:
            print("âš ï¸ pandas/openpyxlãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€Excelãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
        except Exception as e:
            print(f"âŒ DocumentProcessorRecordBasedå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        try:
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            supabase = get_supabase_client()
            
            # chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å‰Šé™¤ï¼ˆå¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®ãŸã‚å…ˆã«å‰Šé™¤ï¼‰
            chunks_delete = supabase.table("chunks").delete().like("doc_id", "test-%").execute()
            print(f"ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆç”¨chunksãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {len(chunks_delete.data) if chunks_delete.data else 0}ä»¶")
            
            # document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å‰Šé™¤
            docs_delete = supabase.table("document_sources").delete().eq("company_id", test_company_id).execute()
            print(f"ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆç”¨document_sourcesãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {len(docs_delete.data) if docs_delete.data else 0}ä»¶")
            
            # usersãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å‰Šé™¤
            users_delete = supabase.table("users").delete().eq("id", test_user_id).execute()
            print(f"ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆç”¨usersãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {len(users_delete.data) if users_delete.data else 0}ä»¶")
            
            # companiesãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å‰Šé™¤
            companies_delete = supabase.table("companies").delete().eq("id", test_company_id).execute()
            print(f"ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆç”¨companiesãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {len(companies_delete.data) if companies_delete.data else 0}ä»¶")
            
        except Exception as cleanup_error:
            print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {cleanup_error}")

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ğŸ“¤ document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    success = await test_document_sources_insertion()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†: document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æŒ¿å…¥ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: document_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æŒ¿å…¥ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())