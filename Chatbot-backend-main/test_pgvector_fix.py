#!/usr/bin/env python3
"""
pgvectoræ‹¡å¼µæ©Ÿèƒ½ä¿®æ­£ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®å•é¡Œã‚’è¨ºæ–­ãƒ»ä¿®æ­£ã—ã€å‹•ä½œç¢ºèªã‚’è¡Œã†
"""

import os
import sys
import logging
from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import RealDictCursor

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_db_url():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’æ§‹ç¯‰"""
    supabase_url = os.getenv("SUPABASE_URL")
    db_password = os.getenv("DB_PASSWORD")
    
    if not supabase_url or not db_password:
        raise ValueError("SUPABASE_URL ã¨ DB_PASSWORD ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # Supabase URLã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’æŠ½å‡º
    if "supabase.co" in supabase_url:
        project_id = supabase_url.split("://")[1].split(".")[0]
        return f"postgresql://postgres.{project_id}:{db_password}@aws-0-ap-northeast-1.pooler.supabase.com:6543/postgres"
    else:
        db_url = os.getenv("DATABASE_URL")
        if not db_url:
            raise ValueError("DATABASE_URL ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return db_url

def check_pgvector_status(db_url):
    """pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®ç¢ºèª
                cur.execute("""
                    SELECT 
                        extname,
                        extversion,
                        extrelocatable
                    FROM pg_extension 
                    WHERE extname = 'vector'
                """)
                result = cur.fetchone()
                
                if result:
                    logger.info(f"âœ… pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒæœ‰åŠ¹: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {result['extversion']}")
                    return True
                else:
                    logger.warning("âš ï¸ pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™")
                    return False
                    
    except Exception as e:
        logger.error(f"âŒ pgvectorçŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

def enable_pgvector(db_url):
    """pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–"""
    try:
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                logger.info("ğŸ”§ pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ä¸­...")
                
                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
                cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                conn.commit()
                
                # ç¢ºèª
                cur.execute("""
                    SELECT 
                        extname,
                        extversion
                    FROM pg_extension 
                    WHERE extname = 'vector'
                """)
                result = cur.fetchone()
                
                if result:
                    logger.info(f"âœ… pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {result['extversion']}")
                    return True
                else:
                    logger.error("âŒ pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
                    
    except Exception as e:
        logger.error(f"âŒ pgvectoræœ‰åŠ¹åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_chunks_table_schema(db_url):
    """chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèª"""
    try:
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                # embeddingã‚«ãƒ©ãƒ ã®å‹ç¢ºèª
                cur.execute("""
                    SELECT 
                        column_name, 
                        data_type, 
                        udt_name,
                        column_default
                    FROM information_schema.columns 
                    WHERE table_name = 'chunks' 
                    AND column_name = 'embedding'
                """)
                result = cur.fetchone()
                
                if result:
                    logger.info(f"ğŸ“Š embeddingã‚«ãƒ©ãƒ æƒ…å ±:")
                    logger.info(f"  - ãƒ‡ãƒ¼ã‚¿å‹: {result['data_type']}")
                    logger.info(f"  - UDTå: {result['udt_name']}")
                    logger.info(f"  - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤: {result['column_default']}")
                    
                    # VECTORå‹ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                    if result['udt_name'] == 'vector':
                        logger.info("âœ… embeddingã‚«ãƒ©ãƒ ã¯VECTORå‹ã§ã™")
                        return True
                    else:
                        logger.warning(f"âš ï¸ embeddingã‚«ãƒ©ãƒ ãŒVECTORå‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {result['udt_name']}")
                        return False
                else:
                    logger.error("âŒ embeddingã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return False
                    
    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚­ãƒ¼ãƒç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

def fix_embedding_column(db_url):
    """embeddingã‚«ãƒ©ãƒ ã‚’VECTORå‹ã«ä¿®æ­£"""
    try:
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                logger.info("ğŸ”§ embeddingã‚«ãƒ©ãƒ ã‚’VECTORå‹ã«ä¿®æ­£ä¸­...")
                
                # æ—¢å­˜ã®embeddingã‚«ãƒ©ãƒ ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ
                cur.execute("ALTER TABLE chunks DROP COLUMN IF EXISTS embedding;")
                cur.execute("ALTER TABLE chunks ADD COLUMN embedding VECTOR(768);")
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_chunks_embedding_ivfflat 
                    ON chunks USING ivfflat (embedding vector_cosine_ops) 
                    WITH (lists = 100);
                """)
                
                # ä¼šç¤¾IDã¨embeddingã®è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_chunks_company_embedding 
                    ON chunks(company_id) 
                    WHERE embedding IS NOT NULL;
                """)
                
                conn.commit()
                
                logger.info("âœ… embeddingã‚«ãƒ©ãƒ ã‚’VECTOR(768)å‹ã«ä¿®æ­£ã—ã¾ã—ãŸ")
                logger.info("âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ")
                return True
                
    except Exception as e:
        logger.error(f"âŒ embeddingã‚«ãƒ©ãƒ ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_vector_operations(db_url):
    """ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                logger.info("ğŸ§ª ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆä¸­...")
                
                # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ
                test_vector = [0.1] * 768  # 768æ¬¡å…ƒã®ãƒ†ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«
                
                # ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã®ãƒ†ã‚¹ãƒˆ
                cur.execute("""
                    SELECT 
                        %s::vector <=> %s::vector as cosine_distance,
                        1 - (%s::vector <=> %s::vector) as cosine_similarity
                """, [test_vector, test_vector, test_vector, test_vector])
                
                result = cur.fetchone()
                
                if result:
                    logger.info(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆæˆåŠŸ:")
                    logger.info(f"  - ã‚³ã‚µã‚¤ãƒ³è·é›¢: {result['cosine_distance']}")
                    logger.info(f"  - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦: {result['cosine_similarity']}")
                    return True
                else:
                    logger.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆå¤±æ•—")
                    return False
                    
    except Exception as e:
        logger.error(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_vector_search_fixed():
    """ä¿®æ­£ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª ä¿®æ­£ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        # ä¿®æ­£ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from modules.vector_search_fixed import VectorSearchSystem
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        vector_search = VectorSearchSystem()
        
        # ãƒ†ã‚¹ãƒˆæ¤œç´¢
        test_query = "æ–™é‡‘è¡¨"
        test_company_id = "77acc2e2-ce67-458d-bd38-7af0476b297a"
        
        logger.info(f"ğŸ” ãƒ†ã‚¹ãƒˆæ¤œç´¢å®Ÿè¡Œ: '{test_query}'")
        results = vector_search.vector_similarity_search(
            query=test_query,
            company_id=test_company_id,
            limit=5
        )
        
        if results:
            logger.info(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆæˆåŠŸ: {len(results)}ä»¶ã®çµæœ")
            for i, result in enumerate(results[:3]):
                logger.info(f"  {i+1}. {result['document_name']} (é¡ä¼¼åº¦: {result['similarity_score']:.3f})")
            return True
        else:
            logger.warning("âš ï¸ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœãŒç©ºã§ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")
            return True  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã ã‘ã§ã€ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸
            
    except Exception as e:
        logger.error(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸš€ pgvectorä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLå–å¾—
        db_url = get_db_url()
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ±ã‚’å–å¾—")
        
        # 1. pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®çŠ¶æ…‹ç¢ºèª
        pgvector_enabled = check_pgvector_status(db_url)
        
        # 2. pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒç„¡åŠ¹ã®å ´åˆã€æœ‰åŠ¹åŒ–ã‚’è©¦è¡Œ
        if not pgvector_enabled:
            logger.info("ğŸ”§ pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–ã‚’è©¦è¡Œä¸­...")
            pgvector_enabled = enable_pgvector(db_url)
        
        if not pgvector_enabled:
            logger.error("âŒ pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # 3. chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒç¢ºèª
        schema_ok = check_chunks_table_schema(db_url)
        
        # 4. embeddingã‚«ãƒ©ãƒ ãŒVECTORå‹ã§ãªã„å ´åˆã€ä¿®æ­£
        if not schema_ok:
            logger.info("ğŸ”§ embeddingã‚«ãƒ©ãƒ ã®ä¿®æ­£ã‚’è©¦è¡Œä¸­...")
            schema_ok = fix_embedding_column(db_url)
        
        if not schema_ok:
            logger.error("âŒ embeddingã‚«ãƒ©ãƒ ã®ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # 5. ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã®ãƒ†ã‚¹ãƒˆ
        vector_ops_ok = test_vector_operations(db_url)
        
        if not vector_ops_ok:
            logger.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # 6. ä¿®æ­£ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
        search_ok = test_vector_search_fixed()
        
        if search_ok:
            logger.info("ğŸ‰ pgvectorä¿®æ­£ãƒ†ã‚¹ãƒˆå®Œäº† - ã™ã¹ã¦æˆåŠŸ!")
            logger.info("âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
            return True
        else:
            logger.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)