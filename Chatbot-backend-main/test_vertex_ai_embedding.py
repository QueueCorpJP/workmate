"""
ğŸ§ª Vertex AI Embedding ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Vertex AI gemini-embedding-001 ã®å‹•ä½œç¢ºèªç”¨
"""

import os
import sys
import asyncio
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.vertex_ai_embedding import get_vertex_ai_embedding_client, vertex_ai_embedding_available
from modules.auto_embedding import AutoEmbeddingGenerator
from modules.realtime_rag import RealtimeRAGProcessor
from modules.vector_search import VectorSearchSystem

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

def test_vertex_ai_client():
    """Vertex AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ğŸ§ª Vertex AI Embedding ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    if not vertex_ai_embedding_available():
        print("âŒ Vertex AI Embedding ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        print("   - GOOGLE_CLOUD_PROJECT ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        print("   - USE_VERTEX_AI=true ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return False
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
    client = get_vertex_ai_embedding_client()
    if not client:
        print("âŒ Vertex AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—")
        return False
    
    print("âœ… Vertex AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ
    test_texts = [
        "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
        "Vertex AI embedding test text.",
        "æ—¥æœ¬èªã¨è‹±èªã®æ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆ mixed language text."
    ]
    
    # å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“ å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° ãƒ†ã‚¹ãƒˆ:")
    for i, text in enumerate(test_texts, 1):
        print(f"  {i}. ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
        embedding = client.generate_embedding(text)
        
        if embedding:
            print(f"     âœ… æˆåŠŸ: {len(embedding)}æ¬¡å…ƒ")
            print(f"     æœ€åˆã®5è¦ç´ : {embedding[:5]}")
        else:
            print(f"     âŒ å¤±æ•—")
    
    # ãƒãƒƒãƒãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    print(f"\nğŸ“¦ ãƒãƒƒãƒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° ãƒ†ã‚¹ãƒˆ:")
    batch_embeddings = client.generate_embeddings_batch(test_texts)
    
    for i, (text, embedding) in enumerate(zip(test_texts, batch_embeddings), 1):
        print(f"  {i}. ãƒ†ã‚­ã‚¹ãƒˆ: {text[:30]}...")
        if embedding:
            print(f"     âœ… æˆåŠŸ: {len(embedding)}æ¬¡å…ƒ")
        else:
            print(f"     âŒ å¤±æ•—")
    
    return True

def test_auto_embedding_integration():
    """AutoEmbeddingGenerator ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ”„ AutoEmbeddingGenerator çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        generator = AutoEmbeddingGenerator()
        print("âœ… AutoEmbeddingGenerator åˆæœŸåŒ–æˆåŠŸ")
        
        # Vertex AIä½¿ç”¨çŠ¶æ³ã®ç¢ºèª
        if generator.use_vertex_ai:
            print("ğŸ§  Vertex AI ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        else:
            print("ğŸ”„ æ¨™æº– Gemini API ãƒ¢ãƒ¼ãƒ‰")
        
        print(f"ğŸ“‹ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«: {generator.embedding_model}")
        
        return True
        
    except Exception as e:
        print(f"âŒ AutoEmbeddingGenerator åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def test_realtime_rag_integration():
    """RealtimeRAGProcessor ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("âš¡ RealtimeRAGProcessor çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        processor = RealtimeRAGProcessor()
        print("âœ… RealtimeRAGProcessor åˆæœŸåŒ–æˆåŠŸ")
        
        # Vertex AIä½¿ç”¨çŠ¶æ³ã®ç¢ºèª
        if processor.use_vertex_ai:
            print("ğŸ§  Vertex AI ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        else:
            print("ğŸ”„ æ¨™æº– Gemini API ãƒ¢ãƒ¼ãƒ‰")
        
        print(f"ğŸ“‹ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«: {processor.embedding_model}")
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        test_question = "ãƒ†ã‚¹ãƒˆç”¨ã®è³ªå•ã§ã™"
        print(f"\nğŸ“ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ: {test_question}")
        
        try:
            embedding = await processor.step2_generate_embedding(test_question)
            print(f"âœ… ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”ŸæˆæˆåŠŸ: {len(embedding)}æ¬¡å…ƒ")
            return True
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
    except Exception as e:
        print(f"âŒ RealtimeRAGProcessor åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_vector_search_integration():
    """VectorSearchSystem ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ” VectorSearchSystem çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        search_system = VectorSearchSystem()
        print("âœ… VectorSearchSystem åˆæœŸåŒ–æˆåŠŸ")
        
        # Vertex AIä½¿ç”¨çŠ¶æ³ã®ç¢ºèª
        if search_system.use_vertex_ai:
            print("ğŸ§  Vertex AI ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        else:
            print("ğŸ”„ æ¨™æº– Gemini API ãƒ¢ãƒ¼ãƒ‰")
        
        print(f"ğŸ“‹ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«: {search_system.model}")
        
        # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        test_query = "ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ã‚¨ãƒªã§ã™"
        print(f"\nğŸ“ ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ: {test_query}")
        
        embedding = search_system.generate_query_embedding(test_query)
        if embedding:
            print(f"âœ… ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”ŸæˆæˆåŠŸ: {len(embedding)}æ¬¡å…ƒ")
            return True
        else:
            print(f"âŒ ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•—")
            return False
        
    except Exception as e:
        print(f"âŒ VectorSearchSystem åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def print_environment_info():
    """ç’°å¢ƒæƒ…å ±ã®è¡¨ç¤º"""
    print("=" * 60)
    print("ğŸ”§ ç’°å¢ƒè¨­å®šæƒ…å ±")
    print("=" * 60)
    
    print(f"EMBEDDING_MODEL: {os.getenv('EMBEDDING_MODEL', 'Not set')}")
    print(f"USE_VERTEX_AI: {os.getenv('USE_VERTEX_AI', 'Not set')}")
    print(f"GOOGLE_CLOUD_PROJECT: {os.getenv('GOOGLE_CLOUD_PROJECT', 'Not set')}")
    print(f"GOOGLE_API_KEY: {'Set' if os.getenv('GOOGLE_API_KEY') else 'Not set'}")
    print(f"AUTO_GENERATE_EMBEDDINGS: {os.getenv('AUTO_GENERATE_EMBEDDINGS', 'Not set')}")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ Vertex AI Embedding çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ç’°å¢ƒæƒ…å ±è¡¨ç¤º
    print_environment_info()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tests = [
        ("Vertex AI Client", test_vertex_ai_client),
        ("AutoEmbedding Integration", test_auto_embedding_integration),
        ("RealtimeRAG Integration", test_realtime_rag_integration),
        ("VectorSearch Integration", test_vector_search_integration),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ çµæœ: {passed}/{len(results)} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if passed == len(results):
        print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    else:
        print("âš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    # ã‚¿ã‚¤ãƒä¿®æ­£
    def vector_ai_embedding_available():
        return vertex_ai_embedding_available()
    
    asyncio.run(main())