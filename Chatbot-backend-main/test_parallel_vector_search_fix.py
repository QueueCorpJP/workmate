#!/usr/bin/env python3
"""
ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ä¿®æ­£ãƒ†ã‚¹ãƒˆ
- clientå±æ€§ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ç¢ºèª
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®ç¢ºèª
- ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã®ç¢ºèª
"""

import sys
import os
import logging
import asyncio
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_parallel_vector_search_initialization():
    """ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    try:
        from modules.parallel_vector_search import ParallelVectorSearchSystem
        
        logger.info("ğŸ§ª ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        search_system = ParallelVectorSearchSystem()
        
        logger.info("âœ… ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–æˆåŠŸ")
        return search_system
        
    except Exception as e:
        logger.error(f"âŒ ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return None

def test_database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    try:
        import psycopg2
        from psycopg2.extras import RealDictCursor
        
        logger.info("ğŸ§ª ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’å–å¾—
        supabase_url = os.getenv("SUPABASE_URL")
        db_password = os.getenv("DB_PASSWORD")
        
        if not supabase_url or not db_password:
            logger.error("âŒ ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return False
        
        # æ¥ç¶šURLæ§‹ç¯‰
        project_id = supabase_url.split("://")[1].split(".")[0]
        db_url = f"postgresql://postgres.{project_id}:{db_password}@aws-0-ap-northeast-1.pooler.supabase.com:6543/postgres"
        
        logger.info(f"æ¥ç¶šå…ˆ: {project_id}.supabase.co")
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        with psycopg2.connect(db_url, cursor_factory=RealDictCursor) as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT 1 as test")
                result = cur.fetchone()
                
                if result and result['test'] == 1:
                    logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ")
                    
                    # chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
                    cur.execute("""
                        SELECT COUNT(*) as chunk_count 
                        FROM chunks 
                        WHERE embedding IS NOT NULL
                    """)
                    chunk_result = cur.fetchone()
                    logger.info(f"ğŸ“Š åŸ‹ã‚è¾¼ã¿æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_result['chunk_count']}")
                    
                    return True
                else:
                    logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—")
                    return False
        
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

def test_embedding_generation():
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
    try:
        import google.generativeai as genai
        
        logger.info("ğŸ§ª ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # APIè¨­å®š
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            logger.error("âŒ Google API Key ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        genai.configure(api_key=api_key)
        model = "models/gemini-embedding-exp-03-07"
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_query = "ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ã‚¨ãƒªã§ã™"
        
        logger.info(f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: {test_query}")
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
        response = genai.embed_content(
            model=model,
            content=test_query
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
        embedding_vector = None
        
        if isinstance(response, dict) and 'embedding' in response:
            embedding_vector = response['embedding']
        elif hasattr(response, 'embedding') and response.embedding:
            embedding_vector = response.embedding
        else:
            logger.error(f"âŒ äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
            return False
        
        if embedding_vector and len(embedding_vector) > 0:
            logger.info(f"âœ… ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”ŸæˆæˆåŠŸ: {len(embedding_vector)}æ¬¡å…ƒ")
            return True
        else:
            logger.error("âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå¤±æ•—")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

def test_sync_parallel_search():
    """åŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª åŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        search_system = test_parallel_vector_search_initialization()
        if not search_system:
            return False
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_query = "5000å††ä»¥ä¸‹"
        company_id = "77acc2e2-ce67-458d-bd38-7af0476b297a"
        
        logger.info(f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: {test_query}")
        logger.info(f"ä¼šç¤¾ID: {company_id}")
        
        # åŒæœŸä¸¦åˆ—æ¤œç´¢å®Ÿè¡Œ
        result = search_system.parallel_comprehensive_search_sync(
            query=test_query,
            company_id=company_id,
            max_results=10
        )
        
        if result:
            logger.info(f"âœ… åŒæœŸä¸¦åˆ—æ¤œç´¢æˆåŠŸ: {len(result)}æ–‡å­—ã®çµæœ")
            logger.info(f"çµæœã®å…ˆé ­200æ–‡å­—: {result[:200]}...")
            return True
        else:
            logger.warning("âš ï¸ åŒæœŸä¸¦åˆ—æ¤œç´¢ã¯æˆåŠŸã—ãŸãŒã€çµæœãŒç©ºã§ã™")
            return True  # ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ã®ã§æˆåŠŸã¨ã™ã‚‹
        
    except Exception as e:
        logger.error(f"âŒ åŒæœŸä¸¦åˆ—æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

async def test_async_parallel_search():
    """éåŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª éåŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        search_system = test_parallel_vector_search_initialization()
        if not search_system:
            return False
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_query = "5000å††ä»¥ä¸‹"
        company_id = "77acc2e2-ce67-458d-bd38-7af0476b297a"
        
        logger.info(f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: {test_query}")
        logger.info(f"ä¼šç¤¾ID: {company_id}")
        
        # éåŒæœŸä¸¦åˆ—æ¤œç´¢å®Ÿè¡Œ
        result = await search_system.parallel_comprehensive_search(
            query=test_query,
            company_id=company_id,
            max_results=10
        )
        
        if result:
            logger.info(f"âœ… éåŒæœŸä¸¦åˆ—æ¤œç´¢æˆåŠŸ: {len(result)}æ–‡å­—ã®çµæœ")
            logger.info(f"çµæœã®å…ˆé ­200æ–‡å­—: {result[:200]}...")
            return True
        else:
            logger.warning("âš ï¸ éåŒæœŸä¸¦åˆ—æ¤œç´¢ã¯æˆåŠŸã—ãŸãŒã€çµæœãŒç©ºã§ã™")
            return True  # ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ã®ã§æˆåŠŸã¨ã™ã‚‹
        
    except Exception as e:
        logger.error(f"âŒ éåŒæœŸä¸¦åˆ—æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info("ğŸš€ ä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    test_results = []
    
    # 1. åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "="*50)
    logger.info("1. åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ")
    logger.info("="*50)
    init_result = test_parallel_vector_search_initialization()
    test_results.append(("åˆæœŸåŒ–", init_result is not None))
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "="*50)
    logger.info("2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    logger.info("="*50)
    db_result = test_database_connection()
    test_results.append(("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š", db_result))
    
    # 3. ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "="*50)
    logger.info("3. ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    logger.info("="*50)
    embedding_result = test_embedding_generation()
    test_results.append(("ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ", embedding_result))
    
    # 4. åŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "="*50)
    logger.info("4. åŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    logger.info("="*50)
    sync_result = test_sync_parallel_search()
    test_results.append(("åŒæœŸä¸¦åˆ—æ¤œç´¢", sync_result))
    
    # 5. éåŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    logger.info("\n" + "="*50)
    logger.info("5. éåŒæœŸä¸¦åˆ—æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    logger.info("="*50)
    async_result = asyncio.run(test_async_parallel_search())
    test_results.append(("éåŒæœŸä¸¦åˆ—æ¤œç´¢", async_result))
    
    # çµæœã‚µãƒãƒªãƒ¼
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    logger.info("="*50)
    
    for test_name, result in test_results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        logger.info(f"{test_name}: {status}")
    
    success_count = sum(1 for _, result in test_results if result)
    total_count = len(test_results)
    
    logger.info(f"\nğŸ¯ ç·åˆçµæœ: {success_count}/{total_count} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if success_count == total_count:
        logger.info("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        return True
    else:
        logger.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)