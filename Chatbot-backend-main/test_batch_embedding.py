#!/usr/bin/env python3
"""
ğŸ§ª ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ã—ã„ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œã‚’æ¤œè¨¼
"""

import os
import sys
import asyncio
import logging
from datetime import datetime
from dotenv import load_dotenv
from modules.batch_embedding import BatchEmbeddingGenerator, batch_generate_embeddings_for_all_pending
from supabase_adapter import get_supabase_client, select_data, insert_data

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

async def test_batch_embedding_system():
    """ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # 1. ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        logger.info("ğŸ“‹ ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯...")
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        auto_embed = os.getenv("AUTO_GENERATE_EMBEDDINGS", "false").lower()
        
        if not api_key:
            logger.error("âŒ GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        logger.info(f"âœ… API Key: è¨­å®šæ¸ˆã¿")
        logger.info(f"âœ… AUTO_GENERATE_EMBEDDINGS: {auto_embed}")
        
        # 2. ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå™¨ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ”§ ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå™¨åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ...")
        generator = BatchEmbeddingGenerator()
        
        if not generator._init_clients():
            logger.error("âŒ ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—")
            return False
        
        logger.info("âœ… ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå™¨åˆæœŸåŒ–æˆåŠŸ")
        
        # 3. æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã®ç¢ºèª
        logger.info("ğŸ“Š æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ç¢ºèª...")
        pending_chunks = generator._get_pending_chunks(limit=20)
        
        if not pending_chunks:
            logger.info("âœ… æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
            logger.info("ğŸ”§ ãƒ†ã‚¹ãƒˆç”¨ãƒ€ãƒŸãƒ¼ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ...")
            await create_test_chunks()
            
            # å†åº¦ç¢ºèª
            pending_chunks = generator._get_pending_chunks(limit=5)
        
        if pending_chunks:
            logger.info(f"ğŸ“‹ æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {len(pending_chunks)}")
            
            # 4. å°è¦æ¨¡ãƒãƒƒãƒãƒ†ã‚¹ãƒˆï¼ˆæœ€å¤§5ãƒãƒ£ãƒ³ã‚¯ï¼‰
            logger.info("ğŸ§ª å°è¦æ¨¡ãƒãƒƒãƒãƒ†ã‚¹ãƒˆé–‹å§‹...")
            test_chunks = pending_chunks[:5]  # æœ€å¤§5ãƒãƒ£ãƒ³ã‚¯ã§ãƒ†ã‚¹ãƒˆ
            
            success_count = 0
            for chunk in test_chunks:
                try:
                    chunk_id = chunk['id']
                    content = chunk['content']
                    
                    # embeddingç”Ÿæˆãƒ†ã‚¹ãƒˆ
                    embedding = await generator._generate_embedding_with_retry(content, chunk_id)
                    
                    if embedding:
                        logger.info(f"  âœ… ãƒãƒ£ãƒ³ã‚¯ {chunk_id}: embeddingç”ŸæˆæˆåŠŸ ({len(embedding)}æ¬¡å…ƒ)")
                        success_count += 1
                    else:
                        logger.warning(f"  âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {chunk_id}: embeddingç”Ÿæˆå¤±æ•—")
                        
                except Exception as e:
                    logger.error(f"  âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk['id']} ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            
            logger.info(f"ğŸ“Š å°è¦æ¨¡ãƒ†ã‚¹ãƒˆçµæœ: {success_count}/{len(test_chunks)} æˆåŠŸ")
            
            if success_count > 0:
                logger.info("âœ… ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œç¢ºèªå®Œäº†")
                return True
            else:
                logger.error("âŒ ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ")
                return False
        else:
            logger.info("âœ… å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ãŒãªã„ãŸã‚ã€ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã§ã™")
            return True
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

async def create_test_chunks():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ"""
    try:
        logger.info("ğŸ”§ ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ä½œæˆä¸­...")
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
        test_doc_id = "test-batch-embedding-doc"
        
        # æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
        from supabase_adapter import delete_data
        try:
            delete_data("chunks", "doc_id", test_doc_id)
            delete_data("document_sources", "id", test_doc_id)
        except:
            pass  # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚½ãƒ¼ã‚¹ã‚’ä½œæˆ
        doc_data = {
            "id": test_doc_id,
            "name": "ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            "type": "test",
            "page_count": 1,
            "uploaded_by": "test-user",
            "company_id": "test-company",
            "uploaded_at": datetime.now().isoformat()
        }
        
        insert_data("document_sources", doc_data)
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
        test_contents = [
            "ã“ã‚Œã¯ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯1ã§ã™ã€‚",
            "ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚",
            "10ä»¶ãšã¤ã¾ã¨ã‚ã¦å‡¦ç†ã™ã‚‹æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™ã€‚",
            "APIã®è² è·è»½æ¸›ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ãŒç›®çš„ã§ã™ã€‚",
            "ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
        ]
        
        for i, content in enumerate(test_contents):
            chunk_data = {
                "doc_id": test_doc_id,
                "chunk_index": i,
                "content": content,
                "company_id": "test-company"
            }
            
            insert_data("chunks", chunk_data)
        
        logger.info(f"âœ… ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ä½œæˆå®Œäº†: {len(test_contents)}ä»¶")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

async def test_full_batch_processing():
    """å®Œå…¨ãªãƒãƒƒãƒå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸš€ å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ç¢ºèª
        chunks_result = select_data(
            "chunks",
            columns="id",
            filters={"embedding": None},
            limit=50  # ãƒ†ã‚¹ãƒˆç”¨åˆ¶é™
        )
        
        if not chunks_result.data:
            logger.info("âœ… å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
            return True
        
        pending_count = len(chunks_result.data)
        logger.info(f"ğŸ“Š æœªå‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {pending_count}")
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œï¼ˆåˆ¶é™ä»˜ãï¼‰
        success = await batch_generate_embeddings_for_all_pending(limit=20)
        
        if success:
            logger.info("âœ… å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
        else:
            logger.warning("âš ï¸ å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def cleanup_test_data():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    try:
        logger.info("ğŸ§¹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...")
        
        from supabase_adapter import delete_data
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ã‚¯ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
        delete_data("chunks", "doc_id", "test-batch-embedding-doc")
        delete_data("document_sources", "id", "test-batch-embedding-doc")
        
        logger.info("âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸ§ª ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info(f"â° é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
        basic_test_success = await test_batch_embedding_system()
        
        if not basic_test_success:
            logger.error("âŒ åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—")
            sys.exit(1)
        
        # å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ
        full_test_success = await test_full_batch_processing()
        
        if not full_test_success:
            logger.warning("âš ï¸ å®Œå…¨ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await cleanup_test_data()
        
        if basic_test_success and full_test_success:
            logger.info("ğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ")
            sys.exit(0)
        else:
            logger.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            sys.exit(1)
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆä¸­æ–­")
        await cleanup_test_data()
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸ’¥ äºˆæœŸã—ãªã„ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        await cleanup_test_data()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())