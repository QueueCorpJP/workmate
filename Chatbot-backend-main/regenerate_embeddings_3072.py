#!/usr/bin/env python3
"""
å…¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ gemini-embedding-exp-03-07 (3072æ¬¡å…ƒ) ã§å†ç”Ÿæˆ
- chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®å…¨åŸ‹ã‚è¾¼ã¿ã‚’å†ç”Ÿæˆ
- 3072æ¬¡å…ƒã«çµ±ä¸€
- ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–
"""

import sys
import os
import logging
import time
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv
import google.generativeai as genai
import psycopg2
from psycopg2.extras import RealDictCursor

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class EmbeddingRegenerator:
    """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        self.model = "models/gemini-embedding-exp-03-07"  # 3072æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«
        self.db_url = self._get_db_url()
        
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        genai.configure(api_key=self.api_key)
        
        logger.info(f"âœ… åŸ‹ã‚è¾¼ã¿å†ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–: ãƒ¢ãƒ‡ãƒ«={self.model}")
        
    def _get_db_url(self) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’æ§‹ç¯‰"""
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        
        if not supabase_url or not supabase_key:
            raise ValueError("SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if "supabase.co" in supabase_url:
            project_id = supabase_url.split("://")[1].split(".")[0]
            return f"postgresql://postgres.{project_id}:{os.getenv('DB_PASSWORD', '')}@aws-0-ap-northeast-1.pooler.supabase.com:6543/postgres"
        else:
            db_url = os.getenv("DATABASE_URL")
            if not db_url:
                raise ValueError("DATABASE_URL ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return db_url

    def generate_embedding(self, text: str) -> Optional[List[float]]:
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ (3072æ¬¡å…ƒ)"""
        try:
            if not text or len(text.strip()) == 0:
                logger.warning("ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã—ãŸ")
                return None
            
            response = genai.embed_content(
                model=self.model,
                content=text
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—
            embedding_vector = None
            
            if isinstance(response, dict) and 'embedding' in response:
                embedding_vector = response['embedding']
            elif hasattr(response, 'embedding') and response.embedding:
                embedding_vector = response.embedding
            else:
                logger.error(f"äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼: {type(response)}")
                return None
            
            if embedding_vector and len(embedding_vector) > 0:
                logger.debug(f"åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†: {len(embedding_vector)}æ¬¡å…ƒ")
                return embedding_vector
            else:
                logger.error("åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
        
        except Exception as e:
            logger.error(f"åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def get_all_chunks(self) -> List[Dict]:
        """chunksãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
        try:
            with psycopg2.connect(self.db_url, cursor_factory=RealDictCursor) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT
                            id,
                            content,
                            doc_id,
                            chunk_index,
                            company_id,
                            CASE
                                WHEN embedding IS NOT NULL THEN vector_dims(embedding)
                                ELSE 0
                            END as current_dim
                        FROM chunks
                        WHERE content IS NOT NULL
                        AND content != ''
                        ORDER BY id
                    """)
                    chunks = cur.fetchall()
                    
                    logger.info(f"ğŸ“Š å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")
                    
                    # ç¾åœ¨ã®æ¬¡å…ƒåˆ†å¸ƒã‚’è¡¨ç¤º
                    dim_counts = {}
                    for chunk in chunks:
                        dim = chunk['current_dim'] or 0
                        dim_counts[dim] = dim_counts.get(dim, 0) + 1
                    
                    logger.info("ğŸ“Š ç¾åœ¨ã®åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒåˆ†å¸ƒ:")
                    for dim, count in sorted(dim_counts.items()):
                        logger.info(f"  {dim}æ¬¡å…ƒ: {count}ãƒãƒ£ãƒ³ã‚¯")
                    
                    return chunks
        
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ³ã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def update_chunk_embedding(self, chunk_id: str, embedding: List[float]) -> bool:
        """ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ›´æ–°"""
        try:
            with psycopg2.connect(self.db_url, cursor_factory=RealDictCursor) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        UPDATE chunks 
                        SET embedding = %s::vector
                        WHERE id = %s
                    """, (embedding, chunk_id))
                    
                    if cur.rowcount > 0:
                        conn.commit()
                        return True
                    else:
                        logger.warning(f"ãƒãƒ£ãƒ³ã‚¯ID {chunk_id} ã®æ›´æ–°ã«å¤±æ•—")
                        return False
        
        except Exception as e:
            logger.error(f"åŸ‹ã‚è¾¼ã¿æ›´æ–°ã‚¨ãƒ©ãƒ¼ (ID: {chunk_id}): {e}")
            return False

    def process_single_chunk(self, chunk: Dict) -> Dict:
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’å‡¦ç†"""
        chunk_id = chunk['id']
        content = chunk['content']
        current_dim = chunk['current_dim'] or 0
        
        try:
            # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            embedding = self.generate_embedding(content)
            
            if embedding is None:
                return {
                    'chunk_id': chunk_id,
                    'success': False,
                    'error': 'åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå¤±æ•—',
                    'current_dim': current_dim,
                    'new_dim': 0
                }
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
            success = self.update_chunk_embedding(chunk_id, embedding)
            
            return {
                'chunk_id': chunk_id,
                'success': success,
                'error': None if success else 'æ›´æ–°å¤±æ•—',
                'current_dim': current_dim,
                'new_dim': len(embedding)
            }
        
        except Exception as e:
            return {
                'chunk_id': chunk_id,
                'success': False,
                'error': str(e),
                'current_dim': current_dim,
                'new_dim': 0
            }

    def regenerate_all_embeddings(self, max_workers: int = 3) -> Dict:
        """å…¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¸¦åˆ—ã§å†ç”Ÿæˆ"""
        logger.info("ğŸš€ å…¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆé–‹å§‹")
        start_time = time.time()
        
        # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
        chunks = self.get_all_chunks()
        if not chunks:
            logger.error("å‡¦ç†å¯¾è±¡ã®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {'success': False, 'error': 'ãƒãƒ£ãƒ³ã‚¯ãªã—'}
        
        total_chunks = len(chunks)
        logger.info(f"ğŸ“ å‡¦ç†å¯¾è±¡: {total_chunks}ãƒãƒ£ãƒ³ã‚¯")
        
        # ä¸¦åˆ—å‡¦ç†ã§åŸ‹ã‚è¾¼ã¿å†ç”Ÿæˆ
        results = []
        success_count = 0
        error_count = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—å‡¦ç†ã«æŠ•å…¥
            future_to_chunk = {
                executor.submit(self.process_single_chunk, chunk): chunk 
                for chunk in chunks
            }
            
            # çµæœã‚’åé›†
            for i, future in enumerate(as_completed(future_to_chunk), 1):
                chunk = future_to_chunk[future]
                
                try:
                    result = future.result(timeout=60)  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                    results.append(result)
                    
                    if result['success']:
                        success_count += 1
                        logger.info(f"âœ… {i}/{total_chunks} - ãƒãƒ£ãƒ³ã‚¯ {result['chunk_id']}: {result['current_dim']}â†’{result['new_dim']}æ¬¡å…ƒ")
                    else:
                        error_count += 1
                        logger.error(f"âŒ {i}/{total_chunks} - ãƒãƒ£ãƒ³ã‚¯ {result['chunk_id']}: {result['error']}")
                    
                    # é€²æ—è¡¨ç¤º
                    if i % 10 == 0 or i == total_chunks:
                        progress = (i / total_chunks) * 100
                        logger.info(f"ğŸ“Š é€²æ—: {i}/{total_chunks} ({progress:.1f}%) - æˆåŠŸ: {success_count}, å¤±æ•—: {error_count}")
                
                except Exception as e:
                    error_count += 1
                    logger.error(f"âŒ {i}/{total_chunks} - ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        elapsed_time = time.time() - start_time
        
        # çµæœã‚µãƒãƒªãƒ¼
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š åŸ‹ã‚è¾¼ã¿å†ç”Ÿæˆå®Œäº†ã‚µãƒãƒªãƒ¼")
        logger.info("="*60)
        logger.info(f"ç·å‡¦ç†æ™‚é–“: {elapsed_time:.2f}ç§’")
        logger.info(f"å‡¦ç†å¯¾è±¡: {total_chunks}ãƒãƒ£ãƒ³ã‚¯")
        logger.info(f"æˆåŠŸ: {success_count}ãƒãƒ£ãƒ³ã‚¯")
        logger.info(f"å¤±æ•—: {error_count}ãƒãƒ£ãƒ³ã‚¯")
        logger.info(f"æˆåŠŸç‡: {(success_count/total_chunks)*100:.1f}%")
        
        # æ¬¡å…ƒåˆ†å¸ƒã®ç¢ºèª
        self.verify_embedding_dimensions()
        
        return {
            'success': True,
            'total_chunks': total_chunks,
            'success_count': success_count,
            'error_count': error_count,
            'elapsed_time': elapsed_time,
            'results': results
        }

    def verify_embedding_dimensions(self):
        """åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã®ç¢ºèª"""
        try:
            with psycopg2.connect(self.db_url, cursor_factory=RealDictCursor) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT
                            vector_dims(embedding) as dim_count,
                            COUNT(*) as chunk_count
                        FROM chunks
                        WHERE embedding IS NOT NULL
                        GROUP BY vector_dims(embedding)
                        ORDER BY dim_count
                    """)
                    results = cur.fetchall()
                    
                    logger.info("\nğŸ“Š æ›´æ–°å¾Œã®åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒåˆ†å¸ƒ:")
                    for row in results:
                        logger.info(f"  {row['dim_count']}æ¬¡å…ƒ: {row['chunk_count']}ãƒãƒ£ãƒ³ã‚¯")
        
        except Exception as e:
            logger.error(f"æ¬¡å…ƒç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        logger.info("ğŸš€ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
        
        # å†ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        regenerator = EmbeddingRegenerator()
        
        # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        print("\n" + "="*60)
        print("âš ï¸  é‡è¦: å…¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†ç”Ÿæˆã—ã¾ã™")
        print("="*60)
        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {regenerator.model}")
        print("å¯¾è±¡: chunksãƒ†ãƒ¼ãƒ–ãƒ«ã®å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰")
        print("äºˆæƒ³æ¬¡å…ƒ: 3072æ¬¡å…ƒ")
        print("å‡¦ç†æ™‚é–“: æ•°åˆ†ã€œæ•°ååˆ†ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹ï¼‰")
        print("="*60)
        
        confirm = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            logger.info("å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # åŸ‹ã‚è¾¼ã¿å†ç”Ÿæˆå®Ÿè¡Œ
        result = regenerator.regenerate_all_embeddings(max_workers=3)
        
        if result['success']:
            logger.info("ğŸ‰ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            logger.error("âŒ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except KeyboardInterrupt:
        logger.info("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"è©³ç´°: {traceback.format_exc()}")

if __name__ == "__main__":
    main()