"""
ğŸš¨ WebSocket Connection Leak & Quota Issue Fix
Fix the real cause of 429 errors: WebSocket connection leaks causing resource exhaustion

Root Cause Analysis:
1. WebSocket connections are not being properly closed
2. Multiple WebSocket connections accumulate over time
3. Each connection maintains async tasks that consume API quota
4. File queue manager has infinite retry loops
5. Progress manager keeps connections alive indefinitely

This fix addresses:
1. WebSocket connection lifecycle management
2. Proper cleanup of async tasks
3. Connection pooling and limits
4. Resource exhaustion prevention
5. Circuit breaker integration with WebSocket state
"""

import os
import sys
import logging
import asyncio
import weakref
from datetime import datetime, timedelta
from typing import List, Optional, Any, Dict

# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fix_websocket_connection_leaks():
    """Fix WebSocket connection leaks that cause resource exhaustion"""
    try:
        # Patch upload progress manager
        from modules.upload_progress import UploadProgressManager
        
        # Store original methods
        original_add_websocket = UploadProgressManager.add_websocket_connection
        original_remove_websocket = UploadProgressManager.remove_websocket_connection
        original_notify_progress = UploadProgressManager._notify_progress
        
        async def fixed_add_websocket_connection(self, websocket):
            """Add WebSocket connection with proper lifecycle management"""
            import uuid
            
            # Limit maximum connections to prevent resource exhaustion
            max_connections = 10
            if len(self.websocket_connections) >= max_connections:
                logger.warning(f"ğŸš¨ WebSocketæ¥ç¶šæ•°ä¸Šé™åˆ°é” ({max_connections}) - å¤ã„æ¥ç¶šã‚’å‰Šé™¤")
                # Remove oldest connections
                oldest_connections = list(self.websocket_connections.keys())[:5]
                for old_id in oldest_connections:
                    try:
                        old_websocket = self.websocket_connections[old_id]
                        await old_websocket.close()
                    except:
                        pass
                    del self.websocket_connections[old_id]
            
            connection_id = str(uuid.uuid4())
            
            # Add new connection with weak reference to prevent memory leaks
            self.websocket_connections[connection_id] = websocket
            
            # Set connection timeout
            asyncio.create_task(self._monitor_connection_timeout(connection_id, websocket))
            
            logger.info(f"ğŸ“¡ WebSocketæ¥ç¶šè¿½åŠ : {connection_id} (ç·æ¥ç¶šæ•°: {len(self.websocket_connections)})")
            return connection_id
        
        async def fixed_remove_websocket_connection(self, connection_id):
            """Remove WebSocket connection with proper cleanup"""
            if connection_id in self.websocket_connections:
                try:
                    websocket = self.websocket_connections[connection_id]
                    if not websocket.client_state.DISCONNECTED:
                        await websocket.close()
                except Exception as e:
                    logger.warning(f"WebSocketåˆ‡æ–­ã‚¨ãƒ©ãƒ¼: {e}")
                finally:
                    del self.websocket_connections[connection_id]
                    logger.info(f"ğŸ“¡ WebSocketæ¥ç¶šå‰Šé™¤: {connection_id} (æ®‹ã‚Šæ¥ç¶šæ•°: {len(self.websocket_connections)})")
        
        async def fixed_notify_progress(self, upload_id):
            """Notify progress with connection health check"""
            if not self.websocket_connections:
                return
            
            upload_info = self.active_uploads.get(upload_id)
            if not upload_info:
                return
            
            message = {
                "type": "upload_progress",
                "upload_id": upload_id,
                "data": upload_info
            }
            
            # Track disconnected connections
            disconnected = []
            
            for connection_id, websocket in list(self.websocket_connections.items()):
                try:
                    # Check if connection is still alive
                    if websocket.client_state.DISCONNECTED:
                        disconnected.append(connection_id)
                        continue
                    
                    await websocket.send_text(json.dumps(message, ensure_ascii=False, default=str))
                    
                except Exception as e:
                    logger.warning(f"WebSocketé€šçŸ¥ã‚¨ãƒ©ãƒ¼ ({connection_id}): {e}")
                    disconnected.append(connection_id)
            
            # Clean up disconnected connections
            for connection_id in disconnected:
                await self.remove_websocket_connection(connection_id)
        
        async def monitor_connection_timeout(self, connection_id, websocket, timeout_minutes=30):
            """Monitor connection timeout and auto-cleanup"""
            try:
                await asyncio.sleep(timeout_minutes * 60)
                if connection_id in self.websocket_connections:
                    logger.info(f"â° WebSocketæ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {connection_id}")
                    await self.remove_websocket_connection(connection_id)
            except asyncio.CancelledError:
                pass
            except Exception as e:
                logger.error(f"æ¥ç¶šç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
        
        # Apply patches
        UploadProgressManager.add_websocket_connection = fixed_add_websocket_connection
        UploadProgressManager.remove_websocket_connection = fixed_remove_websocket_connection
        UploadProgressManager._notify_progress = fixed_notify_progress
        UploadProgressManager._monitor_connection_timeout = monitor_connection_timeout
        
        logger.info("âœ… Upload progress manager WebSocket leaks fixed")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to fix upload progress WebSocket leaks: {e}")
        return False

def fix_client_websocket_leaks():
    """Fix client WebSocket connection leaks"""
    try:
        from modules.client_websocket_api import ClientWebSocketManager
        
        # Store original methods
        original_add_connection = ClientWebSocketManager.add_connection
        original_remove_connection = ClientWebSocketManager.remove_connection
        original_broadcast = ClientWebSocketManager.broadcast_status_update
        original_periodic_broadcast = ClientWebSocketManager._start_periodic_broadcast
        
        async def fixed_add_connection(self, websocket, connection_id, user_info):
            """Add connection with limits and monitoring"""
            # Limit connections per user
            user_id = user_info.get("id")
            user_connections = [
                cid for cid, data in self.connections.items()
                if data.get("user_id") == user_id
            ]
            
            max_per_user = 3
            if len(user_connections) >= max_per_user:
                logger.warning(f"ğŸš¨ ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¥ç¶šæ•°ä¸Šé™ ({user_id}): {len(user_connections)}")
                # Remove oldest connection for this user
                oldest_id = user_connections[0]
                await self.remove_connection(oldest_id)
            
            # Limit total connections
            max_total = 20
            if len(self.connections) >= max_total:
                logger.warning(f"ğŸš¨ ç·WebSocketæ¥ç¶šæ•°ä¸Šé™åˆ°é”: {len(self.connections)}")
                # Remove oldest connections
                oldest_connections = list(self.connections.keys())[:5]
                for old_id in oldest_connections:
                    await self.remove_connection(old_id)
            
            connection_data = {
                "websocket": websocket,
                "user_id": user_info.get("id"),
                "company_id": user_info.get("company_id"),
                "connected_at": datetime.now().isoformat(),
                "last_activity": datetime.now()
            }
            
            self.connections[connection_id] = connection_data
            
            logger.info(f"ğŸ“± ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆWebSocketæ¥ç¶šè¿½åŠ : {connection_id} (ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_info.get('id')}) (ç·æ•°: {len(self.connections)})")
            
            # Start periodic broadcast with connection limits
            if not self.is_broadcasting and len(self.connections) > 0:
                asyncio.create_task(self._start_periodic_broadcast())
        
        async def fixed_remove_connection(self, connection_id):
            """Remove connection with proper cleanup"""
            if connection_id in self.connections:
                try:
                    connection_data = self.connections[connection_id]
                    websocket = connection_data["websocket"]
                    if not websocket.client_state.DISCONNECTED:
                        await websocket.close()
                except Exception as e:
                    logger.warning(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆWebSocketåˆ‡æ–­ã‚¨ãƒ©ãƒ¼: {e}")
                finally:
                    del self.connections[connection_id]
                    logger.info(f"ğŸ“± ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆWebSocketæ¥ç¶šå‰Šé™¤: {connection_id} (æ®‹ã‚Š: {len(self.connections)})")
        
        async def fixed_broadcast_status_update(self, force_update=False):
            """Broadcast with connection health monitoring"""
            if not self.connections:
                return
            
            try:
                from .client_queue_status import client_queue_status
                current_status = client_queue_status.get_client_queue_status()
                
                if not force_update and self.last_status == current_status:
                    return
                
                self.last_status = current_status
                
                message = {
                    "type": "queue_status_update",
                    "timestamp": datetime.now().isoformat(),
                    "data": current_status
                }
                
                message_json = json.dumps(message, ensure_ascii=False, default=str)
                
                # Track disconnected connections
                disconnected = []
                active_count = 0
                
                for connection_id, connection_data in list(self.connections.items()):
                    try:
                        websocket = connection_data["websocket"]
                        
                        # Check connection health
                        if websocket.client_state.DISCONNECTED:
                            disconnected.append(connection_id)
                            continue
                        
                        # Check for stale connections (no activity for 1 hour)
                        last_activity = connection_data.get("last_activity", datetime.now())
                        if isinstance(last_activity, str):
                            last_activity = datetime.fromisoformat(last_activity.replace('Z', '+00:00'))
                        
                        if datetime.now() - last_activity > timedelta(hours=1):
                            logger.info(f"ğŸ• å¤ã„WebSocketæ¥ç¶šã‚’å‰Šé™¤: {connection_id}")
                            disconnected.append(connection_id)
                            continue
                        
                        await websocket.send_text(message_json)
                        connection_data["last_activity"] = datetime.now()
                        active_count += 1
                        
                    except Exception as e:
                        logger.warning(f"ğŸ“± ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé…ä¿¡ã‚¨ãƒ©ãƒ¼ ({connection_id}): {e}")
                        disconnected.append(connection_id)
                
                # Clean up disconnected connections
                for connection_id in disconnected:
                    await self.remove_connection(connection_id)
                
                if active_count > 0:
                    logger.debug(f"ğŸ“± çŠ¶æ…‹é…ä¿¡å®Œäº†: {active_count}æ¥ç¶š")
                    
            except Exception as e:
                logger.error(f"ğŸ“± ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçŠ¶æ…‹é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        
        async def fixed_periodic_broadcast(self):
            """Periodic broadcast with resource management"""
            if self.is_broadcasting:
                return
            
            self.is_broadcasting = True
            logger.info("ğŸ“± å®šæœŸé…ä¿¡é–‹å§‹")
            
            try:
                broadcast_count = 0
                max_broadcasts = 1000  # Limit total broadcasts to prevent resource exhaustion
                
                while self.connections and broadcast_count < max_broadcasts:
                    await self.broadcast_status_update()
                    
                    # Longer intervals to reduce resource usage
                    await asyncio.sleep(5.0)
                    broadcast_count += 1
                    
                    # Periodic cleanup
                    if broadcast_count % 100 == 0:
                        logger.info(f"ğŸ“± å®šæœŸé…ä¿¡ç¶™ç¶šä¸­: {broadcast_count}å›, æ¥ç¶šæ•°: {len(self.connections)}")
                
                logger.info("ğŸ“± å®šæœŸé…ä¿¡çµ‚äº† (æ¥ç¶šãªã—ã¾ãŸã¯ä¸Šé™åˆ°é”)")
                
            except Exception as e:
                logger.error(f"ğŸ“± å®šæœŸé…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            finally:
                self.is_broadcasting = False
        
        # Apply patches
        ClientWebSocketManager.add_connection = fixed_add_connection
        ClientWebSocketManager.remove_connection = fixed_remove_connection
        ClientWebSocketManager.broadcast_status_update = fixed_broadcast_status_update
        ClientWebSocketManager._start_periodic_broadcast = fixed_periodic_broadcast
        
        logger.info("âœ… Client WebSocket manager leaks fixed")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to fix client WebSocket leaks: {e}")
        return False

def fix_file_queue_infinite_loops():
    """Fix infinite loops in file queue manager"""
    try:
        from modules.file_queue_manager import FileQueueManager
        from modules.quota_manager import quota_manager
        
        # Store original method
        original_retry_unlimited = FileQueueManager._retry_embeddings_unlimited
        
        async def fixed_retry_embeddings_unlimited(self, retry_task):
            """Fixed embedding retry with proper limits and quota awareness"""
            try:
                from modules.document_processor import document_processor
                
                logger.info(f"ğŸ§  åˆ¶é™ä»˜ãEmbeddingãƒªãƒˆãƒ©ã‚¤é–‹å§‹: {retry_task.doc_id}")
                
                max_retries = 20  # Reasonable limit instead of unlimited
                retry_count = 0
                consecutive_failures = 0
                max_consecutive_failures = 5
                max_quota_errors = 10
                quota_error_count = 0
                
                while retry_count < max_retries:
                    retry_count += 1
                    retry_task.retry_count = retry_count
                    retry_task.last_attempt = datetime.now()
                    
                    # Check quota status before each retry
                    status = quota_manager.get_status()
                    
                    # Stop if circuit breaker is open
                    if status['circuit_state'] == 'open':
                        logger.warning(f"ğŸš¨ Circuit breaker OPEN - Stopping retry for {retry_task.doc_id}")
                        break
                    
                    # Stop if too many quota errors globally
                    if status['quota_errors'] > 30:
                        logger.warning(f"ğŸš¨ Global quota errors too high ({status['quota_errors']}) - Stopping retry")
                        break
                    
                    # Stop if too many quota errors for this task
                    if quota_error_count >= max_quota_errors:
                        logger.warning(f"ğŸš¨ Task quota errors too high ({quota_error_count}) - Stopping retry for {retry_task.doc_id}")
                        break
                    
                    logger.info(f"ğŸ”„ Embeddingãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œ #{retry_count}/{max_retries}: {retry_task.doc_id}")
                    
                    try:
                        # Use document processor with limited retries
                        result = await document_processor.retry_failed_embeddings(
                            doc_id=retry_task.doc_id,
                            company_id=retry_task.company_id,
                            max_retries=3  # Limited retries per attempt
                        )
                        
                        # Check results
                        if result["still_failed"] == 0:
                            logger.info(f"ğŸ‰ Embeddingãƒªãƒˆãƒ©ã‚¤å®Œå…¨æˆåŠŸ: {retry_task.doc_id} (è©¦è¡Œå›æ•°: {retry_count})")
                            break
                        elif result["successful"] > 0:
                            # Partial success - reset consecutive failures
                            consecutive_failures = 0
                            quota_error_count = 0  # Reset quota error count on success
                            logger.info(f"ğŸ“ˆ Embeddingãƒªãƒˆãƒ©ã‚¤éƒ¨åˆ†æˆåŠŸ: {retry_task.doc_id} (æˆåŠŸ: {result['successful']}, æ®‹ã‚Šå¤±æ•—: {result['still_failed']})")
                        else:
                            # All failed
                            consecutive_failures += 1
                            logger.warning(f"âš ï¸ Embeddingãƒªãƒˆãƒ©ã‚¤å…¨å¤±æ•—: {retry_task.doc_id} (é€£ç¶šå¤±æ•—: {consecutive_failures})")
                        
                        # Stop if too many consecutive failures
                        if consecutive_failures >= max_consecutive_failures:
                            logger.error(f"âŒ Embeddingãƒªãƒˆãƒ©ã‚¤é€£ç¶šå¤±æ•—ä¸Šé™åˆ°é”: {retry_task.doc_id}")
                            break
                        
                    except Exception as retry_error:
                        error_str = str(retry_error)
                        
                        # Check if it's a quota error
                        if "429" in error_str or "quota" in error_str.lower() or "exhausted" in error_str.lower():
                            quota_error_count += 1
                            logger.error(f"ğŸš¨ Quota error #{quota_error_count} in retry #{retry_count}: {retry_task.doc_id} - {retry_error}")
                        else:
                            consecutive_failures += 1
                            logger.error(f"âŒ Embeddingãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ #{retry_count}: {retry_task.doc_id} - {retry_error}")
                        
                        if consecutive_failures >= max_consecutive_failures:
                            logger.error(f"âŒ Embeddingãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼é€£ç¶šç™ºç”Ÿä¸Šé™åˆ°é”: {retry_task.doc_id}")
                            break
                        
                        if quota_error_count >= max_quota_errors:
                            logger.error(f"ğŸš¨ Quota error limit reached for task: {retry_task.doc_id}")
                            break
                    
                    # Progressive backoff with max delay
                    if retry_count < max_retries:
                        delay = min(2 ** (retry_count - 1), 300)  # Max 5 minutes delay
                        logger.info(f"â³ æ¬¡ã®Embeddingãƒªãƒˆãƒ©ã‚¤ã¾ã§ {delay}ç§’å¾…æ©Ÿ: {retry_task.doc_id}")
                        await asyncio.sleep(delay)
                
                logger.info(f"âœ… Embeddingãƒªãƒˆãƒ©ã‚¤å®Œäº†: {retry_task.doc_id} (ç·è©¦è¡Œå›æ•°: {retry_count})")
                
            except Exception as e:
                logger.error(f"âŒ åˆ¶é™ä»˜ãEmbeddingãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼: {retry_task.doc_id} - {e}", exc_info=True)
            finally:
                # Always remove from active retries
                self.active_embedding_retries.pop(retry_task.task_id, None)
        
        # Apply patch
        FileQueueManager._retry_embeddings_unlimited = fixed_retry_embeddings_unlimited
        
        logger.info("âœ… File queue manager infinite loops fixed")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to fix file queue infinite loops: {e}")
        return False

def cleanup_existing_connections():
    """Clean up existing WebSocket connections and tasks"""
    try:
        # Clean up upload progress connections
        try:
            from modules.upload_progress import progress_manager
            connection_count = len(progress_manager.websocket_connections)
            progress_manager.websocket_connections.clear()
            logger.info(f"ğŸ§¹ Upload progress WebSocketæ¥ç¶šã‚’ã‚¯ãƒªã‚¢: {connection_count}ä»¶")
        except Exception as e:
            logger.warning(f"Upload progress cleanup error: {e}")
        
        # Clean up client WebSocket connections
        try:
            from modules.client_websocket_api import ClientWebSocketManager
            # Get the global instance if it exists
            import modules.client_websocket_api as client_ws_module
            if hasattr(client_ws_module, 'client_websocket_manager'):
                manager = client_ws_module.client_websocket_manager
                connection_count = len(manager.connections)
                manager.connections.clear()
                manager.is_broadcasting = False
                logger.info(f"ğŸ§¹ Client WebSocketæ¥ç¶šã‚’ã‚¯ãƒªã‚¢: {connection_count}ä»¶")
        except Exception as e:
            logger.warning(f"Client WebSocket cleanup error: {e}")
        
        # Stop file queue processing
        try:
            from modules.file_queue_manager import file_queue_manager
            
            # Clear retry queues
            if hasattr(file_queue_manager, 'embedding_retry_queue'):
                retry_count = len(file_queue_manager.embedding_retry_queue)
                file_queue_manager.embedding_retry_queue.clear()
                logger.info(f"ğŸ§¹ Embedding retry queue cleared: {retry_count}ä»¶")
            
            if hasattr(file_queue_manager, 'active_embedding_retries'):
                active_count = len(file_queue_manager.active_embedding_retries)
                file_queue_manager.active_embedding_retries.clear()
                logger.info(f"ğŸ§¹ Active embedding retries cleared: {active_count}ä»¶")
            
            # Set flags to stop processing
            if hasattr(file_queue_manager, 'is_embedding_retry_active'):
                file_queue_manager.is_embedding_retry_active = False
                logger.info("ğŸ§¹ Embedding retry processing disabled")
                
        except Exception as e:
            logger.warning(f"File queue cleanup error: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to cleanup existing connections: {e}")
        return False

def main():
    """Main function to apply the WebSocket quota fix"""
    logger.info("ğŸš¨ Starting WebSocket connection leak & quota fix...")
    
    success_count = 0
    total_fixes = 4
    
    # 1. Cleanup existing connections first
    logger.info("\nğŸ§¹ Step 1: Cleaning up existing connections...")
    if cleanup_existing_connections():
        logger.info("âœ… Existing connections cleaned up")
        success_count += 1
    else:
        logger.warning("âš ï¸ Could not cleanup existing connections")
    
    # 2. Fix upload progress WebSocket leaks
    logger.info("\nğŸ”§ Step 2: Fixing upload progress WebSocket leaks...")
    if fix_websocket_connection_leaks():
        logger.info("âœ… Upload progress WebSocket leaks fixed")
        success_count += 1
    else:
        logger.warning("âš ï¸ Could not fix upload progress WebSocket leaks")
    
    # 3. Fix client WebSocket leaks
    logger.info("\nğŸ”§ Step 3: Fixing client WebSocket leaks...")
    if fix_client_websocket_leaks():
        logger.info("âœ… Client WebSocket leaks fixed")
        success_count += 1
    else:
        logger.warning("âš ï¸ Could not fix client WebSocket leaks")
    
    # 4. Fix file queue infinite loops
    logger.info("\nğŸ”§ Step 4: Fixing file queue infinite loops...")
    if fix_file_queue_infinite_loops():
        logger.info("âœ… File queue infinite loops fixed")
        success_count += 1
    else:
        logger.warning("âš ï¸ Could not fix file queue infinite loops")
    
    # Summary
    logger.info(f"\nğŸ“Š Fix Summary: {success_count}/{total_fixes} fixes applied successfully")
    
    if success_count == total_fixes:
        logger.info("ğŸ‰ All WebSocket and quota fixes applied successfully!")
        logger.info("ğŸ’¡ The system now has:")
        logger.info("   - WebSocket connection limits and cleanup")
        logger.info("   - Proper connection lifecycle management")
        logger.info("   - Resource exhaustion prevention")
        logger.info("   - Limited retry attempts instead of infinite loops")
        logger.info("   - Quota-aware processing")
        logger.info("\nğŸš€ You can now safely restart the application.")
        logger.info("ğŸ” Monitor WebSocket connections: they should stay under 30 total")
        return True
    else:
        logger.error("âŒ Some fixes failed. Please check the errors above.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)