#!/usr/bin/env python3
"""
ğŸ§ª è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import asyncio
import logging
import tempfile
from datetime import datetime
from dotenv import load_dotenv
from supabase_adapter import get_supabase_client, select_data, delete_data

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

async def test_auto_embedding_integration():
    """è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        auto_embed = os.getenv("AUTO_GENERATE_EMBEDDINGS", "false").lower()
        logger.info(f"ğŸ“‹ AUTO_GENERATE_EMBEDDINGSè¨­å®š: {auto_embed}")
        
        if auto_embed != "true":
            logger.warning("âš ï¸ AUTO_GENERATE_EMBEDDINGS=true ã«è¨­å®šã—ã¦ãã ã•ã„")
            return False
        
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
        supabase = get_supabase_client()
        logger.info("âœ… Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—å®Œäº†")
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        from modules.knowledge.api import process_file_upload
        from modules.database import get_db
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        test_content = """
        ã“ã‚Œã¯è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
        
        ç¬¬1ç« : ãƒ†ã‚¹ãƒˆæ¦‚è¦
        ã“ã®ãƒ†ã‚¹ãƒˆã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã«è‡ªå‹•çš„ã«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
        
        ç¬¬2ç« : æŠ€è¡“ä»•æ§˜
        - Gemini Flash Embedding APIä½¿ç”¨
        - 768æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        - chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«è‡ªå‹•ä¿å­˜
        
        ç¬¬3ç« : æœŸå¾…çµæœ
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†å¾Œã€ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã«embeddingãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
        """
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:
            temp_file.write(test_content)
            temp_file_path = temp_file.name
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            logger.info("ğŸ“¤ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
            
            # FastAPIã®UploadFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            class MockUploadFile:
                def __init__(self, file_path: str):
                    self.filename = os.path.basename(file_path)
                    self.content_type = "text/plain"
                    self._file_path = file_path
                
                async def read(self):
                    with open(self._file_path, 'rb') as f:
                        return f.read()
            
            mock_file = MockUploadFile(temp_file_path)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå–å¾—
            db = get_db()
            
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
            test_user_id = "c8ee4bd7-b5de-48fc-9f54-fba1414da09b"  # ãƒ­ã‚°ã‹ã‚‰å–å¾—ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            result = await process_file_upload(
                file=mock_file,
                user_id=test_user_id,
                db=db
            )
            
            logger.info(f"ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœ: {result.get('message', 'Unknown')}")
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
            logger.info("ğŸ” ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ä¸­...")
            
            # æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            docs_result = select_data(
                "document_sources",
                columns="id,name",
                filters={"name": f"test_auto_embedding_{datetime.now().strftime('%Y%m%d')}.txt"},
                limit=1
            )
            
            if not docs_result.data:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
                docs_result = select_data(
                    "document_sources",
                    columns="id,name",
                    limit=5
                )
                
                if docs_result.data:
                    # æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
                    doc_id = docs_result.data[0]['id']
                    doc_name = docs_result.data[0]['name']
                    logger.info(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc_name} (ID: {doc_id})")
                else:
                    logger.error("âŒ ãƒ†ã‚¹ãƒˆç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return False
            else:
                doc_id = docs_result.data[0]['id']
                doc_name = docs_result.data[0]['name']
                logger.info(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc_name} (ID: {doc_id})")
            
            # ãƒãƒ£ãƒ³ã‚¯ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®çŠ¶æ…‹ã‚’ç¢ºèª
            logger.info("ğŸ” ãƒãƒ£ãƒ³ã‚¯ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
            
            chunks_result = select_data(
                "chunks",
                columns="id,chunk_index,embedding",
                filters={"doc_id": doc_id}
            )
            
            if not chunks_result.data:
                logger.error("âŒ ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            chunks = chunks_result.data
            total_chunks = len(chunks)
            embedded_chunks = sum(1 for chunk in chunks if chunk.get('embedding') is not None)
            
            logger.info(f"ğŸ“Š ãƒãƒ£ãƒ³ã‚¯çµ±è¨ˆ:")
            logger.info(f"   - ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}")
            logger.info(f"   - ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿: {embedded_chunks}")
            logger.info(f"   - æœªå‡¦ç†: {total_chunks - embedded_chunks}")
            
            # çµæœåˆ¤å®š
            if embedded_chunks == total_chunks:
                logger.info("ğŸ‰ ãƒ†ã‚¹ãƒˆæˆåŠŸ: ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                return True
            elif embedded_chunks > 0:
                logger.warning(f"âš ï¸ éƒ¨åˆ†çš„æˆåŠŸ: {embedded_chunks}/{total_chunks} ãƒãƒ£ãƒ³ã‚¯ã«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                return True
            else:
                logger.error("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
                
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                logger.info("ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    success = await test_auto_embedding_integration()
    
    if success:
        logger.info("âœ… è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
        sys.exit(0)
    else:
        logger.error("âŒ è‡ªå‹•ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())