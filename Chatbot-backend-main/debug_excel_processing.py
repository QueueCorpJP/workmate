#!/usr/bin/env python3
"""
Excelå‡¦ç†ã§ã®ãƒ‡ãƒ¼ã‚¿æå¤±å•é¡Œã‚’èª¿æŸ»ã™ã‚‹ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®Excelãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®å„æ®µéšã§ãƒ‡ãƒ¼ã‚¿ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ã‚’è¿½è·¡
"""

import sys
import os
import logging
import pandas as pd
from io import BytesIO
import json

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def debug_excel_processing(excel_file_path: str):
    """Excelå‡¦ç†ã®å„æ®µéšã§ãƒ‡ãƒ¼ã‚¿ã®å¤‰åŒ–ã‚’è©³ç´°ã«è¿½è·¡"""
    
    if not os.path.exists(excel_file_path):
        logger.error(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {excel_file_path}")
        return
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(excel_file_path, 'rb') as f:
        content = f.read()
    
    logger.info(f"ğŸ“Š Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {excel_file_path} ({len(content)} bytes)")
    
    # 1. ç”Ÿã®pandasèª­ã¿è¾¼ã¿ã§ã®å…¨ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    logger.info("\n=== 1. ç”Ÿã®pandasèª­ã¿è¾¼ã¿ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ä¿æŒï¼‰ ===")
    try:
        excel_file = pd.ExcelFile(BytesIO(content))
        logger.info(f"ğŸ“‹ ã‚·ãƒ¼ãƒˆä¸€è¦§: {excel_file.sheet_names}")
        
        original_data = {}
        for sheet_name in excel_file.sheet_names:
            try:
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                df = pd.read_excel(excel_file, sheet_name=sheet_name, header=None)
                logger.info(f"ğŸ“Š ã‚·ãƒ¼ãƒˆ '{sheet_name}': {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")
                
                # éç©ºã‚»ãƒ«ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                non_empty_cells = df.notna().sum().sum()
                total_cells = df.shape[0] * df.shape[1]
                logger.info(f"   éç©ºã‚»ãƒ«: {non_empty_cells}/{total_cells} ({non_empty_cells/total_cells*100:.1f}%)")
                
                # ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                logger.info(f"   ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« (æœ€åˆã®5è¡Œ5åˆ—):")
                sample_data = []
                for i in range(min(5, df.shape[0])):
                    row_sample = []
                    for j in range(min(5, df.shape[1])):
                        cell_value = df.iloc[i, j]
                        if pd.notna(cell_value):
                            cell_str = str(cell_value)[:50]  # æœ€åˆã®50æ–‡å­—
                            row_sample.append(cell_str)
                        else:
                            row_sample.append("[ç©º]")
                    sample_data.append(row_sample)
                    logger.info(f"     è¡Œ{i+1}: {row_sample}")
                
                original_data[sheet_name] = df
                
            except Exception as e:
                logger.error(f"âŒ ã‚·ãƒ¼ãƒˆ '{sheet_name}' èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
    except Exception as e:
        logger.error(f"âŒ pandasèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 2. å„Excel cleanerã§ã®å‡¦ç†çµæœã‚’æ¯”è¼ƒ
    logger.info("\n=== 2. Excel Cleaner å‡¦ç†çµæœæ¯”è¼ƒ ===")
    
    cleaners = [
        ("Enhanced", "modules.excel_data_cleaner_enhanced", "ExcelDataCleanerEnhanced"),
        ("Ultra Conservative", "modules.excel_data_cleaner_ultra_conservative", "ExcelDataCleanerUltraConservative"),
        ("Fixed", "modules.excel_data_cleaner_fixed", "ExcelDataCleanerFixed"),
        ("Original", "modules.excel_data_cleaner", "ExcelDataCleaner")
    ]
    
    cleaner_results = {}
    
    for cleaner_name, module_name, class_name in cleaners:
        try:
            logger.info(f"\n--- {cleaner_name} Cleaner ãƒ†ã‚¹ãƒˆ ---")
            
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‹•çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            module = __import__(module_name, fromlist=[class_name])
            cleaner_class = getattr(module, class_name)
            cleaner = cleaner_class()
            
            # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
            cleaned_text = cleaner.clean_excel_data(content)
            
            logger.info(f"âœ… {cleaner_name}: å‡¦ç†å®Œäº†")
            logger.info(f"   å‡ºåŠ›æ–‡å­—æ•°: {len(cleaned_text)}")
            newline_count = cleaned_text.count('\n') + 1
            logger.info(f"   å‡ºåŠ›è¡Œæ•°: {newline_count}")
            
            # å‡ºåŠ›ã®æœ€åˆã®500æ–‡å­—ã‚’è¡¨ç¤º
            preview = cleaned_text[:500].replace('\n', '\\\\n')
            logger.info(f"   å‡ºåŠ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview}...")
            
            cleaner_results[cleaner_name] = {
                "text": cleaned_text,
                "length": len(cleaned_text),
                "lines": cleaned_text.count('\n') + 1
            }
            
        except ImportError:
            logger.warning(f"âš ï¸ {cleaner_name} cleaner ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        except Exception as e:
            logger.error(f"âŒ {cleaner_name} cleaner ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. çµæœã®æ¯”è¼ƒåˆ†æ
    logger.info("\n=== 3. å‡¦ç†çµæœæ¯”è¼ƒåˆ†æ ===")
    
    if cleaner_results:
        # æ–‡å­—æ•°ã®æ¯”è¼ƒ
        lengths = [(name, result["length"]) for name, result in cleaner_results.items()]
        lengths.sort(key=lambda x: x[1], reverse=True)
        
        logger.info("ğŸ“Š å‡ºåŠ›æ–‡å­—æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
        for i, (name, length) in enumerate(lengths):
            logger.info(f"   {i+1}. {name}: {length:,} æ–‡å­—")
        
        # æœ€ã‚‚é•·ã„å‡ºåŠ›ã¨æœ€ã‚‚çŸ­ã„å‡ºåŠ›ã®å·®ã‚’åˆ†æ
        if len(lengths) >= 2:
            longest_name, longest_length = lengths[0]
            shortest_name, shortest_length = lengths[-1]
            
            loss_ratio = (longest_length - shortest_length) / longest_length * 100
            logger.info(f"ğŸ“‰ ãƒ‡ãƒ¼ã‚¿æå¤±ç‡: {loss_ratio:.1f}% ({longest_name} vs {shortest_name})")
            
            # å…·ä½“çš„ãªå·®åˆ†ã‚’åˆ†æ
            longest_text = cleaner_results[longest_name]["text"]
            shortest_text = cleaner_results[shortest_name]["text"]
            
            # æœ€é•·ç‰ˆã«ã‚ã£ã¦æœ€çŸ­ç‰ˆã«ãªã„å†…å®¹ã‚’æ¢ã™
            longest_lines = set(longest_text.split('\n'))
            shortest_lines = set(shortest_text.split('\n'))
            missing_lines = longest_lines - shortest_lines
            
            if missing_lines:
                logger.info(f"ğŸ” {shortest_name}ã§å¤±ã‚ã‚ŒãŸè¡Œæ•°: {len(missing_lines)}")
                logger.info("   å¤±ã‚ã‚ŒãŸè¡Œã®ä¾‹ï¼ˆæœ€åˆã®5è¡Œï¼‰:")
                for i, line in enumerate(list(missing_lines)[:5]):
                    if line.strip():
                        logger.info(f"     {i+1}. {line[:100]}...")
    
    # 4. æ¨å¥¨äº‹é …
    logger.info("\n=== 4. æ¨å¥¨äº‹é … ===")
    
    if cleaner_results:
        # æœ€ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã‚’æ¨å¥¨
        best_cleaner = max(cleaner_results.items(), key=lambda x: x[1]["length"])
        logger.info(f"ğŸ† æ¨å¥¨ã‚¯ãƒªãƒ¼ãƒŠãƒ¼: {best_cleaner[0]} ({best_cleaner[1]['length']:,} æ–‡å­—)")
        
        # ãƒ‡ãƒ¼ã‚¿æå¤±ãŒå¤§ãã„å ´åˆã®è­¦å‘Š
        if len(cleaner_results) >= 2:
            lengths = [result["length"] for result in cleaner_results.values()]
            max_length = max(lengths)
            min_length = min(lengths)
            
            if (max_length - min_length) / max_length > 0.1:  # 10%ä»¥ä¸Šã®å·®
                logger.warning("âš ï¸ ã‚¯ãƒªãƒ¼ãƒŠãƒ¼é–“ã§å¤§ããªãƒ‡ãƒ¼ã‚¿æå¤±ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™")
                logger.warning("   Ultra Conservative ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python debug_excel_processing.py <excel_file_path>")
        print("ä¾‹: python debug_excel_processing.py 01_ISPæ¡ˆä»¶ä¸€è¦§.xlsx")
        sys.exit(1)
    
    excel_file_path = sys.argv[1]
    debug_excel_processing(excel_file_path)