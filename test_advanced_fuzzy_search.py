#!/usr/bin/env python3
"""
é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
normalize_texté–¢æ•°ã¨æ–‡å­—æ•°å·®ã‚’è€ƒæ…®ã—ãŸã‚¹ã‚³ã‚¢è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import asyncio
from datetime import datetime

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'Chatbot-backend-main'))

async def test_advanced_fuzzy_search():
    """é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    try:
        from modules.advanced_fuzzy_search import (
            get_advanced_fuzzy_search_instance,
            advanced_fuzzy_search,
            advanced_fuzzy_search_available
        )
        
        print("âœ… é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
    except ImportError as e:
        print(f"âŒ é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    if not advanced_fuzzy_search_available():
        print("âŒ é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
        return
    
    print("âœ… é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  åˆ©ç”¨å¯èƒ½")
    
    # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—ã¨ãƒ†ã‚¹ãƒˆ
    instance = get_advanced_fuzzy_search_instance()
    if not instance:
        print("âŒ é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—å¤±æ•—")
        return
    
    print("âœ… é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ å–å¾—æˆåŠŸ")
    
    # 1. normalize_texté–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ”§ 1. normalize_texté–¢æ•°ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    test_texts = [
        "æ ªå¼ä¼šç¤¾ã‚ã„ã†ãˆãŠ",
        "ãˆ±ï¼¡ï¼¢ï¼£ï¼¤",
        "æœ‰é™ä¼šç¤¾ï¼ˆã‹ãªï¼‰ï¼‘ï¼’ï¼“",
        "ï¾•ï½³ï½¹ï¾ï¾ï½¶ï¾ï½²ï½¼ï½¬ã€€ãƒ†ã‚¹ãƒˆ",
        "åˆåŒä¼šç¤¾ã€€ã€€ã€€ã‚¹ãƒšãƒ¼ã‚¹"
    ]
    
    for test_text in test_texts:
        try:
            result = await instance.test_normalize_function(test_text)
            print(f"å…¥åŠ›: {result['original']}")
            print(f"æ­£è¦åŒ–: {result['normalized']}")
            print()
        except Exception as e:
            print(f"âŒ normalize_texté–¢æ•°ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    print("\nğŸ” 2. é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    test_queries = [
        {
            "query": "æ ªå¼ä¼šç¤¾",
            "threshold": 0.3,
            "length_penalty": 0.012,
            "limit": 5
        },
        {
            "query": "é›»è©±ç•ªå·",
            "threshold": 0.4,
            "length_penalty": 0.008,
            "limit": 5
        },
        {
            "query": "é€£çµ¡å…ˆ",
            "threshold": 0.45,
            "length_penalty": 0.012,
            "limit": 10
        }
    ]
    
    for i, test_config in enumerate(test_queries, 1):
        print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆ{i}: ã‚¯ã‚¨ãƒªã€Œ{test_config['query']}ã€")
        print(f"   é–¾å€¤: {test_config['threshold']}, ãƒšãƒŠãƒ«ãƒ†ã‚£: {test_config['length_penalty']}, åˆ¶é™: {test_config['limit']}")
        
        try:
            results = await instance.advanced_fuzzy_search(
                query=test_config['query'],
                threshold=test_config['threshold'],
                length_penalty=test_config['length_penalty'],
                limit=test_config['limit']
            )
            
            if results:
                print(f"   âœ… {len(results)}ä»¶ã®çµæœã‚’å–å¾—")
                for j, result in enumerate(results, 1):
                    print(f"   {j}. {result.document_name}")
                    print(f"      ğŸ“Š æœ€çµ‚ã‚¹ã‚³ã‚¢: {result.final_score:.4f} (é¡ä¼¼åº¦: {result.similarity_score:.4f}, æ–‡å­—æ•°å·®: {result.length_diff})")
                    print(f"      ğŸ“ å†…å®¹: {result.content[:80]}...")
                    print()
            else:
                print("   âš ï¸ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            print(f"   âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    # 3. é¡ä¼¼åº¦åˆ†å¸ƒåˆ†æãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š 3. é¡ä¼¼åº¦åˆ†å¸ƒåˆ†æãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        distribution = await instance.get_similarity_distribution("ä¼šç¤¾")
        if distribution:
            print(f"ã‚¯ã‚¨ãƒª: {distribution['query']}")
            print(f"ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {distribution['total_chunks']}")
            print(f"å¹³å‡é¡ä¼¼åº¦: {distribution['avg_similarity']:.4f}")
            print(f"æœ€å°é¡ä¼¼åº¦: {distribution['min_similarity']:.4f}")
            print(f"æœ€å¤§é¡ä¼¼åº¦: {distribution['max_similarity']:.4f}")
            print(f"æ¨™æº–åå·®: {distribution['std_similarity']:.4f}")
        else:
            print("âŒ é¡ä¼¼åº¦åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    except Exception as e:
        print(f"âŒ é¡ä¼¼åº¦åˆ†å¸ƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. é«˜åº¦ã‚¯ã‚¨ãƒªã®å®Ÿéš›ã®å®Ÿè¡Œä¾‹
    print("\nğŸ¯ 4. ã”è³ªå•ã®ã‚¯ã‚¨ãƒªã¨åŒç­‰ã®å®Ÿè¡Œãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        # ã”è³ªå•ã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        print("å®Ÿè¡Œã‚¯ã‚¨ãƒªä¾‹:")
        print("WITH normalized AS (")
        print("  SELECT *, normalize_text(content) AS norm_content,")
        print("         normalize_text('ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª') AS norm_query")
        print("  FROM chunks WHERE company_id = :company_id")
        print(")")
        print("SELECT *,")
        print("  similarity(norm_content, norm_query) AS sim,")
        print("  abs(length(norm_content) - length(norm_query)) AS len_diff,")
        print("  (similarity(...) - 0.012 * len_diff")
        print("   + CASE WHEN norm_content = norm_query THEN 0.4")
        print("          WHEN norm_content LIKE norm_query || '%' THEN 0.2")
        print("          ELSE 0 END) AS final_score")
        print("FROM normalized")
        print("WHERE similarity(norm_content, norm_query) > 0.45")
        print("ORDER BY final_score DESC LIMIT 50;\n")
        
        results = await advanced_fuzzy_search(
            query="ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª",
            threshold=0.45,
            length_penalty=0.012,
            limit=50
        )
        
        if results:
            print(f"âœ… {len(results)}ä»¶ã®çµæœã‚’å–å¾—")
            print("ğŸ“‹ ä¸Šä½3ä»¶ã®è©³ç´°:")
            for i, result in enumerate(results[:3], 1):
                result_dict = result if isinstance(result, dict) else result
                print(f"{i}. æ–‡æ›¸: {result_dict.get('document_name', 'Unknown')}")
                print(f"   æœ€çµ‚ã‚¹ã‚³ã‚¢: {result_dict.get('final_score', 0):.4f}")
                print(f"   é¡ä¼¼åº¦: {result_dict.get('similarity_score', 0):.4f}")
                print(f"   æ–‡å­—æ•°å·®: {result_dict.get('length_diff', 0)}")
                print(f"   å†…å®¹: {result_dict.get('content', '')[:100]}...")
                print()
        else:
            print("âš ï¸ æŒ‡å®šã—ãŸé–¾å€¤ã§çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print("   ï¼ˆã“ã‚Œã¯æ­£å¸¸ãªå‹•ä½œã§ã™ - å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼‰")
        
    except Exception as e:
        print(f"âŒ é«˜åº¦ã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nğŸ‰ é«˜åº¦ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 80)
    
    # 5. æ€§èƒ½ã¨ç‰¹å¾´ã®ã¾ã¨ã‚
    print("\nğŸ“‹ å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½ã¾ã¨ã‚:")
    print("âœ… normalize_text() - ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–é–¢æ•°")
    print("   - å¤§æ–‡å­—å°æ–‡å­—çµ±ä¸€")
    print("   - å…¨è§’è‹±æ•°å­—â†’åŠè§’å¤‰æ›")
    print("   - ä¼šç¤¾å½¢æ…‹çµ±ä¸€ï¼ˆæ ªå¼ä¼šç¤¾â†’(æ ª)ç­‰ï¼‰")
    print("   - ç‰¹æ®Šæ–‡å­—çµ±ä¸€")
    print("   - ç©ºç™½æ–‡å­—æ­£è¦åŒ–")
    print()
    print("âœ… similarity() - PostgreSQL trigramé¡ä¼¼åº¦è¨ˆç®—")
    print("âœ… length() - æ–‡å­—æ•°å·®è¨ˆç®—")
    print("âœ… final_score - é¡ä¼¼åº¦ - (0.012 * æ–‡å­—æ•°å·®) + ãƒœãƒ¼ãƒŠã‚¹")
    print("âœ… å®Œå…¨ä¸€è‡´ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆ+0.4ï¼‰")
    print("âœ… å‰æ–¹ä¸€è‡´ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆ+0.2ï¼‰")
    print("âœ… å‹•çš„é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.45ï¼‰")
    print("âœ… æœ€çµ‚ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆï¼ˆDESCï¼‰")
    print("âœ… çµæœæ•°åˆ¶é™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰")
    print("âœ… ä¼šç¤¾IDãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œ")
    print("âœ… WITHå¥ã«ã‚ˆã‚‹åŠ¹ç‡çš„ã‚¯ã‚¨ãƒªæ§‹é€ ")
    print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    print()
    print("ğŸ¯ ã”è³ªå•ã®ã‚¯ã‚¨ãƒªãŒå®Œå…¨ã«å®Ÿè£…ã•ã‚Œã¾ã—ãŸï¼")

if __name__ == "__main__":
    asyncio.run(test_advanced_fuzzy_search()) 